<?xml version="1.0" encoding="utf-8"?><?xml-stylesheet type="text/xsl" href="atom.xsl"?>
<feed xmlns="http://www.w3.org/2005/Atom">
    <id>https://block.github.io/goose/blog</id>
    <title>codename goose Blog</title>
    <updated>2025-04-14T00:00:00.000Z</updated>
    <generator>https://github.com/jpmonette/feed</generator>
    <link rel="alternate" href="https://block.github.io/goose/blog"/>
    <subtitle>codename goose Blog</subtitle>
    <icon>https://block.github.io/goose/img/favicon.ico</icon>
    <entry>
        <title type="html"><![CDATA[How ATrueLight4 Helped Goose Navigate Windows]]></title>
        <id>https://block.github.io/goose/blog/2025/04/14/community-atruelight4</id>
        <link href="https://block.github.io/goose/blog/2025/04/14/community-atruelight4"/>
        <updated>2025-04-14T00:00:00.000Z</updated>
        <summary type="html"><![CDATA[Block Open Source Top Contributor of the Month]]></summary>
        <content type="html"><![CDATA[<p><img decoding="async" loading="lazy" alt="blog cover" src="https://block.github.io/goose/assets/images/goose4win-7f57433fa3f19849e74b18ebffe08bcf.png" width="1206" height="633" class="img_ev3q"></p>
<p>As the goose team continues to work on new features over 800 community members voted to express their need for Goose on Windows. Today's top contributor stepped in to aid this ongoing effort.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="windows-support">Windows Support<a href="https://block.github.io/goose/blog/2025/04/14/community-atruelight4#windows-support" class="hash-link" aria-label="Direct link to Windows Support" title="Direct link to Windows Support">​</a></h2>
<p>Since the launch of codename goose, the open source community has been wanting and requesting the same automation by goose on Windows.</p>
<p>Currently, goose's CLI version works on Windows with limited built-in extensions via WSL, or Windows Subsystem for Linux. While there is a limited internal beta in the works, there are several bugs and improvements that are being worked on to ensure codename goose has the same seamless experience as it does on Mac.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="atruelight4s-goose4win">ATrueLight4's Goose4Win<a href="https://block.github.io/goose/blog/2025/04/14/community-atruelight4#atruelight4s-goose4win" class="hash-link" aria-label="Direct link to ATrueLight4's Goose4Win" title="Direct link to ATrueLight4's Goose4Win">​</a></h2>
<p>Our featured contributor, <a href="https://github.com/ATrueLight4" target="_blank" rel="noopener noreferrer">ATrueLight4</a>, shipped <strong>Goose4Win</strong>, a fix that improves how Goose handles Windows-specific file paths. Their contribution is already merged into main, so if you install Goose for CLI on Windows today, you’ll get the improvement out of the box. No extra setup needed.</p>
<p>Thank you so much for your contribution, ATrueLight4! Your work brings us one step closer to Goose on Windows.</p>
<p>To show our deep gratitude for your contribution, we've granted you the exclusive ✨Top Contributor✨ badge on the Block Open Source Discord! You'll also be one of the first contributors to receive exclusive codename goose swag. (more info on that to be announced later 👀🪿)</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="get-your-own-spotlight">Get Your Own Spotlight<a href="https://block.github.io/goose/blog/2025/04/14/community-atruelight4#get-your-own-spotlight" class="hash-link" aria-label="Direct link to Get Your Own Spotlight" title="Direct link to Get Your Own Spotlight">​</a></h2>
<p>Interested in contributing to goose and having your contribution featured? Whether it's improving platform support, adding new features, or fixing bugs, we welcome all contributions from the open source community. You can <a href="https://discord.gg/block-opensource" target="_blank" rel="noopener noreferrer">join the Block Open Source Discord</a> or <a href="https://block.github.io/goose/" target="_blank" rel="noopener noreferrer">get started using codename goose</a> today.</p>
]]></content>
        <author>
            <name>Tania Chakraborty</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Finetuning Toolshim Models for Tool Calling]]></title>
        <id>https://block.github.io/goose/blog/2025/04/11/finetuning-toolshim</id>
        <link href="https://block.github.io/goose/blog/2025/04/11/finetuning-toolshim"/>
        <updated>2025-04-11T00:00:00.000Z</updated>
        <summary type="html"><![CDATA[Addressing performance limitations in models without native tool calling support]]></summary>
        <content type="html"><![CDATA[<p><img decoding="async" loading="lazy" alt="blog cover" src="https://block.github.io/goose/assets/images/toolshim-header-42611f614e7722f90cf83991debe3046.png" width="1200" height="630" class="img_ev3q"></p>
<p>Our recently published <a href="https://block.github.io/goose/blog/2025/03/31/goose-benchmark" target="_blank" rel="noopener noreferrer">Goose benchmark</a> revealed significant performance limitations in models where tool calling is not straightforwardly supported (e.g., Gemma3, Deepseek-r1, phi4). These models often fail to invoke tools at appropriate times or produce malformed or inconsistently formatted tool calls. With the most recent releases of Llama4 and Deepseek v3 (0324), we are again observing challenges with effective tool calling performance, even on these flagship openweight models.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="why-tool-calling-is-important">Why tool calling is important<a href="https://block.github.io/goose/blog/2025/04/11/finetuning-toolshim#why-tool-calling-is-important" class="hash-link" aria-label="Direct link to Why tool calling is important" title="Direct link to Why tool calling is important">​</a></h2>
<p>Tool calling is a critical capability for agents like goose. It allows models to go beyond text and image generation and take concrete actions, such as executing code, querying databases, searching the web, or interacting with design tools like Figma. Equipping agents with a broad set of tools empowers them to discover and interface with external systems, much like a human would. While this might be overkill for narrow, more deterministic applications of LLMs, it is essential for general-purpose agents like goose. Without reliable tool calling, we limit what models can do to help us automate, remove toil and navigate complex systems. Pure generation–of text, images, speech, and video–is just the first step on the path to more powerful agentic capabilities. There is so much more that models can do if we give them the legs to run.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="background-using-a-local-model-as-a-toolshim">Background: using a local model as a "toolshim"<a href="https://block.github.io/goose/blog/2025/04/11/finetuning-toolshim#background-using-a-local-model-as-a-toolshim" class="hash-link" aria-label="Direct link to Background: using a local model as a &quot;toolshim&quot;" title="Direct link to Background: using a local model as a &quot;toolshim&quot;">​</a></h2>
<p>The goal is to allow goose to work with the widest variety of models possible. A "toolshim" in this case is a thin layer which sits between the main model doing the agent work, and the tools that can perform actual actions (making the agent take action, vs being a chatbot). Previously we have been trying this approach with open models including in this <a href="https://block.github.io/goose/blog/2025/03/31/goose-benchmark" target="_blank" rel="noopener noreferrer">past benchmark</a> post. A toolshim, if it can work, unlocks both powerful cutting edge models (open weight and closed) which while may perform well on various benchmarks, fall well short when tool calling for agents is required (or perhaps don't, by design, support tool calling at all, such as the case with some reasoning models).</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="proposal-fine-tune-a-lightweight-toolshim-model-up-to-12b">Proposal: Fine-tune a lightweight toolshim model (up to 12b)<a href="https://block.github.io/goose/blog/2025/04/11/finetuning-toolshim#proposal-fine-tune-a-lightweight-toolshim-model-up-to-12b" class="hash-link" aria-label="Direct link to Proposal: Fine-tune a lightweight toolshim model (up to 12b)" title="Direct link to Proposal: Fine-tune a lightweight toolshim model (up to 12b)">​</a></h2>
<p>Develop a dedicated toolshim model that translates open-source model outputs into well-structured tool calls, acting as a reliable post-processor to standardize across model families trained that currently exhibit inconsistent and unreliable tool call generation behavior. We do not use tool calling apis even if available, but provide tool context in the system prompts.</p>
<p>We already experimented with this in the <a href="https://block.github.io/goose/blog/2025/03/31/goose-benchmark" target="_blank" rel="noopener noreferrer">benchmarking effort</a>, finding that phi4 (14b) and gemma3 (27b) achieved close performance to llama3.3 (70b) when used with a generic local model (mistral-nemo) as the shim. This shows potential for furthering their performance with more focused attention on improving the shim's performance.</p>
<p>Toolshim System Sketch:</p>
<p><img decoding="async" loading="lazy" alt="Toolshim System Sketch" src="https://block.github.io/goose/assets/images/sketch-0bb4b0e6fb7fdbd194fff4db41c3806f.png" width="1132" height="828" class="img_ev3q"></p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="key-observations-on-current-challenges-with-tool-call-generation">Key Observations on Current Challenges with Tool Call Generation<a href="https://block.github.io/goose/blog/2025/04/11/finetuning-toolshim#key-observations-on-current-challenges-with-tool-call-generation" class="hash-link" aria-label="Direct link to Key Observations on Current Challenges with Tool Call Generation" title="Direct link to Key Observations on Current Challenges with Tool Call Generation">​</a></h2>
<ol>
<li>
<p><strong>Model training templates are inconsistent</strong><br>
<!-- -->For example, <a href="https://qwen.readthedocs.io/en/latest/framework/function_call.html" target="_blank" rel="noopener noreferrer">Qwen models use</a> <a href="https://github.com/NousResearch/Hermes-Function-Calling" target="_blank" rel="noopener noreferrer">Hermes-style tool formats</a>, while Openhands generates Markdown despite explicit JSON instructions—suggesting training data shape can have an underestimated impact on reliable tool call generation</p>
</li>
<li>
<p><strong>Current workarounds aren't enough</strong><br>
<a href="https://docs.vllm.ai/en/latest/features/tool_calling.html" target="_blank" rel="noopener noreferrer">Model providers may implement approaches like guided decoding</a> to guarantee validly-parsable function calls, but these may not produce high-quality outputs if the model wasn't trained on schemas matching what users provide in context. The widespread challenges with tool use with Llama4 may be indicative of the challenges providers have in effectively serving new models to make full use of their capabilities</p>
</li>
<li>
<p><strong>Hosting providers vary wildly in how well they work with tool calls</strong><br>
<!-- -->Hosting providers helpfully provide chat templates or similar which can, in many cases, prompt some of the larger models to reply correctly formatted tool calls, and thus can support openai-like apis where tools are provided, but in practice these can fall short after one shot, or vary a lot between providers (an issue exacerbated if using model routers such as openrouter or huggingface hosted inference)</p>
</li>
</ol>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="some-examples-of-model-specific-quirks-wrt-tool-calling">Some examples of model-specific quirks wrt tool calling:<a href="https://block.github.io/goose/blog/2025/04/11/finetuning-toolshim#some-examples-of-model-specific-quirks-wrt-tool-calling" class="hash-link" aria-label="Direct link to Some examples of model-specific quirks wrt tool calling:" title="Direct link to Some examples of model-specific quirks wrt tool calling:">​</a></h3>
<p><strong>Openhands</strong>: Despite instructions to generate JSON-formatted tool calls, still generates markdown (likely due to shape of their training data)</p>
<p><img decoding="async" loading="lazy" alt="Openhands example" src="https://block.github.io/goose/assets/images/openhands-7fe1d878c7108c846e6275ed3157be6e.png" width="1287" height="233" class="img_ev3q"></p>
<p><strong>Llama4 Maverick</strong>: Generates malformed tool calls, but performs somewhat better when specifically prompted to generate tool calls as JSON</p>
<p>With "tool calls" on OpenRouter:<br>
<img decoding="async" loading="lazy" alt="OpenRouter tool calls example" src="https://block.github.io/goose/assets/images/openrouter_toolcalls-01ef22c3d91ff5580c49b89f6599293f.png" width="1295" height="621" class="img_ev3q"></p>
<p>Llama4 Maverick when instead just prompted to generate tool calls in JSON:<br>
<img decoding="async" loading="lazy" alt="Llama4 example" src="https://block.github.io/goose/assets/images/llama4-2ebc0ab8f18d31c450ee2bf34aa82191.png" width="1296" height="767" class="img_ev3q"></p>
<p><strong>Gemma3</strong>: A DeepMind engineer <a href="https://www.philschmid.de/gemma-function-calling" target="_blank" rel="noopener noreferrer">suggested providing a function calling template in-context in Python format</a><br>
<!-- -->The 12B model also outputs valid JSON tool calls reasonably well:<br>
<img decoding="async" loading="lazy" alt="Gemma3 example" src="https://block.github.io/goose/assets/images/gemma3-eca1a363fea57b818a967883e567a481.png" width="1293" height="299" class="img_ev3q"></p>
<p><strong>Functionary models</strong>: <a href="https://github.com/MeetKai/functionary/issues/302#issuecomment-2650187280" target="_blank" rel="noopener noreferrer">Ollama couldn't support the tool calling capabilities</a> because these models were trained with prompt templates in a TypeScript schema incompatible with Ollama's supported JSON schema</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="experimentation-approach">Experimentation Approach<a href="https://block.github.io/goose/blog/2025/04/11/finetuning-toolshim#experimentation-approach" class="hash-link" aria-label="Direct link to Experimentation Approach" title="Direct link to Experimentation Approach">​</a></h2>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="data-collection">Data Collection<a href="https://block.github.io/goose/blog/2025/04/11/finetuning-toolshim#data-collection" class="hash-link" aria-label="Direct link to Data Collection" title="Direct link to Data Collection">​</a></h3>
<ul>
<li>Extract user messages from historical Goose sessions, and for messages followed by tool calls from Anthropic/OpenAI (all tool calls up to today):<!-- -->
<ul>
<li><strong>Regenerate tool calls with open models:</strong> Regenerate the tool calls with the most capable open models that have supported tool calling capabilities (e.g., QwQ, Qwen, deepseek chat v3)</li>
<li><strong>Generate json/markdown-formatted tool calls to parse:</strong> Instruct the most capable open models (e.g., DeepSeek-r1, Llama4, Gemma3), that don't necessarily have strong tool calling to output tool calls in the correct schema (JSON/markdown). Parse the output into the appropriate tool calls.</li>
<li><strong>Discard any malformed tool calls, tool calls that fail to properly execute, or tool calls that meet other rejection criteria</strong></li>
</ul>
</li>
<li>Generate a few thousand examples with this approach</li>
</ul>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="modeling">Modeling<a href="https://block.github.io/goose/blog/2025/04/11/finetuning-toolshim#modeling" class="hash-link" aria-label="Direct link to Modeling" title="Direct link to Modeling">​</a></h3>
<p>Fine tune small models like mistral-nemo (14b), gemma 4-12b, qwen2.5-coder 7-14b.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="evaluations">Evaluations<a href="https://block.github.io/goose/blog/2025/04/11/finetuning-toolshim#evaluations" class="hash-link" aria-label="Direct link to Evaluations" title="Direct link to Evaluations">​</a></h3>
<p>Test with Goosebench evals run in the benchmarking blogpost. We can directly compare performance of models with and without the finetuned toolshim models supporting them.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="future-approaches">Future approaches<a href="https://block.github.io/goose/blog/2025/04/11/finetuning-toolshim#future-approaches" class="hash-link" aria-label="Direct link to Future approaches" title="Direct link to Future approaches">​</a></h2>
<p>On top of local models, we would like to consider parsers, parser combinators, context-free grammars and more (even very large ones) which are constructed based on 1000s of examples of tool results. Even if large, these can operate at every low latencies extracting parameters for suggested tool calls. There are likely other structured text extraction techniques to be explored to assist with discovery and extraction of tool calls from rich responses from powerful general models.</p>
]]></content>
        <author>
            <name>Alice Hau</name>
        </author>
        <author>
            <name>Michael Neale</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[A Visual Guide To MCP Ecosystem]]></title>
        <id>https://block.github.io/goose/blog/2025/04/10/visual-guide-mcp</id>
        <link href="https://block.github.io/goose/blog/2025/04/10/visual-guide-mcp"/>
        <updated>2025-04-10T00:00:00.000Z</updated>
        <summary type="html"><![CDATA[Visual breakdown of MCP: How your AI agent, tools, and models work together.]]></summary>
        <content type="html"><![CDATA[<p><img decoding="async" loading="lazy" alt="blog cover" src="https://block.github.io/goose/assets/images/mcpblog-40894789122bda594a8576ebcb67a2d8.png" width="2240" height="1260" class="img_ev3q"></p>
<p>You ever open a GitHub repo or blog post, read the first sentence, and immediately feel like you’ve stumbled into a PhD dissertation?</p>
<p>Yeah. Same.</p>
<p>MCP (Model Context Protocol) sounds complicated, but it’s really not. Think of this as your go to cheat sheet, no whitepapers, no academic jargon, just plain English and a few good visuals.</p>
<p>Let's break this down together.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="what-is-mcp-in-plain-english">What Is MCP in Plain English?<a href="https://block.github.io/goose/blog/2025/04/10/visual-guide-mcp#what-is-mcp-in-plain-english" class="hash-link" aria-label="Direct link to What Is MCP in Plain English?" title="Direct link to What Is MCP in Plain English?">​</a></h2>
<p>MCP is like a universal translator between your AI agent, like Goose, and external tools, files, databases, APIs, you name it.</p>
<p>It gives your agent a way to ask questions, run tools, store/retrieve context, and keep track of everything it knows.</p>
<p>Instead of cramming everything into one prompt like “here’s 10k tokens worth of context, good luck,” MCP helps the model pull what it needs, when it needs it.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="who-are-the-players">Who Are The Players?<a href="https://block.github.io/goose/blog/2025/04/10/visual-guide-mcp#who-are-the-players" class="hash-link" aria-label="Direct link to Who Are The Players?" title="Direct link to Who Are The Players?">​</a></h2>
<p><img decoding="async" loading="lazy" alt="players" src="https://block.github.io/goose/assets/images/players-e2b075360b81c342d61ed84bc51c1e97.png" width="2320" height="818" class="img_ev3q"></p>
<ul>
<li>
<p><strong>User</strong> – You, the person with the big ideas and messy problems</p>
</li>
<li>
<p><strong>Agent</strong> – The AI agent, Goose, living in your CLI, IDE, or desktop application</p>
</li>
<li>
<p><strong>LLM</strong> – The model that does the reasoning (like Claude, GPT-4, etc.)</p>
</li>
<li>
<p><strong>MCP Servers (Extensions)</strong> – Goose's toolbox: built-in and custom extensions that give goose the ability to execute tasks</p>
</li>
</ul>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="how-do-they-communicate">How Do They Communicate?<a href="https://block.github.io/goose/blog/2025/04/10/visual-guide-mcp#how-do-they-communicate" class="hash-link" aria-label="Direct link to How Do They Communicate?" title="Direct link to How Do They Communicate?">​</a></h2>
<p>Lets take a look at how all the players work together:</p>
<p><img decoding="async" loading="lazy" alt="Visual guide" src="https://block.github.io/goose/assets/images/visualguide-9b44af19be52631e84712cad31849bee.png" width="1056" height="1516" class="img_ev3q">
In this flow, the user kicks things off by giving Goose a prompt. Goose gets the prompt ready, along with its available tools and any relevant context, and hands it off to the LLM. The LLM decides which tools it needs to complete the task. Goose then routes those tool calls to the right MCP servers, and they execute the tasks. As steps of the task are being completed, informs you, the user, of what it's done and can also loop with the LLM as needed.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="heres-an-analogy">Here's An Analogy<a href="https://block.github.io/goose/blog/2025/04/10/visual-guide-mcp#heres-an-analogy" class="hash-link" aria-label="Direct link to Here's An Analogy" title="Direct link to Here's An Analogy">​</a></h2>
<p>Let’s make this even clearer with a James Bond analogy. Sometimes a story makes it all click.</p>
<p><img decoding="async" loading="lazy" alt="james bond" src="https://block.github.io/goose/assets/images/james-89c46143c593bee36832667ded97233c.png" width="1266" height="844" class="img_ev3q"></p>
<p>If you’ve ever seen a James Bond movie, you know the scene,
Bond walks into Q’s lab before the mission.
Q opens up the suitcase of gadgets, exploding pens, invisible cars, grappling watches, you name it.</p>
<p>Goose is <em>like</em> Q in this situation.
The suitcase is already packed with tools, built-in and custom extensions (MCP servers).</p>
<p>Before the LLM (Bond) starts the mission, Goose gives it the full briefing:</p>
<blockquote>
<p><em>"Here’s your target (the prompt). Here’s your gadget suitcase (the extensions you can use). Good luck."</em></p>
</blockquote>
<p>The MCP servers?</p>
<p>That’s the hidden team in the back actually building the gadgets and handing them over when Bond needs them in the field.</p>
<p>The LLM (Bond) picks the right gadgets for the mission, Goose routes the request to the right MCP server, MCP makes sure they work, and the whole operation runs smoothly.</p>
<p>Without Goose handing over the gadget suitcase, the model would just show up in the field with nothing but a tuxedo and a smile, and we don't want to know how that ends.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="your-turn">Your Turn<a href="https://block.github.io/goose/blog/2025/04/10/visual-guide-mcp#your-turn" class="hash-link" aria-label="Direct link to Your Turn" title="Direct link to Your Turn">​</a></h2>
<p>Now that you’ve got the basics down, and you understand how the MCP ecosystem works, it’s time to try it yourself.</p>
<p>The <a href="https://block.github.io/goose/docs/quickstart">Quickstart Guide</a> walks you through connecting your first MCP server.</p>
<p>And when you’re ready to explore more, head over to the <a href="https://block.github.io/goose/docs/category/tutorials">tutorials section</a> in the docs — it has step-by-step guides and short video demos to show you how to connect to a variety of MCP servers.</p>
<p>And don't forget to <a href="https://discord.gg/block-opensource" target="_blank" rel="noopener noreferrer">join the community</a> to see what others are building, ask questions, or to simply connect.</p>
]]></content>
        <author>
            <name>Ebony Louis</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[How to Vibe Code Responsibly (with Goose)]]></title>
        <id>https://block.github.io/goose/blog/2025/04/08/vibe-code-responsibly</id>
        <link href="https://block.github.io/goose/blog/2025/04/08/vibe-code-responsibly"/>
        <updated>2025-04-08T00:00:00.000Z</updated>
        <summary type="html"><![CDATA[Vibe coding feels magical until it isn't. Learn how to flow with Goose while protecting your code, your team, and your future self.]]></summary>
        <content type="html"><![CDATA[<p><img decoding="async" loading="lazy" alt="blog cover" src="https://block.github.io/goose/assets/images/responsible-vibe-code-a77f5e24a879edda943cc76f1fc0bd2a.png" width="2240" height="1260" class="img_ev3q"></p>
<p>On Feb 2, 2025, Andrej Karpathy coined the phrase "<a href="https://x.com/karpathy/status/1886192184808149383" target="_blank" rel="noopener noreferrer">vibe coding</a>". Vibe coding represents a new approach to coding where developers ask an AI agent to build something, and they go with the flow.</p>
<p>The <a href="https://modelcontextprotocol.io/introduction" target="_blank" rel="noopener noreferrer">Model Context Protocol (MCP)</a> makes this practice possible. Before MCP, developers copied and pasted context between applications. This workflow fell short of the promised AI agent automation that everyone claimed. Today, AI agents can work autonomously using MCP and integrate with any application, from GitHub to Cloudflare, YouTube, and Figma.</p>
<p>This shift democratizes coding. For example, it's empowered:</p>
<ul>
<li>Web developers to create video games with Unity</li>
<li>Designers and product managers to prototype full-stack applications</li>
<li>Business owners to transform their visions into functional products</li>
</ul>
<p>It's a freeing experience. But too often, we're <a href="https://www.britannica.com/topic/Icarus-Greek-mythology" target="_blank" rel="noopener noreferrer">Icarus</a> with the keyboard, vibe coding too close to the sun.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="the-dark-side-of-vibe-coding">The Dark Side of Vibe Coding<a href="https://block.github.io/goose/blog/2025/04/08/vibe-code-responsibly#the-dark-side-of-vibe-coding" class="hash-link" aria-label="Direct link to The Dark Side of Vibe Coding" title="Direct link to The Dark Side of Vibe Coding">​</a></h2>
<p>This creative freedom comes with significant risks. Many developers have encountered serious issues while vibe coding:</p>
<ul>
<li>Committing code with security vulnerabilities</li>
<li>Introducing difficult-to-fix bugs on top of "spaghetti" code</li>
<li>Losing weeks or months of work due to lack of version control</li>
<li>Accidentally exposing sensitive information like environment variables and API keys in production</li>
</ul>
<blockquote class="twitter-tweet" data-dnt="true" align="center"><p lang="en" dir="ltr">Today was the worst day ever☹️<br>The project I had been working on for the last two weeks got corrupted, and everything was lost. Just like that, my SaaS was gone. Two weeks of hard work, completely ruined.<br>But!!!<br>I started from scratch and have already completed 50% of the work…</p>— CC Anuj (@vid_anuj) <a href="https://twitter.com/vid_anuj/status/1902379748501880934?ref_src=twsrc%5Etfw">March 19, 2025</a></blockquote>
<!-- -->
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="a-better-way-to-vibe-code-with-goose">A Better Way to Vibe Code with Goose<a href="https://block.github.io/goose/blog/2025/04/08/vibe-code-responsibly#a-better-way-to-vibe-code-with-goose" class="hash-link" aria-label="Direct link to A Better Way to Vibe Code with Goose" title="Direct link to A Better Way to Vibe Code with Goose">​</a></h2>
<p><a href="https://block.github.io/goose" target="_blank" rel="noopener noreferrer">Goose</a> is an open source AI agent local to your machine with built-in features for safe vibe coding.</p>
<div class="theme-admonition theme-admonition-note admonition_xJq3 alert alert--secondary"><div class="admonitionHeading_Gvgb"><span class="admonitionIcon_Rf37"><svg viewBox="0 0 14 16"><path fill-rule="evenodd" d="M6.3 5.69a.942.942 0 0 1-.28-.7c0-.28.09-.52.28-.7.19-.18.42-.28.7-.28.28 0 .52.09.7.28.18.19.28.42.28.7 0 .28-.09.52-.28.7a1 1 0 0 1-.7.3c-.28 0-.52-.11-.7-.3zM8 7.99c-.02-.25-.11-.48-.31-.69-.2-.19-.42-.3-.69-.31H6c-.27.02-.48.13-.69.31-.2.2-.3.44-.31.69h1v3c.02.27.11.5.31.69.2.2.42.31.69.31h1c.27 0 .48-.11.69-.31.2-.19.3-.42.31-.69H8V7.98v.01zM7 2.3c-3.14 0-5.7 2.54-5.7 5.68 0 3.14 2.56 5.7 5.7 5.7s5.7-2.55 5.7-5.7c0-3.15-2.56-5.69-5.7-5.69v.01zM7 .98c3.86 0 7 3.14 7 7s-3.14 7-7 7-7-3.12-7-7 3.14-7 7-7z"></path></svg></span>note</div><div class="admonitionContent_BuS1"><p>Most folks define "vibe coding" as purely chaotic development with no rules. I'm redefining it as flowing with AI while protecting your project, team, and future self.</p></div></div>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="1-use-gooseignore-to-protect-sensitive-files">1. Use <code>.gooseignore</code> to Protect Sensitive Files<a href="https://block.github.io/goose/blog/2025/04/08/vibe-code-responsibly#1-use-gooseignore-to-protect-sensitive-files" class="hash-link" aria-label="Direct link to 1-use-gooseignore-to-protect-sensitive-files" title="Direct link to 1-use-gooseignore-to-protect-sensitive-files">​</a></h3>
<p>Goose supports <a href="https://block.github.io/goose/docs/guides/using-gooseignore" target="_blank" rel="noopener noreferrer"><code>.gooseignore</code></a> files. The concept is similar to <code>.gitignore</code> files for your AI agent. It defines which files and folders Goose should <em>not</em> read, modify, or interact with.</p>
<p>Use this when you want to prevent:</p>
<ul>
<li>Accidental changes to environment variables</li>
<li>Modifications to sensitive configs</li>
<li>Changes to test fixtures or snapshots</li>
<li>Edits to infrastructure and deployment configs</li>
<li>Changes to code examples or documentation</li>
<li>Shell commands running in places they shouldn't</li>
</ul>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="2-create-a-plan">2. Create a plan<a href="https://block.github.io/goose/blog/2025/04/08/vibe-code-responsibly#2-create-a-plan" class="hash-link" aria-label="Direct link to 2. Create a plan" title="Direct link to 2. Create a plan">​</a></h3>
<p>Goose's <a href="https://block.github.io/goose/docs/guides/goose-cli-commands#examples" target="_blank" rel="noopener noreferrer"><code>/plan</code></a> command helps you align with your agent before any code is touched, giving you a clear understanding of what it intends to do and how it will do it.</p>
<p>This is especially useful for tasks that span multiple files, involve side effects, or could impact critical areas of your codebase. No more guesswork—just a structured breakdown you can review and approve.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="3-choose-the-right-mode-for-the-job">3. Choose the Right Mode for the Job<a href="https://block.github.io/goose/blog/2025/04/08/vibe-code-responsibly#3-choose-the-right-mode-for-the-job" class="hash-link" aria-label="Direct link to 3. Choose the Right Mode for the Job" title="Direct link to 3. Choose the Right Mode for the Job">​</a></h3>
<p>While letting your AI agent take the lead is fun, not every moment calls for full autonomy. Sometimes, you need to pause, review, or plan before any code changes. Goose offers several <a href="https://block.github.io/goose/docs/guides/goose-permissions" target="_blank" rel="noopener noreferrer">modes</a> that help you stay in control without breaking your momentum. Here's how to use them intentionally during your sessions:</p>
<ul>
<li>
<p><strong>Chat Mode</strong><br>
<!-- -->Goose will only respond with text so that you can brainstorm together.</p>
</li>
<li>
<p><strong>Approval Mode</strong><br>
<!-- -->Before Goose executes an action, it asks for your approval. This is helpful when you want to keep building fast but still want to know what's about to happen before it does.</p>
</li>
<li>
<p><strong>Smart Approval</strong><br>
<!-- -->In this mode, Goose requests your approval for risky actions. This mode is helpful for prototyping quickly while keeping guardrails in place.</p>
</li>
<li>
<p><strong>Autonomous Mode</strong><br>
<!-- -->In this mode, Goose moves forward without asking for approval. Using this mode is best if you feel confident in the direction and have safety nets in place.</p>
</li>
</ul>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="4-use-version-control-religiously">4. Use Version Control Religiously<a href="https://block.github.io/goose/blog/2025/04/08/vibe-code-responsibly#4-use-version-control-religiously" class="hash-link" aria-label="Direct link to 4. Use Version Control Religiously" title="Direct link to 4. Use Version Control Religiously">​</a></h3>
<p>There are moments when AI agents change too many files and lines that the Control + Z can't fix. It's best to commit to every change that you or Goose make to get recovery points, clear diffs, and the ability to revert quickly.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="5-ask-questions-and-think-critically">5. Ask Questions and Think Critically<a href="https://block.github.io/goose/blog/2025/04/08/vibe-code-responsibly#5-ask-questions-and-think-critically" class="hash-link" aria-label="Direct link to 5. Ask Questions and Think Critically" title="Direct link to 5. Ask Questions and Think Critically">​</a></h3>
<p>Even if you're vibe coding, don't turn off your brain.</p>
<p>Ask Goose:</p>
<ul>
<li>Why did you make this change?</li>
<li>Is this secure?</li>
<li>How are we handling secrets?</li>
<li>Is this the best way to structure the database?</li>
</ul>
<p>By pushing your agent to explain itself, you'll build a better product and learn more along the way.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="6-define-goosehints-for-better-context">6. Define .goosehints for Better Context<a href="https://block.github.io/goose/blog/2025/04/08/vibe-code-responsibly#6-define-goosehints-for-better-context" class="hash-link" aria-label="Direct link to 6. Define .goosehints for Better Context" title="Direct link to 6. Define .goosehints for Better Context">​</a></h3>
<p>The <a href="https://block.github.io/goose/docs/guides/using-goosehints" target="_blank" rel="noopener noreferrer">.goosehints</a> file gives Goose additional context about your project's coding standards, architectural preferences, and security practices.</p>
<p>Here are a few examples:</p>
<ul>
<li>"Never expose API keys."</li>
<li>"Use prepared statements for database queries."</li>
<li>"Avoid using eval or unsafe dynamic code."</li>
</ul>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="7-integrate-goose-into-your-cicd">7. Integrate Goose into Your CI/CD<a href="https://block.github.io/goose/blog/2025/04/08/vibe-code-responsibly#7-integrate-goose-into-your-cicd" class="hash-link" aria-label="Direct link to 7. Integrate Goose into Your CI/CD" title="Direct link to 7. Integrate Goose into Your CI/CD">​</a></h3>
<p>Before issues hit production, add <a href="https://block.github.io/goose/docs/tutorials/cicd" target="_blank" rel="noopener noreferrer">Goose to your CI/CD pipeline</a> to:</p>
<ul>
<li>Automate code reviews</li>
<li>Validate documentation</li>
<li>Run security checks</li>
</ul>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="8-use-an-allowlist-to-block-unsafe-mcp-servers">8. Use an Allowlist to Block Unsafe MCP Servers<a href="https://block.github.io/goose/blog/2025/04/08/vibe-code-responsibly#8-use-an-allowlist-to-block-unsafe-mcp-servers" class="hash-link" aria-label="Direct link to 8. Use an Allowlist to Block Unsafe MCP Servers" title="Direct link to 8. Use an Allowlist to Block Unsafe MCP Servers">​</a></h3>
<p>Some MCP servers can introduce security risks, especially if compromised.</p>
<p>Use the Goose <a href="https://github.com/block/goose/blob/main/crates/goose-server/ALLOWLIST.md" target="_blank" rel="noopener noreferrer">allowlist</a> feature to prevent Goose from calling unsafe or untrusted tools.</p>
<p>Here's how the team at Block is thinking about <a href="https://block.github.io/goose/blog/2025/03/31/securing-mcp" target="_blank" rel="noopener noreferrer">securing the MCP</a>.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="9-pick-a-high-performing-llm">9. Pick a High-Performing LLM<a href="https://block.github.io/goose/blog/2025/04/08/vibe-code-responsibly#9-pick-a-high-performing-llm" class="hash-link" aria-label="Direct link to 9. Pick a High-Performing LLM" title="Direct link to 9. Pick a High-Performing LLM">​</a></h3>
<p>Not all LLMs are built the same. Goose plays best with:</p>
<ul>
<li>Claude Sonnet 3.5</li>
<li>GPT-4o</li>
</ul>
<p>Lower-performing models might work, but they're more likely to hallucinate or misunderstand your goals. Read more about how <a href="https://block.github.io/goose/blog/2025/03/31/goose-benchmark/" target="_blank" rel="noopener noreferrer">different LLM's perform with Goose</a>.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="watch-vibe-coding-in-action">Watch Vibe Coding in Action<a href="https://block.github.io/goose/blog/2025/04/08/vibe-code-responsibly#watch-vibe-coding-in-action" class="hash-link" aria-label="Direct link to Watch Vibe Coding in Action" title="Direct link to Watch Vibe Coding in Action">​</a></h2>
<p>Here’s how folks vibe code with Goose:</p>
<iframe width="560" height="315" src="https://www.youtube.com/embed/xZo3aA-vFi4?si=14bVczrCUwdKBZyg" title="The Great Great Off" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin"></iframe>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="final-thoughts">Final Thoughts<a href="https://block.github.io/goose/blog/2025/04/08/vibe-code-responsibly#final-thoughts" class="hash-link" aria-label="Direct link to Final Thoughts" title="Direct link to Final Thoughts">​</a></h2>
<p>Vibe coding isn't inherently wrong. It's marks a new chapter in how we build, and it opens the door for everyone. But experienced developers have a responsibility to define what smart, safe vibe coding looks like. Goose gives us the tools to set that standard, so the whole community can code creatively without sacrificing quality.</p>
<p>Download <a href="https://block.github.io/goose/docs/getting-started/installation/" target="_blank" rel="noopener noreferrer">Goose</a>, and start vibe coding with intention today!</p>
]]></content>
        <author>
            <name>Rizel Scarlett</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Top 5 MCP Servers I Use as a Developer with Goose]]></title>
        <id>https://block.github.io/goose/blog/2025/04/01/top-5-mcp-servers</id>
        <link href="https://block.github.io/goose/blog/2025/04/01/top-5-mcp-servers"/>
        <updated>2025-04-02T00:00:00.000Z</updated>
        <summary type="html"><![CDATA[These 5 MCP servers help me automate my workflow and make me a better developer.]]></summary>
        <content type="html"><![CDATA[<p><img decoding="async" loading="lazy" alt="blog cover" src="https://block.github.io/goose/assets/images/mcp-servers-cover-99742334f4c2581d18eb092cd0c737f9.png" width="2240" height="1260" class="img_ev3q"></p>
<p>As a developer, finding the right tools that seamlessly work together can feel like discovering a superpower. And when you have a working process, it can sometimes be difficult to try out new tools.</p>
<p>With the introduction of MCPs, AI agents like Goose are able to plug in to my existing tools, and the only thing that changes with my workflow is that much welcomed automation that comes with it. I still do the same things I do, but backed by AI, I can now do them faster and with more confidence.</p>
<p>Today, I'm excited to share not just my favorite MCP servers, but the ones I actually use almost everyday with real applications that you can probably relate to as well.</p>
<div class="theme-admonition theme-admonition-tip admonition_xJq3 alert alert--success"><div class="admonitionHeading_Gvgb"><span class="admonitionIcon_Rf37"><svg viewBox="0 0 12 16"><path fill-rule="evenodd" d="M6.5 0C3.48 0 1 2.19 1 5c0 .92.55 2.25 1 3 1.34 2.25 1.78 2.78 2 4v1h5v-1c.22-1.22.66-1.75 2-4 .45-.75 1-2.08 1-3 0-2.81-2.48-5-5.5-5zm3.64 7.48c-.25.44-.47.8-.67 1.11-.86 1.41-1.25 2.06-1.45 3.23-.02.05-.02.11-.02.17H5c0-.06 0-.13-.02-.17-.2-1.17-.59-1.83-1.45-3.23-.2-.31-.42-.67-.67-1.11C2.44 6.78 2 5.65 2 5c0-2.2 2.02-4 4.5-4 1.22 0 2.36.42 3.22 1.19C10.55 2.94 11 3.94 11 5c0 .66-.44 1.78-.86 2.48zM4 14h5c-.23 1.14-1.3 2-2.5 2s-2.27-.86-2.5-2z"></path></svg></span>tip</div><div class="admonitionContent_BuS1"><p>You can ask Goose what you can do with an extension to get a list of all the features and example use cases you can try out.</p></div></div>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="github-mcp-server-everything-github">GitHub MCP Server: Everything GitHub<a href="https://block.github.io/goose/blog/2025/04/01/top-5-mcp-servers#github-mcp-server-everything-github" class="hash-link" aria-label="Direct link to GitHub MCP Server: Everything GitHub" title="Direct link to GitHub MCP Server: Everything GitHub">​</a></h2>
<p>The <a href="https://block.github.io/goose/docs/tutorials/github-mcp">GitHub MCP Server</a> comes with quite a lot of functionality. It can help you create issues, pull requests, repositories, and branches. My most frequent use case for the GitHub MCP is reviewing and understanding pull requests.</p>
<p>For cases when it's a large pull request, or I don't understand what is going on, I can pass the PR to Goose, giving it the right context to make me understand and then act on the pull request. I'm even able to create a documentation update or changelog update from the file changes in the PR. This is definitely one of my favorite things.</p>
<p>E.g</p>
<div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">Hey Goose, this pull request https://github.com/block/goose/pull/1949, has a lot of changes. Can you summarize into a changelog for me?</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="knowledge-graph-memory-context-on-steroids">Knowledge Graph Memory: Context on Steroids<a href="https://block.github.io/goose/blog/2025/04/01/top-5-mcp-servers#knowledge-graph-memory-context-on-steroids" class="hash-link" aria-label="Direct link to Knowledge Graph Memory: Context on Steroids" title="Direct link to Knowledge Graph Memory: Context on Steroids">​</a></h2>
<p>The <a href="https://block.github.io/goose/docs/tutorials/knowledge-graph-mcp">Knowledge Graph Memory</a> extension is like giving Goose a photographic memory of your project or data. Like the name implies, it creates a graph of any information fed into it, connecting the dots between different pieces of information or as I like to use it for - documentation.</p>
<p>If I'm working on a specific project or library and I don't want any hallucinations, I am able to feed Goose with the right context and it will be able to answer questions about the project or library with the right context.</p>
<p>This could be documentation of the project I'm currently working on, or even documentation of a library I'm using.</p>
<p>E.g</p>
<div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">I'm currently in a project called Goose, read through the documentation in `documentation/docs/` folder and store key information in the knowledge graph. Use it for reference anytime I ask you about Goose.</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="fetch-extension-the-web-in-our-hands">Fetch Extension: The Web in our Hands<a href="https://block.github.io/goose/blog/2025/04/01/top-5-mcp-servers#fetch-extension-the-web-in-our-hands" class="hash-link" aria-label="Direct link to Fetch Extension: The Web in our Hands" title="Direct link to Fetch Extension: The Web in our Hands">​</a></h2>
<p>I had a slightly hard time deciding between the <a href="https://block.github.io/goose/docs/tutorials/tavily-mcp">Tavily Web Search Extension</a> and The <a href="https://block.github.io/goose/docs/tutorials/fetch-mcp">Fetch Extension</a> because while I do use them both to access the web, the Fetch extension works more like default for me. With the example above using the Knowledge graph, I'm able to get information from the internet to give Goose additional context to work with.</p>
<div class="theme-admonition theme-admonition-note admonition_xJq3 alert alert--secondary"><div class="admonitionHeading_Gvgb"><span class="admonitionIcon_Rf37"><svg viewBox="0 0 14 16"><path fill-rule="evenodd" d="M6.3 5.69a.942.942 0 0 1-.28-.7c0-.28.09-.52.28-.7.19-.18.42-.28.7-.28.28 0 .52.09.7.28.18.19.28.42.28.7 0 .28-.09.52-.28.7a1 1 0 0 1-.7.3c-.28 0-.52-.11-.7-.3zM8 7.99c-.02-.25-.11-.48-.31-.69-.2-.19-.42-.3-.69-.31H6c-.27.02-.48.13-.69.31-.2.2-.3.44-.31.69h1v3c.02.27.11.5.31.69.2.2.42.31.69.31h1c.27 0 .48-.11.69-.31.2-.19.3-.42.31-.69H8V7.98v.01zM7 2.3c-3.14 0-5.7 2.54-5.7 5.68 0 3.14 2.56 5.7 5.7 5.7s5.7-2.55 5.7-5.7c0-3.15-2.56-5.69-5.7-5.69v.01zM7 .98c3.86 0 7 3.14 7 7s-3.14 7-7 7-7-3.12-7-7 3.14-7 7-7z"></path></svg></span>note</div><div class="admonitionContent_BuS1"><p>The Tavily Web Search Extension has deep research capabilities and is great for finding specific information, while the Fetch Extension is more about general web access and data retrieval.</p></div></div>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="memory-extension-my-habits-and-preferences">Memory Extension: My Habits and Preferences<a href="https://block.github.io/goose/blog/2025/04/01/top-5-mcp-servers#memory-extension-my-habits-and-preferences" class="hash-link" aria-label="Direct link to Memory Extension: My Habits and Preferences" title="Direct link to Memory Extension: My Habits and Preferences">​</a></h2>
<p>I use the <a href="https://block.github.io/goose/docs/tutorials/memory-mcp">Memory Extension</a> to remind Goose about my general preferences as I work - to default to JavaScript or Node when trying out new prototypes, if I prefer one naming convention or the other - maybe even how I like my coffee <!-- -->:D<!-- -->.</p>
<p>This works differently from the Knowledge Graph extension even though they both store information locally. When combined with the Knowledge Graph, it can also help maintain a clear trail of technical decisions and their rationale. For example I got stuck on a code migration and asked Goose to remember where we stopped, what we've tried so far, and what we want to do next for when I start a new session.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="vs-code-extension-your-favorite-editor-connected">VS Code Extension: Your Favorite Editor, Connected<a href="https://block.github.io/goose/blog/2025/04/01/top-5-mcp-servers#vs-code-extension-your-favorite-editor-connected" class="hash-link" aria-label="Direct link to VS Code Extension: Your Favorite Editor, Connected" title="Direct link to VS Code Extension: Your Favorite Editor, Connected">​</a></h2>
<p>One of the biggest points in conversations with people especially around vibe coding, is finding ways to track what changes are being made. While version control is always recommended, sometimes I want to be able to stop or change direction before going too far. The <a href="https://block.github.io/goose/docs/tutorials/vscode-mcp">VS Code Extension</a> alongside other features, allows me to preview the diff of my code changes before I commit them.</p>
<p>I can choose to accept or refuse these changes, or tell Goose to try something else before any actual changes are made.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="the-power-of-integration">The Power of Integration<a href="https://block.github.io/goose/blog/2025/04/01/top-5-mcp-servers#the-power-of-integration" class="hash-link" aria-label="Direct link to The Power of Integration" title="Direct link to The Power of Integration">​</a></h2>
<p>As mentioned at the beginning of this post, the best thing about these MCP servers is how they plug into my existing workflow. I am able to:</p>
<ul>
<li>Start a new session on Goose which opens the current folder as a project in VS Code.</li>
<li>Start work on any changes and get any context I need from either the Knowledge Graph or from the internet using the Fetch extension.</li>
<li>Any attempts at making changes takes my preferences from the Memory extension into account.</li>
<li>I can then review these changes right in VS Code and either accept or reject them.</li>
<li>And complete the task by asking Goose to create a pull request for me.</li>
</ul>
<p>This is a simplified example of how I use these extensions together - I may not use all of them in every session, but having them available sure makes my workflow much smoother.</p>
<p>What are your favorite MCP servers? How do you use them together? Share your experiences with us on <a href="https://discord.gg/block-opensource" target="_blank" rel="noopener noreferrer">Discord server</a>!</p>
]]></content>
        <author>
            <name>Adewale Abati</name>
            <uri>https://adewaleabati.com</uri>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[MCP Explained for Non-Developers]]></title>
        <id>https://block.github.io/goose/blog/2025/04/01/mcp-nondevs</id>
        <link href="https://block.github.io/goose/blog/2025/04/01/mcp-nondevs"/>
        <updated>2025-04-01T00:00:00.000Z</updated>
        <summary type="html"><![CDATA[Learn what Model Context Protocol (MCP) is and how anyone can use it to save time on tasks.]]></summary>
        <content type="html"><![CDATA[<p><img decoding="async" loading="lazy" alt="blog cover" src="https://block.github.io/goose/assets/images/mcp_nondevs-5ce7f39de923cab01de6e14e5dc06744.png" width="1206" height="633" class="img_ev3q"></p>
<p>MCP this, MCP that, what exactly is it, and can you use them if you're not a developer? 🤔</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="what-is-mcp">What is MCP?<a href="https://block.github.io/goose/blog/2025/04/01/mcp-nondevs#what-is-mcp" class="hash-link" aria-label="Direct link to What is MCP?" title="Direct link to What is MCP?">​</a></h2>
<p>MCP stands for <a href="https://modelcontextprotocol.io/introduction" target="_blank" rel="noopener noreferrer">Model Context Protocol</a>, an open standard created by Anthropic.</p>
<p>Let's say you're looking for ways to use AI at work to become more efficient and save as much time as possible. So you go off and learn about large language models (LLMs) like OpenAI or Claude, and start chatting with one. It's amazing being able to chat with AI and have it instantly answer questions or have it tell you how to do something, but how about getting the AI to do stuff for you?</p>
<p>Now there are AI agents, or AI assistants, that can take actions and make decisions for you. But in order to have your AI agent interact with your systems, like Google Drive, Asana, or Slack, there wasn't a standard way to do it. At least not without figuring it out from scratch each time you needed your AI agent to work with what you need it to work with. That's super tedious.</p>
<p>That's exactly where MCP comes in. Best part is, you don't need to be a developer to start using them! MCP essentially allows you to give AI agents access to your external systems without having to code. You can think of MCP as the connector for a system and your AI agent, or like the USB-C of AI integrations.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="mcp-servers-you-should-try-right-now">MCP Servers You Should Try Right Now<a href="https://block.github.io/goose/blog/2025/04/01/mcp-nondevs#mcp-servers-you-should-try-right-now" class="hash-link" aria-label="Direct link to MCP Servers You Should Try Right Now" title="Direct link to MCP Servers You Should Try Right Now">​</a></h2>
<p>So what can you connect your AI agent to? MCP Servers! MCP servers give your agent access to your tools. With <a href="https://glama.ai/mcp/servers" target="_blank" rel="noopener noreferrer">over 3000 MCP servers</a> you can connect to, here is your top list of popular MCP servers you should try:</p>
<ul>
<li><strong><a href="https://block.github.io/goose/docs/tutorials/google-drive-mcp">Google Drive</a></strong>: File access and search capabilities for Google Drive</li>
<li><strong><a href="https://block.github.io/goose/docs/tutorials/youtube-transcript">YouTube Transcript</a></strong>: Grab and work with YouTube video transcripts</li>
<li><strong><a href="https://block.github.io/goose/docs/tutorials/google-maps-mcp">Google Maps</a></strong>: Location services, directions, and place details</li>
<li><strong><a href="https://block.github.io/goose/docs/tutorials/tavily-mcp">Tavily Web Search</a></strong>: Web and local search using Tavily's Search API</li>
<li><strong><a href="https://block.github.io/goose/docs/tutorials/asana-mcp">Asana</a></strong>: View asana tasks, projects, workspaces, and/or comments</li>
<li><strong><a href="https://block.github.io/goose/docs/tutorials/speech-mcp">Speech</a></strong>: Real-time voice interaction, audio/video transcription, text-to-speech conversion and more</li>
<li><strong><a href="https://block.github.io/goose/docs/tutorials/github-mcp">GitHub</a></strong>: Tools to read, search, and manage Git repositories</li>
<li><strong><a href="https://block.github.io/goose/docs/tutorials/fetch-mcp">Fetch</a></strong>: Web content fetching and conversion for efficient LLM usage</li>
</ul>
<p>This quick list should give you an idea of all the ways you can now use AI agents with your workflow. You can also explore community favorites in <a href="https://dev.to/techgirl1908/my-favorite-mcp-directories-573n" target="_blank" rel="noopener noreferrer">handy MCP directories</a>, and learn <a href="https://block.github.io/goose/blog/2025/03/26/mcp-security">how to check MCP servers are safe</a> before installing.</p>
<p>You can also check out these <a href="https://block.github.io/goose/docs/category/tutorials">Goose tutorials</a>, showing you exactly how you can use some of these popular MCP servers with Goose, or use <a href="https://block.github.io/goose/docs/tutorials/tutorial-extension">Goose's Tutorial extension</a> to get extra help walking you through using or building extensions.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="example-mcp-prompts">Example MCP Prompts<a href="https://block.github.io/goose/blog/2025/04/01/mcp-nondevs#example-mcp-prompts" class="hash-link" aria-label="Direct link to Example MCP Prompts" title="Direct link to Example MCP Prompts">​</a></h2>
<p>Now that you've caught a glimpse of some of the MCP servers that out there, how do you make sure you're using MCPs with AI agents the best you can? This is where prompts come in.</p>
<p>Prompts are ultimately the text you input when interacting with an AI assistant, and prompts can range from super simple questions to detailed instructions! Here are some example prompts you can ask an AI agent like Goose right now that use some of the MCP servers mentioned above:</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="google-maps">Google Maps<a href="https://block.github.io/goose/blog/2025/04/01/mcp-nondevs#google-maps" class="hash-link" aria-label="Direct link to Google Maps" title="Direct link to Google Maps">​</a></h3>
<div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">Google Maps: Track the live GPS location of driver ID #{driver_id}. Query Google Maps for real-time traffic data and adjust the estimated delivery time if delays exceed 5 minutes. If ETA changes, update the customer's live tracker and send an SMS notification. If the delay is greater than 20 minutes, check if another driver within a 1-mile radius can take over the delivery.</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="youtube-transcript">YouTube Transcript<a href="https://block.github.io/goose/blog/2025/04/01/mcp-nondevs#youtube-transcript" class="hash-link" aria-label="Direct link to YouTube Transcript" title="Direct link to YouTube Transcript">​</a></h3>
<div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">YouTube Transcript: Get the transcript from this youtube video [link to video]. Then, summarize it into a blog post.</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="google-drive">Google Drive<a href="https://block.github.io/goose/blog/2025/04/01/mcp-nondevs#google-drive" class="hash-link" aria-label="Direct link to Google Drive" title="Direct link to Google Drive">​</a></h3>
<div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">I have an important marketing budget review meeting in 30 minutes and I need your help getting prepared. I have several documents in my Google Drive from our previous meetings and planning sessions. Could you help me by:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">1. Finding all relevant documents about our marketing budget and performance</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">2. Giving me a quick summary of our Q1 performance</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">3. Highlighting the key decisions we need to make about the marketing automation tool and video production</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">4. Identifying any outstanding action items from our last meeting</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="asana">Asana<a href="https://block.github.io/goose/blog/2025/04/01/mcp-nondevs#asana" class="hash-link" aria-label="Direct link to Asana" title="Direct link to Asana">​</a></h3>
<div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">Asana: Create a new task in my Asana workspace called 'Review Q4 metrics' and set the due date to next Friday. Then, find all tasks assigned to me that are due this week and summarize them.</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="github">GitHub<a href="https://block.github.io/goose/blog/2025/04/01/mcp-nondevs#github" class="hash-link" aria-label="Direct link to GitHub" title="Direct link to GitHub">​</a></h3>
<div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">GitHub: Create a new branch called hello-world in my angiejones/goose-demo repository. Update the README.md file to say "this was written by goose" and commit it. Open a pull request with your changes.</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>To see more examples just like this, along with the results you can get, check out this <a href="https://block.github.io/goose/prompt-library" target="_blank" rel="noopener noreferrer">Prompt Library</a>! This is your central directory for discovering and using effective prompts with Goose.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="the-possibilities-are-endless">The Possibilities Are Endless<a href="https://block.github.io/goose/blog/2025/04/01/mcp-nondevs#the-possibilities-are-endless" class="hash-link" aria-label="Direct link to The Possibilities Are Endless" title="Direct link to The Possibilities Are Endless">​</a></h2>
<p>While some are developed by official providers, a vast majority of MCP servers you see are actually developed by community members! Plus, because MCP is an open standard, anyone can build an MCP server for any resource. You could even use Goose to help you build one!</p>
<p>Hopefully now, instead of spending hours manually gathering data and creating your next marketing report, or manually sorting through your todo-backlog on a Monday, you will use MCP with Goose and have it done for you in minutes.</p>
<p><em>To learn more about using MCP servers and Goose, check out the <a href="https://block.github.io/goose/docs/category/getting-started" target="_blank" rel="noopener noreferrer">Goose documentation</a>, or join the <a href="https://discord.gg/block-opensource" target="_blank" rel="noopener noreferrer">Block Open Source Discord</a> to connect with other open source community members.</em></p>
]]></content>
        <author>
            <name>Tania Chakraborty</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Community-Inspired Benchmarking: The Goose Vibe Check]]></title>
        <id>https://block.github.io/goose/blog/2025/03/31/goose-benchmark</id>
        <link href="https://block.github.io/goose/blog/2025/03/31/goose-benchmark"/>
        <updated>2025-03-31T00:00:00.000Z</updated>
        <summary type="html"><![CDATA[See how open source AI models measure up in our first Goose agent benchmark tests]]></summary>
        <content type="html"><![CDATA[<p><img decoding="async" loading="lazy" alt="blog cover" src="https://block.github.io/goose/assets/images/goose-benchmark-d9726c203290ef892fe3fe3adc7d898f.png" width="1200" height="630" class="img_ev3q"></p>
<p>We've been measuring Goose's performance with various AI models, including a variety of popular open-source models that can run locally on consumer hardware (RTX 4080, Mac M-series). We understand that many in our community value a fully open-source, local experience without relying on cloud services.</p>
<p>This blog shares our findings comparing open-source models against their closed counterparts, highlighting both current performance gaps and paths for future improvement. Our benchmark is still in its early stages, but we wanted to release it as a starting point for distinguishing models that exhibit stronger agentic capabilities by their ability to pilot Goose (distinct from reasoning or other capabilities often captured in other popular benchmarks).</p>
<p>Our evaluations are inspired by grassroots efforts we've seen in communities like <a href="https://www.reddit.com/r/LocalLLaMA/" target="_blank" rel="noopener noreferrer">r/LocalLlama</a>. If you've spent time there, you’ve probably seen enthusiasts crowdsource model performance on standard tasks like "build a flappy bird game" or <a href="https://www.reddit.com/r/LocalLLaMA/comments/1j7r47l/i_just_made_an_animation_of_a_ball_bouncing/" target="_blank" rel="noopener noreferrer">create a rotating hexagon with a bouncing ball</a>" to quickly compare model performance.</p>
<p>These community evals aren't the rigorous, peer-reviewed benchmarks that research labs publish in academic papers. However, they help provide quick, intuitive assessments of capabilities across different models and versions.</p>
<p>In this spirit, we're introducing our <strong>Goose Vibe Check</strong> leaderboard.</p>
<p>Thank you to the Ollama team for their help and support in our experimentation contributing to this blog! We used Ollama’s <a href="https://ollama.com/blog/structured-outputs" target="_blank" rel="noopener noreferrer">structured outputs</a> feature to enable our <a href="https://block.github.io/goose/docs/guides/experimental-features/#ollama-tool-shim" target="_blank" rel="noopener noreferrer">toolshim implementation</a> (more below) and their recently released <a href="https://github.com/ollama/ollama/blob/main/docs/faq.md#how-can-i-specify-the-context-window-size" target="_blank" rel="noopener noreferrer">context length parameter override</a> to enable testing on longer contexts.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="leaderboard">Leaderboard<a href="https://block.github.io/goose/blog/2025/03/31/goose-benchmark#leaderboard" class="hash-link" aria-label="Direct link to Leaderboard" title="Direct link to Leaderboard">​</a></h2>
<table><thead><tr><th>Rank</th><th>Model</th><th>Average Eval Score</th><th>Inference Provider</th></tr></thead><tbody><tr><td>1</td><td>claude-3-5-sonnet-2</td><td>1.00</td><td>databricks (bedrock)</td></tr><tr><td>2</td><td>claude-3-7-sonnet</td><td>0.94</td><td>databricks (bedrock)</td></tr><tr><td>3</td><td>claude-3-5-haiku</td><td>0.91</td><td>databricks (bedrock)</td></tr><tr><td>4</td><td>o1</td><td>0.81</td><td>databricks (bedrock)</td></tr><tr><td>4</td><td>gpt-4o</td><td>0.81</td><td>databricks (bedrock)</td></tr><tr><td>6</td><td>qwen2.5-coder:32b</td><td>0.8</td><td>ollama</td></tr><tr><td>7</td><td>o3-mini</td><td>0.79</td><td>databricks (bedrock)</td></tr><tr><td>8</td><td>qwq</td><td>0.77</td><td>ollama</td></tr><tr><td>9</td><td>gpt-4o-mini</td><td>0.74</td><td>databricks (bedrock)</td></tr><tr><td>10</td><td>deepseek-chat-v3-0324</td><td>0.73</td><td>openrouter</td></tr><tr><td>11</td><td>gpt-4-5-preview</td><td>0.67</td><td>databricks</td></tr><tr><td>12</td><td>qwen2.5:32b</td><td>0.64</td><td>ollama</td></tr><tr><td>13</td><td>qwen2.5:14b</td><td>0.62</td><td>ollama</td></tr><tr><td>14</td><td>qwen2.5-coder:14b</td><td>0.51</td><td>ollama</td></tr><tr><td>15</td><td>deepseek-r1-toolshim-mistral-nemo*</td><td>0.48</td><td>openrouter</td></tr><tr><td>16</td><td>llama3.3:70b-instruct-q4_K_M</td><td>0.47</td><td>ollama</td></tr><tr><td>17</td><td>phi4-toolshim-mistral-nemo*</td><td>0.46</td><td>ollama</td></tr><tr><td>18</td><td>phi4-mistral-nemo</td><td>0.45</td><td>ollama</td></tr><tr><td>19</td><td>gemma3:27b-toolshim-mistral-nemo*</td><td>0.43</td><td>ollama</td></tr><tr><td>20</td><td>deepseek-r1-toolshim-qwen2.5-coder7b*</td><td>0.42</td><td>openrouter</td></tr><tr><td>21</td><td>llama3.3:70b-instruct-q8_0</td><td>0.41</td><td>ollama</td></tr><tr><td>22</td><td>deepseek-r1:14b-toolshim-mistral-nemo*</td><td>0.37</td><td>openrouter</td></tr><tr><td>23</td><td>deepseek-r1-distill-llama-70b-toolshim-mistral-nemo*</td><td>0.36</td><td>ollama</td></tr><tr><td>24</td><td>phi4-toolshim-qwen2.5-coder7b*</td><td>0.3</td><td>ollama</td></tr><tr><td>25</td><td>mistral-nemo</td><td>0.27</td><td>ollama</td></tr><tr><td>26</td><td>deepseek-r1-distill-llama-70b-toolshim-qwen2.5-coder7b*</td><td>0.26</td><td>openrouter</td></tr><tr><td>27</td><td>llama3.2</td><td>0.25</td><td>ollama</td></tr><tr><td>28</td><td>gemma3:27b-toolshim-qwen2.5-coder7b*</td><td>0.24</td><td>ollama</td></tr><tr><td>29</td><td>deepseek-r1:14b-toolshim-qwen2.5-coder7b*</td><td>0.22</td><td>ollama</td></tr><tr><td>29</td><td>gemma3:12b-toolshim-qwen2.5-coder7b*</td><td>0.22</td><td>ollama</td></tr><tr><td>31</td><td>mistral</td><td>0.17</td><td>ollama</td></tr><tr><td>32</td><td>gemma3:12b-toolshim-mistral-nemo*</td><td>0.15</td><td>ollama</td></tr></tbody></table>
<blockquote>
<p><em>Models with 'toolshim' in their name indicate a Goose configuration using both a primary model and a secondary local Ollama model to interpret the primary model's response into appropriate tools for Goose to invoke. Low performance may be indicative of the shim performance rather than the base model itself. We use toolshims for select models because all evaluations in this experiment require tool use capabilities, but not all models in our experiment natively support tool calling.</em></p>
</blockquote>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="open-source-model-details">Open Source Model Details<a href="https://block.github.io/goose/blog/2025/03/31/goose-benchmark#open-source-model-details" class="hash-link" aria-label="Direct link to Open Source Model Details" title="Direct link to Open Source Model Details">​</a></h2>
<table><thead><tr><th>Rank</th><th>Model</th><th>Model Params</th><th>Quantization</th></tr></thead><tbody><tr><td>1</td><td>qwen2.5-coder:32b</td><td>32B</td><td>Q4_K_M</td></tr><tr><td>2</td><td>qwq</td><td>32B</td><td>Q4_K_M</td></tr><tr><td>3</td><td>deepseek-chat-v3-0324</td><td>671B total, 37B active</td><td>-</td></tr><tr><td>4</td><td>qwen2.5:32b</td><td>32B</td><td>Q4_K_M</td></tr><tr><td>5</td><td>qwen2.5:14b</td><td>14B</td><td>Q4_K_M</td></tr><tr><td>6</td><td>qwen2.5-coder:14b</td><td>14B</td><td>Q4_K_M</td></tr><tr><td>7</td><td>deepseek-r1-toolshim-mistral-nemo</td><td>671B total, 37B active</td><td>fp8</td></tr><tr><td>8</td><td>llama3.3:70b-instruct-q4_K_M</td><td>70B</td><td>Q4_K_M</td></tr><tr><td>9</td><td>phi4-toolshim-mistral-nemo</td><td>14B</td><td>Q4_K_M</td></tr><tr><td>10</td><td>phi4-mistral-nemo</td><td>14B</td><td>Q4_K_M</td></tr><tr><td>11</td><td>gemma3:27b-toolshim-mistral-nemo</td><td>27B</td><td>Q4_K_M</td></tr><tr><td>12</td><td>deepseek-r1-toolshim-qwen2.5-coder7b</td><td>671B total, 37B active</td><td>fp8</td></tr><tr><td>13</td><td>llama3.3:70b-instruct-q8_0</td><td>70B</td><td>Q8_0</td></tr><tr><td>14</td><td>deepseek-r1:14b-toolshim-mistral-nemo</td><td>14B</td><td>Q4_K_M</td></tr><tr><td>15</td><td>deepseek-r1-distill-llama-70b-toolshim-mistral-nemo</td><td>70B</td><td>-</td></tr><tr><td>16</td><td>phi4-toolshim-qwen2.5-coder7b</td><td>14B</td><td>Q4_K_M</td></tr><tr><td>17</td><td>mistral-nemo</td><td>12B</td><td>Q4_0</td></tr><tr><td>18</td><td>deepseek-r1-distill-llama-70b-toolshim-qwen2.5-coder7b</td><td>70B</td><td>-</td></tr><tr><td>19</td><td>llama3.2</td><td>3B</td><td>Q4_K_M</td></tr><tr><td>20</td><td>gemma3:27b-toolshim-qwen2.5-coder7b</td><td>27B</td><td>Q4_K_M</td></tr><tr><td>21</td><td>deepseek-r1:14b-toolshim-qwen2.5-coder7b</td><td>14B</td><td>Q4_K_M</td></tr><tr><td>21</td><td>gemma3:12b-toolshim-qwen2.5-coder7b</td><td>12B</td><td>Q4_K_M</td></tr><tr><td>23</td><td>mistral</td><td>7B</td><td>Q8_0</td></tr><tr><td>24</td><td>gemma3:12b-toolshim-mistral-nemo</td><td>12B</td><td>Q4_K_M</td></tr></tbody></table>
<p><img decoding="async" loading="lazy" alt="Open Model Performance by Parameter Size" src="https://block.github.io/goose/assets/images/model_sizes_vs_score-6512491865ea8ed96119245f1f21687e.png" width="5370" height="7171" class="img_ev3q"></p>
<blockquote>
<p><em>This chart presents a view of open model performance across different parameter sizes. In the 15-32B category, we see particularly impressive results from models like qwen2.5-coder:32b (0.80) and qwq (0.77). The chart also highlights the performance gap between models with native tool calling capabilities versus those requiring toolshim implementation (shown with dotted lines), a gap which appears consistent across all size categories. This suggests that native tool calling capabilities significantly impact performance on agentic tasks. With targeted improvements in tool calling capabilities, larger open models could potentially close the performance gap with closed-source alternatives in agentic settings.</em></p>
</blockquote>
<p><img decoding="async" loading="lazy" alt="Token Usage vs Scores" src="https://block.github.io/goose/assets/images/tokens_vs_score-729f597c3ada0924c0c400b17459a3f3.png" width="3569" height="2970" class="img_ev3q"></p>
<blockquote>
<p><em>This scatterplot shows Claude models achieving top scores (0.9+) regardless of token usage, while open source models like qwen2.5-coder:32b perform well with moderate token consumption. Toolshimmed models consistently score lower, suggesting the toolshims are not very effective at closing the gap in native tool support between models. Higher token consumption up to a point appears to generally improve performance.</em></p>
</blockquote>
<p><img decoding="async" loading="lazy" alt="Tool Calls vs Scores" src="https://block.github.io/goose/assets/images/tool_calls_vs_score-bb8723cbd0a4509b1776776fb54ec07b.png" width="3568" height="2970" class="img_ev3q"></p>
<blockquote>
<p><em>Models with either too few or excessive tool calls score lower, indicating effective tool utilization - not just frequency - correlates with improved performance. Toolshimmed models for the most part invoke fewer tool calls, suggesting that the toolshims are not sufficient in their current implementation to make models effective at correctly calling the right tools.</em></p>
</blockquote>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="key-results">Key Results<a href="https://block.github.io/goose/blog/2025/03/31/goose-benchmark#key-results" class="hash-link" aria-label="Direct link to Key Results" title="Direct link to Key Results">​</a></h2>
<ol>
<li>
<p><strong>Closed models currently lead</strong>: Closed source models like Claude and GPT models still generally lead open source alternatives in agentic tasks.</p>
</li>
<li>
<p><strong>Promising open challengers</strong>: Models like the Qwen series and DeepSeek-v3 show significant promise among open source alternatives, but they have not yet reached the consistency and reliability of closed models across all tasks.</p>
</li>
<li>
<p><strong>Token efficiency matters</strong>: Some open models can achieve good performance while using fewer tokens, which can translate to faster task completion times and potentially lower cost. Claude-3-7-sonnet exhibits strong performance alongside claude-3-5-sonnet-2, but at much greater token usage.</p>
</li>
<li>
<p><strong>Tool calling is crucial but not as reliable in open source models today</strong>: Effective tool calling remains a significant differentiator in agentic model performance. Open source models still struggle with generating structured tool calls reliably, limiting their effectiveness on complex tasks.</p>
</li>
<li>
<p><strong>More comprehensive and complex eval tasks are needed to further stratify the top performers:</strong> Our current evaluation suite, consisting of only eight tasks (ran 3x), may be too limited to effectively differentiate top-performing models. Several models clustered around similar scores in the .77-.81 range, likely due to the simplicity of the tasks, which require minimal complex reasoning. Expanding the evaluations to include more sophisticated tasks would provide further stratification and allow the models to better showcase their more or less advanced capabilities.</p>
</li>
</ol>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="approach-and-methodology">Approach and Methodology<a href="https://block.github.io/goose/blog/2025/03/31/goose-benchmark#approach-and-methodology" class="hash-link" aria-label="Direct link to Approach and Methodology" title="Direct link to Approach and Methodology">​</a></h2>
<p>We developed a compact suite of well-scoped evaluations to establish current performance baselines. While the tasks are relatively simple, they already meaningfully stratify model performance. Unlike benchmarks that focus primarily on text generation (e.g., question answering, code generation), our evaluations emphasize <strong>tool calling capabilities</strong> — a core component of what makes Goose a powerful agent.</p>
<p>Tool calling enables models to interact with <a href="https://github.com/modelcontextprotocol/servers" target="_blank" rel="noopener noreferrer">MCP extensions</a> and make API calls, expanding Goose's functionality beyond the base models. In many cases, tasks required multiple chained tool calls to reach completion. For instance, modifying a file involves finding it in your filesystem, viewing its contents, and then updating it. Each step must be executed correctly to complete the task effectively.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="evaluation-suites">Evaluation Suites<a href="https://block.github.io/goose/blog/2025/03/31/goose-benchmark#evaluation-suites" class="hash-link" aria-label="Direct link to Evaluation Suites" title="Direct link to Evaluation Suites">​</a></h3>
<p>Our evaluations are defined in the <a href="https://github.com/block/goose/tree/main/crates/goose-bench/src/eval_suites" target="_blank" rel="noopener noreferrer">Goose repository</a> (PRs welcome to add additional evals!) and are grouped into two categories:</p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="core-suite">Core Suite<a href="https://block.github.io/goose/blog/2025/03/31/goose-benchmark#core-suite" class="hash-link" aria-label="Direct link to Core Suite" title="Direct link to Core Suite">​</a></h4>
<p>These evals focus on certain tasks fundamental to developer workflows:</p>
<ul>
<li><strong>Create a file</strong>: Generate and save a new file</li>
<li><strong>List files</strong>: Access and display directory contents</li>
<li><strong>Developer Search/Replace</strong>: Search through a large file and make several replacements</li>
</ul>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="vibes-suite">Vibes Suite<a href="https://block.github.io/goose/blog/2025/03/31/goose-benchmark#vibes-suite" class="hash-link" aria-label="Direct link to Vibes Suite" title="Direct link to Vibes Suite">​</a></h4>
<p>Designed as a "vibe check", these tasks quickly reveal how well models perform with Goose on a broad variety of tasks. Some, like the Flappy Bird and Goose Wiki tasks are straightforwardly visually inspectable, making it easy to eyeball outputs across models:</p>
<ul>
<li><strong>Blog summary</strong>: Fetch a blog post and summarize key points</li>
<li><strong>Flappy Bird</strong>: Implement the game in Python 2D</li>
<li><strong>Goose Wiki</strong>: Create a Wikipedia-style webpage about Goose</li>
<li><strong>Restaurant research</strong>: Search for the best Sichuanese restaurants in NYC's East Village</li>
<li><strong>Squirrel census</strong>: Perform data analysis on a CSV file</li>
</ul>
<p>This initial set of evaluations represents a carefully curated selection of manually designed tasks, chosen to highlight key strengths and weaknesses of models when integrated with Goose. However, this is just the beginning! Our goal is to continuously expand the Goosebench evaluation suite with high-quality, targeted tasks that provide deeper insights into model performance with Goose.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="evaluation-methodology">Evaluation Methodology<a href="https://block.github.io/goose/blog/2025/03/31/goose-benchmark#evaluation-methodology" class="hash-link" aria-label="Direct link to Evaluation Methodology" title="Direct link to Evaluation Methodology">​</a></h3>
<p>Each model was tested on the above <strong>8 tasks, with 3 runs per task</strong>, (totaling <strong>24 runs per model</strong>):</p>
<ul>
<li>Each evaluation consisted of a single turn prompt to Goose. While this benchmark focuses on single turn execution, future evaluations may assess multi-turn interactions and iterative improvement</li>
<li>Goose was required to autonomously complete the task using tool execution loops without user intervention</li>
<li>If Goose halted execution and asked the user for more guidance (e.g., "I am going to write the following contents to the file. Should I continue?"), this was considered the end of task completion. In such cases, Goose may not have successfully completed the task as measured by our evaluation framework, even if it was on the right track.</li>
<li>To account for output variability, each evaluation was run three times per model, allowing multiple chances for success.</li>
</ul>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="scoring-and-evaluation-criteria">Scoring and Evaluation Criteria<a href="https://block.github.io/goose/blog/2025/03/31/goose-benchmark#scoring-and-evaluation-criteria" class="hash-link" aria-label="Direct link to Scoring and Evaluation Criteria" title="Direct link to Scoring and Evaluation Criteria">​</a></h3>
<p>We calculate each model's leaderboard score by averaging its performance across all evaluation tasks. For each task, we run the model three times and normalize each run's score to a 0-1 scale. The model's task score is the average of these three runs. The final leaderboard score is the average of all task scores for that model.</p>
<p>Each evaluation is scored on a mix of criteria tailored to the specific task:</p>
<ol>
<li>
<p><strong>Tool Call Execution</strong>: Did the model make the correct tool calls to complete the task?</p>
</li>
<li>
<p><strong>LLM as a Judge</strong> (where applicable): Some evaluations used GPT-4o to assess response quality on a 0-2 scale. In these cases, we generated 3 GPT-4o assessments, took the most common score among them, and ran a fourth assessment if needed to break a tie to get the final score.</p>
<ul>
<li>0 points: Incorrect or fundamentally flawed</li>
<li>1 point: Partially correct, but with issues</li>
<li>2 points: Fully correct and well executed</li>
</ul>
</li>
<li>
<p><strong>Task Specific Criteria</strong>: Different tasks required different checks, such as:</p>
<ul>
<li>Correct output formatting (e.g., markdown, output to file)</li>
<li>Expected answers (e.g., correct insights in data analysis)</li>
<li>Valid implementation (e.g., valid Python code)</li>
</ul>
</li>
</ol>
<p>Some evaluations, like code execution or file creation, have clear pass/fail criteria, similar to unit tests. Others, such as blog summarization or restaurant research, require qualitative judgment rather than strict correctness. To assess both objective and open-ended tasks, we combine task-specific criteria, tool call verification, and (where applicable) LLM as a judge scoring.</p>
<p>To assess both objective and open-ended tasks, we combine task-specific criteria, tool call verification, and (where applicable) LLM-as-a-judge scoring. This approach maintains rigor where correctness is well-defined while allowing for nuanced evaluation of subjective outputs.</p>
<p>Our goal is to provide a directional signal of model performance rather than absolute accuracy, balancing concrete and qualitative criteria.</p>
<p>Additionally, we tracked:</p>
<ol>
<li>
<p><strong>Token Efficiency</strong>: Measures total tokens used in successful runs, providing insight into model efficiency and inference speed.</p>
</li>
<li>
<p><strong>Duration</strong>: Time to execute the task. This is not reflected in the leaderboard as it is significantly affected by differences across model inference providers and hardware.</p>
</li>
</ol>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="manual-inspection-and-observations-of-results">Manual Inspection and Observations of Results<a href="https://block.github.io/goose/blog/2025/03/31/goose-benchmark#manual-inspection-and-observations-of-results" class="hash-link" aria-label="Direct link to Manual Inspection and Observations of Results" title="Direct link to Manual Inspection and Observations of Results">​</a></h3>
<p>We manually inspected a handful of results to assess quality. Given the scale (768 total runs across 32 models), full manual validation of every evaluation run was infeasible. Key takeaways from our inspections:</p>
<ul>
<li>
<p>LLM-as-a-judge was reliable at identifying fully incorrect answers (0 points), but distinguishing between 1 and 2 points was more subjective.</p>
</li>
<li>
<p>Some tasks (e.g., blog summarization, restaurant searches) lacked automated factual verification. The evaluation framework could confirm whether a tool was called (e.g., web search executed) and the LLM judge could assess the instruction following to some degree, but our system overall had no way of verifying if the responses were factually correct.</p>
</li>
<li>
<p>Tool execution failures were a key source of performance variation, highlighting the importance of agentic capabilities in real-world AI tasks. A model might generate the correct output in chat, but if it fails to subsequently execute the right tools—such as writing the output to the right file as instructed by the user—the task is incomplete. This underscores the need for models to reliably perform multi-step actions autonomously, not just generate accurate responses.</p>
</li>
</ul>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="technical-challenges-with-open-models">Technical Challenges with Open Models<a href="https://block.github.io/goose/blog/2025/03/31/goose-benchmark#technical-challenges-with-open-models" class="hash-link" aria-label="Direct link to Technical Challenges with Open Models" title="Direct link to Technical Challenges with Open Models">​</a></h2>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="context-length-limitations">Context Length Limitations<a href="https://block.github.io/goose/blog/2025/03/31/goose-benchmark#context-length-limitations" class="hash-link" aria-label="Direct link to Context Length Limitations" title="Direct link to Context Length Limitations">​</a></h3>
<p>A key limitation we encountered early on in our experimentation was the default context length in Ollama's OpenAI-compatible endpoint (2048 tokens), which proved insufficient for most interactive agent scenarios.</p>
<p>Our system prompt alone consumes about 1,000 tokens, leaving limited space for user queries, context, and tool responses. This restriction hampers the model's ability to manage long-running or complex tasks without losing essential context. While quantization (e.g., many Ollama models default to 4-bit) can reduce memory usage, it can also degrade performance.</p>
<p>However, we did not extensively explore the impact of different quantization levels. Fortunately, during our work, Ollama introduced an override that allowed us to increase the context length, helping to mitigate this limitation in our experiments.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="tool-calling-inconsistencies-across-models">Tool Calling Inconsistencies Across Models<a href="https://block.github.io/goose/blog/2025/03/31/goose-benchmark#tool-calling-inconsistencies-across-models" class="hash-link" aria-label="Direct link to Tool Calling Inconsistencies Across Models" title="Direct link to Tool Calling Inconsistencies Across Models">​</a></h3>
<p>Different models have varying expectations for tool calling formats. For instance, Ollama requires JSON, while others like Functionary use XML. This lack of standardization poses integration challenges for inference providers, who must adapt the tool calling mechanisms for each model.</p>
<p>We observed performance fluctuations based on the model host and input/output formatting, highlighting the need for standardized tool calling formats in model training.
For models without native tool calling capabilities, we developed a "toolshim"—an interpretive layer that translates a model's output into the appropriate tool calls.</p>
<p>This approach enables models like DeepSeek and Gemma to perform basic tool actions, though performance remains limited. None of the models configured with the toolshim greater than a 41% success rate in our experiments. Future improvements may focus on fine-tuning these shims for better handling of agentic tasks, helping to reduce inconsistencies across models in tool call generation.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="toolshims-to-bridge-the-gap">“Toolshims” to bridge the gap?<a href="https://block.github.io/goose/blog/2025/03/31/goose-benchmark#toolshims-to-bridge-the-gap" class="hash-link" aria-label="Direct link to “Toolshims” to bridge the gap?" title="Direct link to “Toolshims” to bridge the gap?">​</a></h3>
<p>We developed a "toolshim" as an experimental feature to enable models lacking native tool calling support (e.g., DeepSeek, Gemma3, Phi4) to interact with external tools. The toolshim pairs these models with a smaller, local model (e.g., mistral-nemo, qwen2.5-coder 7b), which is tasked with translating the primary model’s natural language responses into the appropriate tool calls for Goose to invoke. The local model is guided by Ollama’s structured outputs feature to enforce proper formatting for tool call generations.</p>
<p>However, this solution has limited performance due to:</p>
<ul>
<li>
<p><strong>Instruction-following limitations:</strong> The smaller models used typically have less robust instruction-following ability especially for longer inputs, making them prone to inaccuracies when parsing the primary model's output into the correct tool calls. We also found the shim models to be quite sensitive to prompting.</p>
</li>
<li>
<p><strong>Structured output interference:</strong> Ollama’s structured output feature influences the model’s token sampling process, where the output is impacted by the model’s fundamental ability to extract information and generate JSON appropriately.</p>
</li>
</ul>
<p>Despite these challenges, there could be potential in fine-tuning these toolshim models to specifically optimize them for tool call generation.
If you’d like to try out the toolshim, check out our <a href="https://block.github.io/goose/docs/guides/experimental-features" target="_blank" rel="noopener noreferrer">documentation</a></p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="practical-advice-for-local-model-users">Practical Advice for Local Model Users<a href="https://block.github.io/goose/blog/2025/03/31/goose-benchmark#practical-advice-for-local-model-users" class="hash-link" aria-label="Direct link to Practical Advice for Local Model Users" title="Direct link to Practical Advice for Local Model Users">​</a></h2>
<p>For those running a local, open-source AI experience with Goose, here are some key recommendations based on our testing:</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="optimize-context-length">Optimize Context Length<a href="https://block.github.io/goose/blog/2025/03/31/goose-benchmark#optimize-context-length" class="hash-link" aria-label="Direct link to Optimize Context Length" title="Direct link to Optimize Context Length">​</a></h3>
<p>Ensure your model has enough context length to avoid running out of space in the context window. For Ollama, you can adjust the context length via an environment variable:</p>
<div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">OLLAMA_CONTEXT_LENGTH=28672 ollama serve</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>You can also set the context length as a parameter in Ollama by updating the Modlfile with your desired context length and running <code>ollama create</code>.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="be-aware-of-quantization-levels">Be Aware of Quantization Levels<a href="https://block.github.io/goose/blog/2025/03/31/goose-benchmark#be-aware-of-quantization-levels" class="hash-link" aria-label="Direct link to Be Aware of Quantization Levels" title="Direct link to Be Aware of Quantization Levels">​</a></h3>
<p>Different quantization levels (4-bit, 8-bit, and 16-bit) have distinct impacts on performance:</p>
<ul>
<li><strong>4-bit:</strong> Offers maximum compression with minimal memory requirements but may degrade quality.</li>
<li><strong>8-bit:</strong> A balanced option for most consumer hardware, providing good performance and reasonable quality.</li>
<li><strong>16-bit:</strong> Higher quality but requires significantly more memory, which may limit performance on lower-end hardware.</li>
</ul>
<p>Ollama defaults to 4-bit quantization in most cases, but for tasks requiring more complex reasoning or tool usage, testing with higher quantization levels (e.g., 8-bit) may improve performance.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="prompting-matters-for-smaller-models">Prompting Matters for Smaller Models<a href="https://block.github.io/goose/blog/2025/03/31/goose-benchmark#prompting-matters-for-smaller-models" class="hash-link" aria-label="Direct link to Prompting Matters for Smaller Models" title="Direct link to Prompting Matters for Smaller Models">​</a></h3>
<p>Smaller models are more sensitive to prompt variations and often require more explicit instructions due to their limited capacity to infer. To achieve optimal performance, tasks may need to be broken down further, reducing ambiguity and limiting the range of possible responses.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="hardware-considerations">Hardware Considerations<a href="https://block.github.io/goose/blog/2025/03/31/goose-benchmark#hardware-considerations" class="hash-link" aria-label="Direct link to Hardware Considerations" title="Direct link to Hardware Considerations">​</a></h3>
<p>We ran these models with a variety of inference providers (local and hosted) and hardware configurations including Apple M1, NVIDIA RTX 4080, NVIDIA RTX 4090, and NVIDIA H100. Due to the mix of hardware, we did not include measurements of task duration in the benchmark given the expected variability in inference performance driven by the underlying hardware.</p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="gpu-backends">GPU Backends<a href="https://block.github.io/goose/blog/2025/03/31/goose-benchmark#gpu-backends" class="hash-link" aria-label="Direct link to GPU Backends" title="Direct link to GPU Backends">​</a></h4>
<p>Depending on your hardware, different GPU acceleration backends offer varying levels of performance:</p>
<ul>
<li>
<p><strong>CUDA (NVIDIA GPUs)</strong>: Currently offers the best performance and compatibility for running LLMs locally. Most open models and inference frameworks are optimized for CUDA first.</p>
</li>
<li>
<p><strong>Metal (Apple Silicon)</strong>: Provides good acceleration on Mac devices with M-series chips. While not as fast as high-end NVIDIA GPUs, recent optimization work has made Metal increasingly viable for running 7B-13B models.</p>
</li>
<li>
<p><strong>ROCm (AMD GPUs)</strong>: Support is improving but still lags behind CUDA. If you have a compatible AMD GPU, you may expect to see some performance limitations and compatibility issues with certain models and quantization methods.</p>
</li>
</ul>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="cpugpu-memory-management">CPU/GPU Memory Management<a href="https://block.github.io/goose/blog/2025/03/31/goose-benchmark#cpugpu-memory-management" class="hash-link" aria-label="Direct link to CPU/GPU Memory Management" title="Direct link to CPU/GPU Memory Management">​</a></h4>
<p>Ollama helps distribute model layers across CPU and GPU memory, allowing you to run larger models than would fit entirely in your GPU VRAM. However, be aware of:</p>
<ul>
<li><strong>Data movement overhead</strong>: When a model doesn't fit entirely in GPU memory, constant data movement between CPU and GPU can significantly impact performance</li>
<li><strong>GPU utilization</strong>: Models that fit entirely in GPU memory will perform dramatically better than those that require CPU offloading</li>
</ul>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="considering-cloud-hosted-open-models">Considering Cloud-Hosted Open Models?<a href="https://block.github.io/goose/blog/2025/03/31/goose-benchmark#considering-cloud-hosted-open-models" class="hash-link" aria-label="Direct link to Considering Cloud-Hosted Open Models?" title="Direct link to Considering Cloud-Hosted Open Models?">​</a></h3>
<p>If using a cloud service like OpenRouter to try larger open-weight models (e.g., LLaMA 3 70B or Qwen), be aware that performance may vary depending on which hosted inference provider you're using.</p>
<p>Different providers might:</p>
<ul>
<li>Quantize models on the backend without clear disclosure</li>
<li>Implement different integration patterns that affect model performance, especially with tool calling</li>
<li>Have different hardware configurations affecting speed and reliability</li>
</ul>
<p>We recommend experimenting with different hosted inference providers to see which works best for your specific use cases. OpenRouter for example lets you <a href="https://openrouter.ai/docs/features/provider-routing" target="_blank" rel="noopener noreferrer">specify the provider</a> you want to route your requests to.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="run-your-own-benchmarks">Run Your Own Benchmarks<a href="https://block.github.io/goose/blog/2025/03/31/goose-benchmark#run-your-own-benchmarks" class="hash-link" aria-label="Direct link to Run Your Own Benchmarks" title="Direct link to Run Your Own Benchmarks">​</a></h2>
<p>We encourage the community to conduct their own benchmarks with various hardware setups and configurations to help deepen our understanding of how Goose performs across different setups. We also welcome contributions of additional evals to GooseBench to broaden our coverage.</p>
<p>We are currently cleaning up our code and  working on some quality of life improvements to make the process of running evals and reproducing these results more streamlined, and will share those when ready (next few weeks)!</p>
<p>Special thanks to our contributors, Zaki and Marcelle, for their work on GooseBench, which enabled this experimentation.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="future-work">Future Work<a href="https://block.github.io/goose/blog/2025/03/31/goose-benchmark#future-work" class="hash-link" aria-label="Direct link to Future Work" title="Direct link to Future Work">​</a></h2>
<p>As AI capabilities continue to evolve, we aim to systematically expand our evaluation framework to capture a broader range of use cases. We hope to benchmark models on a wider swath of consumer-grade hardware to better understand system requirements, execution times, and the impact of different quantization levels on performance.</p>
<p>We also plan to introduce vision-oriented evaluations, particularly for multimodal models with Goose. These will assess image processing, multimodal reasoning, and visual tool interactions, helping us measure how well models integrate and perform across different modalities.</p>
<p>In addition, we seek to develop evaluations tailored to non-developer workflows and tasks. This will provide insights into how Goose and AI models can serve a wider range of users beyond technical audiences.</p>
<p>Finally, we see value in testing long-context retention and multi-turn interactions to evaluate model performance in complex, sustained conversations.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="result-eval-examples">Result Eval Examples<a href="https://block.github.io/goose/blog/2025/03/31/goose-benchmark#result-eval-examples" class="hash-link" aria-label="Direct link to Result Eval Examples" title="Direct link to Result Eval Examples">​</a></h2>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="flappy-bird">Flappy Bird<a href="https://block.github.io/goose/blog/2025/03/31/goose-benchmark#flappy-bird" class="hash-link" aria-label="Direct link to Flappy Bird" title="Direct link to Flappy Bird">​</a></h3>
<p>For runs that successfully created a working flappy bird game with pygame, here are the gifs of playing the games:</p>
<div class="carousel-container"><h3 class="carousel-header">claude-3-5-haiku</h3><div class="swiper swiper-container-flappy" style="width:40%"><div class="swiper-wrapper"><div class="swiper-slide"><img src="https://block.github.io/goose/assets/images/claude-3-5-haiku-ff0b0347d5aec59efab98769039f7063.gif" alt="Slide 1" class="carousel-image"></div><div class="swiper-slide"><img src="https://block.github.io/goose/assets/images/claude-3-5-sonnet-2-b445a205684b5c7bd674d744b92cc4ea.gif" alt="Slide 2" class="carousel-image"></div><div class="swiper-slide"><img src="https://block.github.io/goose/assets/images/claude-3-7-sonnet-a11804cddf505cec1df78ca8315c8257.gif" alt="Slide 3" class="carousel-image"></div><div class="swiper-slide"><img src="https://block.github.io/goose/assets/images/deepseek-chat-v3-0324-01d4dec7f79311b593ac04fbba9f93ef.gif" alt="Slide 4" class="carousel-image"></div><div class="swiper-slide"><img src="https://block.github.io/goose/assets/images/deepseek-r1-toolshim-mistral-nemo-bf4bd9d06ff57563ae2762d047ccb1c7.gif" alt="Slide 5" class="carousel-image"></div><div class="swiper-slide"><img src="https://block.github.io/goose/assets/images/gpt-4-5-preview-1cd4983ce3ceafaf22b12dff95ed4ad1.gif" alt="Slide 6" class="carousel-image"></div><div class="swiper-slide"><img src="https://block.github.io/goose/assets/images/gpt-4o-mini-9e4478259ad6e3e4353394c0b3f19126.gif" alt="Slide 7" class="carousel-image"></div><div class="swiper-slide"><img src="https://block.github.io/goose/assets/images/gpt-4o-cbdbf0c788605e797fb8f4ea9b987b8c.gif" alt="Slide 8" class="carousel-image"></div><div class="swiper-slide"><img src="https://block.github.io/goose/assets/images/o1-134e3913d813a9e797e979c42a92fa3f.gif" alt="Slide 9" class="carousel-image"></div><div class="swiper-slide"><img src="https://block.github.io/goose/assets/images/o3-mini-7a869a80bf99f27dd7454830ae309184.gif" alt="Slide 10" class="carousel-image"></div><div class="swiper-slide"><img src="https://block.github.io/goose/assets/images/qwen2.5-coder-32b-ceca4ac06aaf0f42f3d6b65363c60e3e.gif" alt="Slide 11" class="carousel-image"></div><div class="swiper-slide"><img src="https://block.github.io/goose/assets/images/qwq-3a05f474ec77049ba53a0439b36df0ba.gif" alt="Slide 12" class="carousel-image"></div></div><div class="swiper-button-prev"></div><div class="swiper-button-next"></div><div class="swiper-pagination"></div></div></div>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="wiki-pages">Wiki Pages<a href="https://block.github.io/goose/blog/2025/03/31/goose-benchmark#wiki-pages" class="hash-link" aria-label="Direct link to Wiki Pages" title="Direct link to Wiki Pages">​</a></h3>
<p>For runs that successfully created an index.html for the Wiki page task, here’s what the rendered outputs look like: Wiki pages Missing results are for models that did not successfully write to an index.html file. For example, they may have outputted the code to write in chat and asked the user to implement that code in an index.html file rather than written to the file themselves.</p>
<div class="carousel-container"><h3 class="carousel-header">gemma3.27b-toolshim-mistral-nemo</h3><div class="swiper swiper-container-wiki" style="width:80%"><div class="swiper-wrapper"><div class="swiper-slide"><img src="https://block.github.io/goose/assets/images/gemma3.27b-toolshim-mistral-nemo-ee63d6bc421659fa3501a447f8c46426.png" alt="Slide 1" class="carousel-image"></div><div class="swiper-slide"><img src="https://block.github.io/goose/assets/images/claude-3.5-haiku-71f1ce5faa13846a556ba539c57caae8.png" alt="Slide 2" class="carousel-image"></div><div class="swiper-slide"><img src="https://block.github.io/goose/assets/images/claude-3.5-sonnet-2-2c683339b1e4880de5ce5aa435304a5a.png" alt="Slide 3" class="carousel-image"></div><div class="swiper-slide"><img src="https://block.github.io/goose/assets/images/claude-3.7-sonnet-6042d99d5829957f3fd471d44ff2ea26.png" alt="Slide 4" class="carousel-image"></div><div class="swiper-slide"><img src="https://block.github.io/goose/assets/images/deepseek-chat-v3-0324-879b3ea78b30ff135607365fd77eeebe.png" alt="Slide 5" class="carousel-image"></div><div class="swiper-slide"><img src="https://block.github.io/goose/assets/images/deepseek-r1-distill-llama-70b-toolshim-mistral-nemo-bfd7f9d3f37a92aaae6c7afb74b52d91.png" alt="Slide 6" class="carousel-image"></div><div class="swiper-slide"><img src="https://block.github.io/goose/assets/images/gpt-4.5-preview-99cafaf409ffbc47a8186ed0a5c05043.png" alt="Slide 7" class="carousel-image"></div><div class="swiper-slide"><img src="https://block.github.io/goose/assets/images/gpt-4o-mini-37fbaf84ea5c2d7d57a9b4e7ddf4fb3b.png" alt="Slide 8" class="carousel-image"></div><div class="swiper-slide"><img src="https://block.github.io/goose/assets/images/gpt-4o-8b238b9d92ca62e7480ab6f12faeedfa.png" alt="Slide 9" class="carousel-image"></div><div class="swiper-slide"><img src="https://block.github.io/goose/assets/images/llama3.3.70b-instruct-q4_K_M-91e7e0436dd5b7530fc18ff39366369d.png" alt="Slide 10" class="carousel-image"></div><div class="swiper-slide"><img src="https://block.github.io/goose/assets/images/llama3.3.70b-instruct-q8_0-9477c2fcd3abc509fa4855d9633be812.png" alt="Slide 11" class="carousel-image"></div><div class="swiper-slide"><img src="https://block.github.io/goose/assets/images/mistral-nemo_index-4866f9a20a1294585adef2dc4fbc4ade.png" alt="Slide 12" class="carousel-image"></div><div class="swiper-slide"><img src="https://block.github.io/goose/assets/images/o1-9a41312ec15fa512b13f215c94dc1335.png" alt="Slide 13" class="carousel-image"></div><div class="swiper-slide"><img src="https://block.github.io/goose/assets/images/o3-mini-0da4fd28bcb174906ff6b2664c08e88d.png" alt="Slide 14" class="carousel-image"></div><div class="swiper-slide"><img src="https://block.github.io/goose/assets/images/phi4-toolshim-mistral-nemo-db0e5f6075b793b2b6facfa483fc9a5d.png" alt="Slide 15" class="carousel-image"></div><div class="swiper-slide"><img src="https://block.github.io/goose/assets/images/phi4-toolshim-qwen2.5-coder7b-632ebfc62d7e69db76bc030235990574.png" alt="Slide 16" class="carousel-image"></div><div class="swiper-slide"><img src="https://block.github.io/goose/assets/images/qwen2.5-coder.14b-dfb90e9a247737df599d7736e982fa64.png" alt="Slide 17" class="carousel-image"></div><div class="swiper-slide"><img src="https://block.github.io/goose/assets/images/qwen2.5-coder.32b-e540b5187a35326045a1810070188b68.png" alt="Slide 18" class="carousel-image"></div><div class="swiper-slide"><img src="https://block.github.io/goose/assets/images/qwen2.5.14b-5f613200d90cb8f8e5242cefab130ed2.png" alt="Slide 19" class="carousel-image"></div><div class="swiper-slide"><img src="https://block.github.io/goose/assets/images/qwen2.5.32b-cf589a3b4494e4f75a63f3b7c8f13923.png" alt="Slide 20" class="carousel-image"></div><div class="swiper-slide"><img src="https://block.github.io/goose/assets/images/qwq-2df978b1c23d170ed2bf2d2caf5c3ecd.png" alt="Slide 21" class="carousel-image"></div></div><div class="swiper-button-prev"></div><div class="swiper-button-next"></div><div class="swiper-pagination"></div></div></div>
]]></content>
        <author>
            <name>Alice Hau</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Securing the Model Context Protocol]]></title>
        <id>https://block.github.io/goose/blog/2025/03/31/securing-mcp</id>
        <link href="https://block.github.io/goose/blog/2025/03/31/securing-mcp"/>
        <updated>2025-03-31T00:00:00.000Z</updated>
        <summary type="html"><![CDATA[Building secure and capable AI integrations with Model Context Protocol (MCP) at Block.]]></summary>
        <content type="html"><![CDATA[<p><img decoding="async" loading="lazy" alt="blog cover" src="https://block.github.io/goose/assets/images/securing-mcp-5e475e91c0e621afa33e30b3d89ef065.png" width="1200" height="630" class="img_ev3q"></p>
<blockquote>
<p><em><strong>Authors:</strong> Alex Rosenzweig, Arihant Virulkar, Andrea Leoszko, Wes Ring, Mike Shema, F G, Alex Klyubin, Michael Rand, Zhen Lian, Angie Jones, Douwe Osinga, Mic Neale, Bradley Axen, Gelareh Taban</em></p>
</blockquote>
<p>At Block, we’ve been working hard to augment the capabilities of AI tooling by building "MCP Servers" which are designed to help make our Artificial Intelligence (AI) Agent codename goose more capable of interacting with the systems and tools we care about.</p>
<p>Block’s Information Security (InfoSec) team has been heavily involved in this work and we wanted to capture our learnings in the space to help others. We expect there to be growing adoption and use cases for this including applying the technology in the security domain.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="what-is-the-model-context-protocol-mcp">What is the Model Context Protocol (MCP)<a href="https://block.github.io/goose/blog/2025/03/31/securing-mcp#what-is-the-model-context-protocol-mcp" class="hash-link" aria-label="Direct link to What is the Model Context Protocol (MCP)" title="Direct link to What is the Model Context Protocol (MCP)">​</a></h2>
<p>Model Context Protocol (MCP) is a protocol <a href="https://docs.anthropic.com/en/docs/agents-and-tools/mcp" target="_blank" rel="noopener noreferrer">developed by Anthropic</a>, with input from Block engineers, that makes it easier to build integrations for agents to connect and use other tooling. Put simply, if you want AI to connect to SaaS solutions (e.g. Github, Jira),  CLI tools (e.g. AWS CLI) or your own custom applications you can write an MCP server and "teach" it how to correctly interact.</p>
<p>This has huge advantages as we can create deterministic, well defined interfaces that reduce the amount of "experimentation/brute force" required for agents to perform helpful tasks.</p>
<p>A use case like "read this ticket from Jira and then clone the relevant github repo and implement the feature" is more likely to succeed if the agent doesn’t have to work out how to interact with Jira, Github and the Git CLI.</p>
<p>This helps agents to spend time solving novel problems rather than burning tokens understanding well defined API specifications.</p>
<p>The following is example code from an MCP tool that integrates with an Snowflake API.</p>
<div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token decorator annotation punctuation" style="color:#393A34">@mcp</span><span class="token decorator annotation punctuation" style="color:#393A34">.</span><span class="token decorator annotation punctuation" style="color:#393A34">tool</span><span class="token punctuation" style="color:#393A34">(</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token keyword" style="color:#00009f">async</span><span class="token plain"> </span><span class="token keyword" style="color:#00009f">def</span><span class="token plain"> </span><span class="token function" style="color:#d73a49">submit_feedback</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    feedback</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token builtin">str</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"> </span><span class="token operator" style="color:#393A34">-</span><span class="token operator" style="color:#393A34">&gt;</span><span class="token plain"> Dict</span><span class="token punctuation" style="color:#393A34">[</span><span class="token builtin">str</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> Union</span><span class="token punctuation" style="color:#393A34">[</span><span class="token builtin">str</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> </span><span class="token builtin">int</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> List</span><span class="token punctuation" style="color:#393A34">]</span><span class="token punctuation" style="color:#393A34">]</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token triple-quoted-string string" style="color:#e3116c">"""Submit feedback to the Snowflake team.</span><br></span><span class="token-line" style="color:#393A34"><span class="token triple-quoted-string string" style="display:inline-block;color:#e3116c"></span><br></span><span class="token-line" style="color:#393A34"><span class="token triple-quoted-string string" style="color:#e3116c">    Args:</span><br></span><span class="token-line" style="color:#393A34"><span class="token triple-quoted-string string" style="color:#e3116c">        feedback: Feedback message</span><br></span><span class="token-line" style="color:#393A34"><span class="token triple-quoted-string string" style="display:inline-block;color:#e3116c"></span><br></span><span class="token-line" style="color:#393A34"><span class="token triple-quoted-string string" style="color:#e3116c">    Returns:</span><br></span><span class="token-line" style="color:#393A34"><span class="token triple-quoted-string string" style="color:#e3116c">        Dictionary containing feedback status</span><br></span><span class="token-line" style="color:#393A34"><span class="token triple-quoted-string string" style="color:#e3116c">    """</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token keyword" style="color:#00009f">return</span><span class="token plain"> snowflake_client</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">submit_feedback</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        feedback_text</span><span class="token operator" style="color:#393A34">=</span><span class="token plain">feedback</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token punctuation" style="color:#393A34">)</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="mcp-misconceptions">MCP Misconceptions<a href="https://block.github.io/goose/blog/2025/03/31/securing-mcp#mcp-misconceptions" class="hash-link" aria-label="Direct link to MCP Misconceptions" title="Direct link to MCP Misconceptions">​</a></h2>
<p>There are some minor misconceptions around MCP, which is understandably exacerbated by some of the verbiage not accurately aligning with more analogous technologies. The biggest point of confusion is the terminology of "MCP Servers".</p>
<p>Upon initially reviewing MCP, I noticed multiple references to "MCP Servers," which led me to believe that integrating with them would require modifications to the application backend.</p>
<p>However, these "servers" act as a client layer (either locally or remotely) to help the agent proxy function calls to an existing service, tool, API or RPC in a deterministic manner.</p>
<p>When securing an MCP integration we need to think about two sets of communications:</p>
<ul>
<li>How does the agent talk to the MCP Server?</li>
<li>How does the MCP Server act as a client for the system it connects to?</li>
</ul>
<p>We can model this by:</p>
<ul>
<li>Treating the Agent as a non-deterministic client that can arbitrarily call tools provided by the MCP server. This is due to the fact that we don’t know what prompts it will be provided.</li>
<li>Treating the MCP Server as a Client Library for the utility/utilities it integrates into. The client type can vary (gRPC, REST, SOAP, CLI, etc.) but in practice, MCPs simply provide a codified way to execute an action.</li>
</ul>
<p>For the former, we can lean into existing practices, understand the scope of access and what risks they present if used inappropriately.</p>
<p>For the latter, we can directly model it as a client for an external provider. This is a well understood pattern as client library generation is in no way new.</p>
<p><img decoding="async" loading="lazy" alt="MCP Workflow" src="https://block.github.io/goose/assets/images/mcp-workflow-9ef765371217ef59184cfddbbede89a4.png" width="1600" height="705" class="img_ev3q"></p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="how-do-we-approach-making-it-secure">How do we approach making it secure?<a href="https://block.github.io/goose/blog/2025/03/31/securing-mcp#how-do-we-approach-making-it-secure" class="hash-link" aria-label="Direct link to How do we approach making it secure?" title="Direct link to How do we approach making it secure?">​</a></h2>
<p>Using this mental model we can break MCP security into a few components:</p>
<ul>
<li>Secure the Agents communication to the MCP</li>
<li>Secure the MCPs connectivity to the tool/server</li>
<li>Secure the identity of the user and the agent when talking to servers</li>
<li>Secure the underlying host and supply chain</li>
</ul>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="securing-agentic-communications-to-mcp-servers">Securing Agentic Communications to MCP Servers<a href="https://block.github.io/goose/blog/2025/03/31/securing-mcp#securing-agentic-communications-to-mcp-servers" class="hash-link" aria-label="Direct link to Securing Agentic Communications to MCP Servers" title="Direct link to Securing Agentic Communications to MCP Servers">​</a></h3>
<p>In the current operating model both the Agent and the MCP Server run on the "client side".</p>
<p>However, the majority of agentic tools are integrated with LLMs provided by third parties. This has implications for data privacy and security.</p>
<p>For example if you expose an MCP interface that returns confidential data like Social Security Numbers (<a href="https://code.cash.app/dsl-framework" target="_blank" rel="noopener noreferrer">what we at Block call DSL4 data</a>) then you run the risk of that data being exposed to the underlying LLM provider.</p>
<p>A mitigation here is allowing MCP implementation to specify an allowlist of LLM providers that it can be integrated with as a configuration option. Having utilities to "tell" agents that can integrate with multiple models which models are allowed to invoke a given tool is a powerful primitive.</p>
<p>Back to our SSN example, if we could specify that this tool can only be invoked by local LLM models and trust the Agent Client to enforce this we could prevent sensitive data from being transmitted to third party LLMs. As a further enhancement, being able to instruct agents not to share tool output with other MCPs would provide further control of dataflow.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="securing-mcp-communications-to-toolingservers">Securing MCP Communications to Tooling/Servers<a href="https://block.github.io/goose/blog/2025/03/31/securing-mcp#securing-mcp-communications-to-toolingservers" class="hash-link" aria-label="Direct link to Securing MCP Communications to Tooling/Servers" title="Direct link to Securing MCP Communications to Tooling/Servers">​</a></h3>
<p>This paradigm actually isn’t new and we can lean into existing best practices for externally facing APIs.</p>
<p>Specifically, if we build our server side APIs with secure-by-design patterns already available through vetted frameworks already in-mind then we are already in a strong position as the MCP Server only acts as a client for these externally facing APIs and utilities.</p>
<p>The reason this paradigm isn’t new is due to the fact that anyone can already interact with external APIs and tooling and likely will call the endpoints in unexpected ways.</p>
<p>This comes from the fact that LLMs interpret information in a manner that is different to human users, the protocol isn’t implicitly allowing for agents to perform actions that users couldn’t but LLMs may decide to perform actions that users wouldn’t choose.</p>
<p>Where this <strong>paradigm does shift</strong> is when integrating with tooling not previously designed to be communicated with by all manner of clients. For example if an API was previously designed to only be communicated with by a specific client or implementation (such as a mobile APIs or internal tooling) then adopting MCP may lead to unexpected failure modes or security concerns.</p>
<p>This area is likely where Security Practitioners will need to concentrate further time and effort to limit integration scope to avoid damages in the event of a security attack against the underlying LLM or planning logic.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="agent-human-and-device-identity">Agent, Human and Device Identity<a href="https://block.github.io/goose/blog/2025/03/31/securing-mcp#agent-human-and-device-identity" class="hash-link" aria-label="Direct link to Agent, Human and Device Identity" title="Direct link to Agent, Human and Device Identity">​</a></h3>
<p>In our traditional model of Authentication (AuthN) and Authorization (AuthZ) it’s common to tie an identity to a single point of abstraction such as a person or a business.</p>
<p>This field has organically been evolving towards pairing a services identity user identity abstraction with identification of client devices such as browsers and mobile phones. This is done to help reduce the prevalence of attacks caused by automation and inauthentic traffic such as account takeover attacks (ATO).</p>
<p>With the evolution of Agents performing actions on behalf of users we will need to evolve to be able to determine the combination of:</p>
<ol>
<li>The primary identity abstraction</li>
<li>The agent’s identity</li>
<li>The device/location the agent is running from</li>
</ol>
<p>Having consistent mechanisms for identifying usage in this manner allows companies to protect users from integrations with malicious agents and protect their platforms from attacks by unwanted agentic tooling.</p>
<p>The model context protocol itself has a <a href="https://spec.modelcontextprotocol.io/specification/2025-03-26/basic/authorization/" target="_blank" rel="noopener noreferrer">specification for OAuth</a> that at the time of writing was a draft, but has since been released here.</p>
<p>This flow considers the following steps:</p>
<ol>
<li>Client/Agent initiates standard OAuth flow with MCP server</li>
<li>MCP server redirects user to third-party authorization server</li>
<li>User authorizes with third-party server</li>
<li>Third-party server redirects back to MCP server with authorization code</li>
<li>MCP server exchanges code for third-party access token</li>
<li>MCP server generates its own access token bound to the third-party session</li>
<li>MCP server completes original OAuth flow with Client/Agent</li>
</ol>
<p>This is aligned with existing best practices but requires the MCPs themselves to have browser integrations/orchestration for OAuth to ensure they are able to redirect users effectively.</p>
<p>A future enhancement we’d love to see is requiring the agents to implement browser orchestration to provide an OAuth interface that MCPs themselves can integrate against and leverage. We believe this change would likely help standardise implementations and allow for protocol expansion to identify the agents and client alongside the user.</p>
<p>Having individual MCP implementations implement OAuth themselves is likely to lead to long term security and maintenance issues due to misimplementation or delays adopting future protocol enhancements.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="human-in-the-loop-for-operational-safety">Human in the loop for operational safety<a href="https://block.github.io/goose/blog/2025/03/31/securing-mcp#human-in-the-loop-for-operational-safety" class="hash-link" aria-label="Direct link to Human in the loop for operational safety" title="Direct link to Human in the loop for operational safety">​</a></h3>
<p>At a certain point we may build enough trust in our agents to allow them to perform more dangerous operations. For these kinds of use cases we can likely lean on known good practices for change management.</p>
<p>Specifically, building server side solutions to alert the user to the expected changes and the agent performing them and seeking consent will likely be a critical primitive for APIs of the future. The goal of this would be to ultimately keep irreversible or hard to reverse actions gated behind human interaction or approval.</p>
<p>For example, for an agent tasked with writing IaC, this could be as simple as requesting a human approver before applying/deploying the IaC.</p>
<p>In client side agents this would improve data integrity in the event the underlying LLM hallucinated or was tampered with externally through malicious MCP or data sources.</p>
<p>In the latest release of the protocol, an enhancement we love is being able to <a href="https://github.com/modelcontextprotocol/specification/blob/9236eb1cbfa02c17ab45c83a7bdbe55c450070be/schema/2025-03-26/schema.ts#L730" target="_blank" rel="noopener noreferrer">annotate a tool</a> to indicate to clients that tool actions are "readOnly" or "destructive". Using this to decide when to require a secondary approval from the user before performing a given action provides significantly better protections for users.</p>
<p>While we encourage an LLM based processing step to check for potentially malicious commands, <strong>having a deterministic aspect to higher risk commands in tandem ensures good access control is a more accurate way to provide protections</strong>.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="securing-the-mcp-supply-chain">Securing the MCP Supply Chain<a href="https://block.github.io/goose/blog/2025/03/31/securing-mcp#securing-the-mcp-supply-chain" class="hash-link" aria-label="Direct link to Securing the MCP Supply Chain" title="Direct link to Securing the MCP Supply Chain">​</a></h3>
<p>At this stage the majority of MCPs are being installed and run client side via commands like docker, uvx, pipx and npx. In practice this means when users install MCP based extensions they are providing arbitrary code execution privileges to the MCP Server.</p>
<p>In practice this presents a well documented and understood supply chain problem. How can we reduce risk associated with using third party code. The good news is that the same techniques still work including:</p>
<ol>
<li>Only install MCPs from trusted sources and are well maintained</li>
<li>Implement integrity checks and/or signing of artifacts where possible to ensure you’re executing the expected code</li>
<li>Implement allow lists on enterprise agents to ensure users only use pre-validated MCPs</li>
</ol>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="conclusion">Conclusion<a href="https://block.github.io/goose/blog/2025/03/31/securing-mcp#conclusion" class="hash-link" aria-label="Direct link to Conclusion" title="Direct link to Conclusion">​</a></h2>
<p>Much like agents are paving the way to allow LLMs to have more real-world utility MCP and similar protocols will continue to grow in adoption.</p>
<p>We believe that by contributing to open source projects early, sharing our learnings publicly, and building our own solutions that leverage MCP, Block can maintain security best practices from the deterministic world while continuing to evolve them with newer technologies.</p>
<p>We’re excited to work on making this protocol more secure for users and developers alike and are looking forward to sharing how we’ve used MCP for our own Security use-cases in the future.</p>
]]></content>
        <author>
            <name>Alex Rosenzweig</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Vibe Coding with Goose and the Speech MCP]]></title>
        <id>https://block.github.io/goose/blog/2025/03/28/vibe-coding-with-goose</id>
        <link href="https://block.github.io/goose/blog/2025/03/28/vibe-coding-with-goose"/>
        <updated>2025-03-28T00:00:00.000Z</updated>
        <summary type="html"><![CDATA[Explore the new Speech MCP server that enables voice-controlled coding and natural conversation with your AI agent]]></summary>
        <content type="html"><![CDATA[<p><img decoding="async" loading="lazy" alt="blog cover" src="https://block.github.io/goose/assets/images/vibe-coding-b2efeed37ea43f4773da5f1ff96f4184.png" width="1280" height="720" class="img_ev3q"></p>
<p>Imagine creating an app just by describing what you want out loud, like you’re talking to a friend. That’s the magic of vibe coding: turning natural language into working code with the help of an AI agent. And while typing a prompt gets the job done, saying it out loud hits different 🔥 The new <a href="https://block.github.io/goose/docs/tutorials/speech-mcp" target="_blank" rel="noopener noreferrer">Speech MCP server</a> has quite literally entered the chat.</p>
<p>In a recent <a href="https://www.youtube.com/watch?v=Zey9GHyXlHY&amp;ab_channel=BlockOpenSource" target="_blank" rel="noopener noreferrer">Wild Goose Case livestream</a>, hosts <a href="https://www.linkedin.com/in/ebonylouis/" target="_blank" rel="noopener noreferrer">Ebony Louis</a> and <a href="https://www.linkedin.com/in/acekyd/" target="_blank" rel="noopener noreferrer">Adewale Abati</a> were joined by <a href="https://www.linkedin.com/in/maksym-stepanenko-26404867" target="_blank" rel="noopener noreferrer">Max Novich</a> from Block's AI tools team, who demonstrated an exciting new extension - the <a href="https://github.com/Kvadratni/speech-mcp" target="_blank" rel="noopener noreferrer">Speech MCP server</a>.</p>
<p>During the livestream, Max demonstrated this by creating an entire web application using only voice commands - no keyboard or mouse required. This resulted in a vibrant, animated webpage with 3D effects, synthwave aesthetics, and interactive elements, all created through natural conversation with Goose.</p>
<iframe class="aspect-ratio" src="https://www.youtube.com/embed/Zey9GHyXlHY?start=437&amp;end=752" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin"></iframe>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="the-speech-mcp-server">The Speech MCP Server<a href="https://block.github.io/goose/blog/2025/03/28/vibe-coding-with-goose#the-speech-mcp-server" class="hash-link" aria-label="Direct link to The Speech MCP Server" title="Direct link to The Speech MCP Server">​</a></h2>
<p><a href="https://github.com/Kvadratni/speech-mcp" target="_blank" rel="noopener noreferrer">Speech MCP</a> is an open source MCP server that enables voice interaction with AI agents like Goose. What makes it special is that it runs entirely locally on your machine, making it:</p>
<ul>
<li>LLM agnostic</li>
<li>Privacy-focused</li>
<li>Cost-effective compared to cloud-based alternatives</li>
<li>Accessible without internet connectivity</li>
</ul>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="key-features">Key Features<a href="https://block.github.io/goose/blog/2025/03/28/vibe-coding-with-goose#key-features" class="hash-link" aria-label="Direct link to Key Features" title="Direct link to Key Features">​</a></h3>
<ol>
<li>
<p><strong>Local Speech Processing</strong>: Uses two main models:</p>
<ul>
<li>Faster Whisper: An efficient method to convert speech to text</li>
<li>Coqui TTS: A Japanese-engineered text-to-speech model with 54 natural-sounding voices</li>
</ul>
</li>
<li>
<p><strong>Voice Selection</strong>: Choose from 54 different voices with varying characteristics and personalities</p>
</li>
<li>
<p><strong>Multi-Speaker Narration</strong>: Generate and play conversations between multiple voices</p>
</li>
<li>
<p><strong>Audio Transcription</strong>: Convert audio/video content to text with timestamps and speaker detection</p>
</li>
</ol>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="live-demo-highlights">Live Demo Highlights<a href="https://block.github.io/goose/blog/2025/03/28/vibe-coding-with-goose#live-demo-highlights" class="hash-link" aria-label="Direct link to Live Demo Highlights" title="Direct link to Live Demo Highlights">​</a></h2>
<p>During the demonstration, Max showcased several impressive capabilities:</p>
<ol>
<li>
<p><strong>Voice-Controlled Development</strong>:</p>
<ul>
<li>Created animated text effects</li>
<li>Implemented 3D transformations</li>
<li>Added synthwave aesthetics with gradients and grids</li>
<li>Integrated music controls</li>
</ul>
</li>
<li>
<p><strong>System Integration</strong>:</p>
<ul>
<li>Controlled applications like Discord using voice commands</li>
<li>Navigated file system and development environment</li>
<li>Generated and managed audio content</li>
</ul>
</li>
<li>
<p><strong>Natural Interaction</strong>:</p>
<ul>
<li>Fluid conversation with Goose</li>
<li>Real-time feedback and adjustments</li>
<li>Multi-voice narration for documentation</li>
</ul>
</li>
</ol>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="getting-started">Getting Started<a href="https://block.github.io/goose/blog/2025/03/28/vibe-coding-with-goose#getting-started" class="hash-link" aria-label="Direct link to Getting Started" title="Direct link to Getting Started">​</a></h2>
<p>To try the Speech MCP server yourself:</p>
<ol>
<li>
<p>Install the required audio library (PortAudio):</p>
<div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain"># For macOS</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">brew install portaudio</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># For Linux</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">apt-get install portaudio  # or dnf install portaudio</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
</li>
<li>
<p>Install the extension directly using the one-click <a href="goose://extension?cmd=uvx&amp;&amp;arg=-p&amp;arg=3.10.14&amp;arg=speech-mcp@latest&amp;id=speech_mcp&amp;name=Speech%20Interface&amp;description=Voice%20interaction%20with%20audio%20visualization%20for%20Goose" target="_blank" rel="noopener noreferrer">deep link install</a> in Goose</p>
</li>
</ol>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="join-the-development">Join the Development<a href="https://block.github.io/goose/blog/2025/03/28/vibe-coding-with-goose#join-the-development" class="hash-link" aria-label="Direct link to Join the Development" title="Direct link to Join the Development">​</a></h2>
<p>The Speech MCP server is <a href="https://github.com/Kvadratni/speech-mcp" target="_blank" rel="noopener noreferrer">open-source</a> and welcomes contributions. You can also connect with Max on <a href="https://discord.gg/block-opensource" target="_blank" rel="noopener noreferrer">Discord</a> for questions and collaboration.</p>
<p>Voice interactions with AI agents like Goose with the power and tools to act on instructions provides a different kind of vibe that makes the future feel closer than ever. Whether you're interested in vibe coding, accessibility improvements, or just want to feel a bit more like Tony Stark while getting Goose to pull a J.A.R.V.I.S, the Speech MCP server offers a glimpse into the future of human-AI collaboration - and it's available today.</p>
]]></content>
        <author>
            <name>Adewale Abati</name>
            <uri>https://adewaleabati.com</uri>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[How to Determine If An MCP Server Is Safe]]></title>
        <id>https://block.github.io/goose/blog/2025/03/26/mcp-security</id>
        <link href="https://block.github.io/goose/blog/2025/03/26/mcp-security"/>
        <updated>2025-03-26T00:00:00.000Z</updated>
        <summary type="html"><![CDATA[Before you plug your agent into just any MCP server, here's how to check if it's actually safe.]]></summary>
        <content type="html"><![CDATA[<p><img decoding="async" loading="lazy" alt="blog cover" src="https://block.github.io/goose/assets/images/mcpsafety-87eb7ace7163a5edbe068ff75b79a199.png" width="2240" height="1260" class="img_ev3q"></p>
<p><a href="https://www.anthropic.com/news/model-context-protocol" target="_blank" rel="noopener noreferrer">Model Context Protocol (MCP)</a> servers are everywhere right now. Last time I checked there were <strong>3,000 and counting</strong>. Every day, a new one pops up, letting AI agents like Goose access files, query your Google Drive, search the web, and unlock all kinds of amazing integrations.</p>
<p>And just when I thought things couldn’t get any crazier, Zapier blessed us with an MCP server. That means your agent can now tap into over 8,000+ integrations.</p>
<p>So trust me, I know it’s super tempting to want to plug your AI agent into everything and just <em>see</em> what happens.</p>
<p>But hold on a minute, we can’t afford to skip over security.</p>
<p>When you connect to an MCP server, you’re giving it access to your workflows, most times even your data. And a lot of these servers are community built, with little to no governance.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="heres-what-i-do-before-i-trust-an-mcp-server">Here’s What I Do Before I Trust an MCP Server<a href="https://block.github.io/goose/blog/2025/03/26/mcp-security#heres-what-i-do-before-i-trust-an-mcp-server" class="hash-link" aria-label="Direct link to Here’s What I Do Before I Trust an MCP Server" title="Direct link to Here’s What I Do Before I Trust an MCP Server">​</a></h2>
<p>Any time I’m checking out a new MCP server to plug into Goose, I start with <strong><a href="https://glama.ai/mcp/servers" target="_blank" rel="noopener noreferrer">Glama.ai</a></strong>.</p>
<p>Glama is an all-in-one AI workspace, and it maintains one of the <strong>most comprehensive and security-aware MCP server directories</strong> that I've seen. The servers listed are either community built or created by the actual companies behind the tools, like <strong>Azure</strong> or <strong>JetBrains</strong>.</p>
<p>Each server gets a <strong>report card</strong>, so at a glance you can quickly assess whether it’s solid or a little sketchy.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="what-glama-scores">What Glama Scores<a href="https://block.github.io/goose/blog/2025/03/26/mcp-security#what-glama-scores" class="hash-link" aria-label="Direct link to What Glama Scores" title="Direct link to What Glama Scores">​</a></h2>
<p>Here’s what Glama grades servers on:</p>
<ul>
<li>✅ <strong>Security</strong> – Checks for known vulnerabilities in the server or its dependencies</li>
<li>✅ <strong>License</strong> – Confirms it’s using a permissive open source license</li>
<li>✅ <strong>Quality</strong> – Indicates whether the server is running and functions as expected</li>
</ul>
<p>You’ll also see helpful context like how many tools the server exposes, whether it has a README file, when it was last updated, and whether it supports live previews through the MCP inspector tool.</p>
<p>Glama doesn't just perform these checks once, they <strong>revaluate servers regularly</strong>, so if something breaks or a vulnerability gets introduced, the score updates automatically.</p>
<p>Here’s an example of a solid server: the <strong>YouTube MCP server</strong>, which lets Goose download and process videos to create summaries and transcripts.</p>
<p><img decoding="async" loading="lazy" alt="YouTube MCP Score" src="https://block.github.io/goose/assets/images/youtubeMcp-3701319613ac205084485a6ee8f8c41f.png" width="625" height="367" class="img_ev3q"></p>
<blockquote>
<p><em>All A’s across the board—<strong>security, license, and quality</strong>.</em></p>
</blockquote>
<p>That’s exactly the kind of score I look for before I plug Goose into any server.</p>
<p>So please, <strong>check before you connect</strong>.</p>
<p>A quick glance at an MCP directory like Glama can save you from crying on your office floor later. However, once you’ve done your homework?</p>
<p><strong>Have fun. Plug your agent in. Break things (safely). And vibe code with peace of mind.</strong></p>
]]></content>
        <author>
            <name>Ebony Louis</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Codename Goose Goes to Boston]]></title>
        <id>https://block.github.io/goose/blog/2025/03/21/goose-boston-meetup</id>
        <link href="https://block.github.io/goose/blog/2025/03/21/goose-boston-meetup"/>
        <updated>2025-03-21T00:00:00.000Z</updated>
        <summary type="html"><![CDATA[We hosted our first Goose Meetup in Boston, bringing together over 70 community members for lightning talks, hacking, and lively conversations about agentic systems and the future of MCPs.]]></summary>
        <content type="html"><![CDATA[<p><img decoding="async" loading="lazy" alt="blog cover" src="https://block.github.io/goose/assets/images/goose_goes_to_boston_banner-3ef0eedeb9d3eac56907c0c5e615d919.png" width="2240" height="1260" class="img_ev3q"></p>
<p><em>Question: What happens when you bring 70+ AI enthusiasts, open source contributors, and curious learners together in one room?</em></p>
<p><strong>Answer: You get an electric night filled with great conversations, hands-on hacking, and mind-blowing insights into agentic systems.</strong></p>
<p>This week, we hosted our very first <a href="https://block.github.io/goose" target="_blank" rel="noopener noreferrer">Goose</a> Meetup in Boston at the Cambridge Innovation Center. The turnout and energy exceeded all expectations! From first-time Goose users to seasoned AI engineers, attendees gathered to explore how Goose and the <a href="https://modelcontextprotocol.io/introduction" target="_blank" rel="noopener noreferrer">Model Context Protocol (MCP)</a> are shaping the future of AI automation.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="why-we-hosted-this-meetup">Why We Hosted This Meetup<a href="https://block.github.io/goose/blog/2025/03/21/goose-boston-meetup#why-we-hosted-this-meetup" class="hash-link" aria-label="Direct link to Why We Hosted This Meetup" title="Direct link to Why We Hosted This Meetup">​</a></h2>
<p>As our community continues to grow, we wanted to create a space where Goose enthusiasts could:</p>
<p>✅ Network and meet like-minded technologists</p>
<p>✅ Geek out over agentic systems and MCP</p>
<p>✅ Learn through talks, demos, and hands-on hacking</p>
<p>Boston has a thriving tech ecosystem, and it was incredible to see so many people come together to explore the future of AI agents.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="in-case-you-missed-it">In Case You Missed It<a href="https://block.github.io/goose/blog/2025/03/21/goose-boston-meetup#in-case-you-missed-it" class="hash-link" aria-label="Direct link to In Case You Missed It" title="Direct link to In Case You Missed It">​</a></h2>
<p>After pizza and networking, we kicked off with two lightning talks that set the tone for the rest of the night:</p>
<ul>
<li>
<p>Ebony Louis, Developer Advocate at Block, Inc. delivered an engaging introduction to Goose, covering how to get started, its capabilities, and a hands-on demo that hooked the audience. Reflecting on the night, she shared:</p>
<blockquote>
<p>"There’s no replacement for meeting in person and getting to talk to people face-to-face about where AI agents can take us. It was great to see the excitement of people who were using Goose for the first time, but it was even more productive to get questions and feedback about how we can work together to make the user experience better. AI is changing how we interact online, but this meetup was proof that it can bring us together in real life, too."</p>
</blockquote>
</li>
</ul>
<p><img decoding="async" loading="lazy" alt="Ebony takes the stage" src="https://block.github.io/goose/assets/images/ebony_preparing-013a8b1730a1f75484dfad5694a73a75.jpg" width="5712" height="4284" class="img_ev3q">
<em>Ebony preparing to take the stage</em></p>
<ul>
<li>
<p>Alex Hancock, Senior Software Engineer at Block, Inc. and MCP Committee Member, followed up with a deep dive into Model Context Protocol architecture, breaking down how it powers agentic systems and what’s next for the ecosystem. Alex was impressed by the enthusiasm in the room, sharing:</p>
<blockquote>
<p>"I was blown away by the attendance and the engagement. I had a lot of fun sticking around after the talks to answer questions and hear how people are thinking of using Goose and MCP."</p>
</blockquote>
</li>
</ul>
<p><img decoding="async" loading="lazy" alt="Alex speaking" src="https://block.github.io/goose/assets/images/alex_speaking-ec13442c55a42985517eb08e0b545137.jpg" width="5712" height="4284" class="img_ev3q">
<em>Alex sharing MCP insights with the audience</em></p>
<p>Both talks were packed with insights, great humor, and interactive moments that had attendees excited for what was to come.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="moments-we-loved">Moments We Loved<a href="https://block.github.io/goose/blog/2025/03/21/goose-boston-meetup#moments-we-loved" class="hash-link" aria-label="Direct link to Moments We Loved" title="Direct link to Moments We Loved">​</a></h2>
<p>Some of our favorite highlights from the night:</p>
<p>📞 Goose made a live phone call to Hack.Diversity alum Eliana Lopez during the event. This was a fun moment that showcased Goose's real-world capabilities in automating everyday tasks.</p>
<!-- -->
<div style="width:100%;max-width:800px;margin:0 auto"><video controls="" width="100%" height="400px" playsinline=""><source src="/goose/assets/medias/goose_makes_a_call-e45f1890addeb5018da2d70ee2e44796.mp4" type="video/mp4"><p>Your browser does not support the video tag.</p></video></div>
<p>💻 Attendees jumped into hands-on hacking, working on their own projects, experimenting with Goose, and sharing ideas in real time. To make sure everyone could participate, we provided OpenRouter credits, allowing attendees to run Goose without worrying about access barriers.</p>
<p><img decoding="async" loading="lazy" alt="Attendee hacking" src="https://block.github.io/goose/assets/images/attendee_hacking-bdac777f63da49683cf58513629ff01a.jpg" width="5712" height="4284" class="img_ev3q">
<em>Attendee hacking alongside Goose</em></p>
<p><img decoding="async" loading="lazy" alt="Debugging with attendees" src="https://block.github.io/goose/assets/images/debugging_with_attendees-528d912677fc352ddb3f601c2cf4c972.jpg" width="5712" height="4284" class="img_ev3q">
<em>Rizel Scarlett debugging with meetup attendees</em></p>
<p>💬 Riveting discussions sparked throughout the evening, including:</p>
<ul>
<li>Security for MCPs — How should we be thinking about security as agentic systems scale?</li>
<li>The future of agentic systems — What are we now capable of, and what’s next?</li>
</ul>
<p><img decoding="async" loading="lazy" alt="chatting with attendees" src="https://block.github.io/goose/assets/images/goose_boston_conversations-01c3e57ecd38e55d3159caeb1ebb0fac.jpg" width="4284" height="5712" class="img_ev3q">
<em>Alex chatting with attendees</em></p>
<p>For Marcelle B., a Software Engineer at Block Inc., the meetup highlighted just how diverse the community was and reinforced the importance of making Goose accessible to everyone:</p>
<blockquote>
<p>"It was enlightening to see the variety of backgrounds of the attendees. For a few, Goose was an opportunity to bring the power of AI to bear on their project, and our meetup was a friendly place for them to dip their toes in. This gave me such empathy for the kind of product features and the level of rock-solid implementation we need in development, so that Goose can continue to be an empowering tool, rather than another AI product that you have to be some kind of 'insider' to use."</p>
</blockquote>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="the-impact--whats-next">The Impact &amp; What’s Next<a href="https://block.github.io/goose/blog/2025/03/21/goose-boston-meetup#the-impact--whats-next" class="hash-link" aria-label="Direct link to The Impact &amp; What’s Next" title="Direct link to The Impact &amp; What’s Next">​</a></h2>
<p>The excitement and engagement from this meetup proved just how much community-driven learning matters. Attendees loved the experience, with one person sharing:</p>
<blockquote>
<p>"Fantastic event—well-paced, super friendly, learned a lot, and met great people. 10/10 would recommend!"</p>
</blockquote>
<p>This event wouldn’t have been the same without all of you. A huge shoutout to Hack.Diversity, Resilient Coders, Goose contributors, and Boston’s tech scene for showing up, supporting, and making this meetup such a success!</p>
<p><img decoding="async" loading="lazy" alt="Goose Team in Boston" src="https://block.github.io/goose/assets/images/goose_team_in_boston-83ed4d854908362156459ede34035521.jpg" width="5712" height="4284" class="img_ev3q">
<em>The Goose Team in Boston</em></p>
<ul>
<li>
<p>If you're experiencing FOMO (the Fear of Missing Out) and want to join the next meetup, follow us on <a href="https://linktr.ee/blockopensource" target="_blank" rel="noopener noreferrer">social media</a> to stay updated.</p>
</li>
<li>
<p>Bring a Goose meetup to your city! If you have a venue, reach out to us on <a href="https://discord.gg/block-opensource" target="_blank" rel="noopener noreferrer">Discord</a>—let’s make it happen!</p>
</li>
</ul>
]]></content>
        <author>
            <name>Rizel Scarlett</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Cracking the Code with VS Code MCP]]></title>
        <id>https://block.github.io/goose/blog/2025/03/21/goose-vscode</id>
        <link href="https://block.github.io/goose/blog/2025/03/21/goose-vscode"/>
        <updated>2025-03-21T00:00:00.000Z</updated>
        <summary type="html"><![CDATA[Connect Goose directly to your code editor with this Visual Studio Code MCP.]]></summary>
        <content type="html"><![CDATA[<p><img decoding="async" loading="lazy" alt="blog cover" src="https://block.github.io/goose/assets/images/vscodestream-74eafa34e7ae10cfb738feddecc98519.png" width="1206" height="633" class="img_ev3q"></p>
<p>Want to use Goose in VS Code? On the recent <a href="https://www.youtube.com/watch?v=hG7AnTw-GLU&amp;ab_channel=BlockOpenSource" target="_blank" rel="noopener noreferrer">Wild Goose Case livestream</a>, hosts <a href="https://www.linkedin.com/in/ebonylouis/" target="_blank" rel="noopener noreferrer">Ebony Louis</a> and <a href="https://www.linkedin.com/in/acekyd/" target="_blank" rel="noopener noreferrer">Adewale Abati</a> were joined by <a href="https://www.linkedin.com/in/andrewgertig/" target="_blank" rel="noopener noreferrer">Andrew Gertig</a>, Engineering Lead at Cash App, as he demonstrated the new VSCode MCP and how it brings powerful Goose-assisted coding capabilities directly into VS Code.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="what-is-the-vscode-mcp">What is the VSCode MCP?<a href="https://block.github.io/goose/blog/2025/03/21/goose-vscode#what-is-the-vscode-mcp" class="hash-link" aria-label="Direct link to What is the VSCode MCP?" title="Direct link to What is the VSCode MCP?">​</a></h2>
<p>The <a href="https://github.com/block/vscode-mcp" target="_blank" rel="noopener noreferrer">VSCode MCP Server</a> and its companion <a href="https://marketplace.visualstudio.com/items?itemName=block.vscode-mcp-extension" target="_blank" rel="noopener noreferrer">VSCode Extension</a> enable AI agents like Goose to interact with VS Code through the Model Context Protocol.</p>
<p>As Andrew explained during the stream, an MCP (<a href="https://modelcontextprotocol.io/introduction" target="_blank" rel="noopener noreferrer">Model Context Protocol</a>) server acts as a proxy between a Large Language Model (LLM) and whatever applications or tools you want to access to, in this case, VS Code. Extensions are add-ons based on this protocol that provide a way to extend Goose's functionality for your workflow.</p>
<div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">vscode-mcp/</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">├── server/    # MCP server implementation</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">└── extension/ # VS Code extension</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="key-features">Key Features<a href="https://block.github.io/goose/blog/2025/03/21/goose-vscode#key-features" class="hash-link" aria-label="Direct link to Key Features" title="Direct link to Key Features">​</a></h2>
<p>VSCode MCP and VSCode Extension offer several powerful features for you to explore:</p>
<p><strong>Intelligent Context Awareness</strong></p>
<p>The extension maintains synchronization between Goose and your VS Code environment to understand your project structure and make contextually relevant suggestions. During the live demo, this came in handy as Goose navigated complex codebases with precision.</p>
<p><strong>Interactive Code Modifications</strong></p>
<p>Rather than making direct changes, the extension presents modifications through VS Code's diff tool. This ensures that no code changes happen without your explicit approval, allowing you to keep control over your codebase.</p>
<p><strong>Progressive Complexity Handling</strong></p>
<p>During the demo, the VSCode MCP seamlessly handled tasks ranging in complexity, from basic text modifications to implementing interactive features like animated emojis with mouse interactions.</p>
<p><strong>Real-time Visual Feedback</strong></p>
<p>Developers can see proposed changes in real-time with the diff view, making it easy to understand exactly what modifications Goose is suggesting before accepting them. This was demonstrated when an emoji's sizes visually while preserving existing functionality.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="whats-next-for-vscode-mcp">What's Next for VSCode MCP?<a href="https://block.github.io/goose/blog/2025/03/21/goose-vscode#whats-next-for-vscode-mcp" class="hash-link" aria-label="Direct link to What's Next for VSCode MCP?" title="Direct link to What's Next for VSCode MCP?">​</a></h2>
<p>The features don't end here. The team is actively exploring several exciting features to take VSCode MCP to the next level:</p>
<ul>
<li><strong>Custom diff tool for granular control</strong> - This means you will be able to be selective on specific parts of changes you want to accept or reject.</li>
<li><strong>Smart navigation to specific code locations</strong> - Imagine being able to ask Goose to take you directly to a function definition or a specific implementation.</li>
<li><strong>Enhanced linting integration</strong> - To help maintain code quality standards automatically, making it way easier to fix issues before production.</li>
<li><strong>Terminal integration for command execution</strong> - This would allow Goose to execute commands and display results right in your development environment.</li>
<li><strong>Potential VS Code sidebar integration for Goose chat</strong> - Andrew showed a quick preview of an early prototype showing Goose running directly inside VS Code.</li>
</ul>
<h1>Community and Contributing</h1>
<p>The project is open source, and welcomes contributions from the community. If you'd like to support the project or directly contribute to it, you can check out <a href="https://github.com/block/vscode-mcp" target="_blank" rel="noopener noreferrer">the VSCode MCP repo on GitHub</a>, or <a href="https://discord.gg/block-opensource" target="_blank" rel="noopener noreferrer">join the Block Open Source Discord</a> if you'd like to ask the team any questions or start discussions.</p>
<p>You can also follow the <a href="https://block.github.io/goose/docs/tutorials/vscode-mcp" target="_blank" rel="noopener noreferrer">tutorial showing you how to integrate VS Code with Goose</a>.</p>
]]></content>
        <author>
            <name>Tania Chakraborty</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[How I Use Goose to Plan My Week with Asana and Google Calendar MCPs]]></title>
        <id>https://block.github.io/goose/blog/2025/03/20/asana-calendar-mcp</id>
        <link href="https://block.github.io/goose/blog/2025/03/20/asana-calendar-mcp"/>
        <updated>2025-03-20T00:00:00.000Z</updated>
        <summary type="html"><![CDATA[Use MCPs with Goose to automate task management and enhance productivity.]]></summary>
        <content type="html"><![CDATA[<p><img decoding="async" loading="lazy" alt="blog cover" src="https://block.github.io/goose/assets/images/mcp-planner-761303c5ddcd5c79ed853536e3f87bcf.png" width="1200" height="630" class="img_ev3q"></p>
<p>Mondays are overwhelming. A pile of unfinished tasks from last week, new priorities rolling in, and meetings scattered across the calendar. It’s a lot 😩. Instead of manually sorting through my todos and figuring out where everything fits, I use a couple of handy MCP servers with Goose and let it figure out my week.</p>
<p>There's so many amazing MCP servers out there to make my work life better, including <a href="https://github.com/roychri/mcp-server-asana" target="_blank" rel="noopener noreferrer">Asana</a> and <a href="https://www.pulsemcp.com/servers?q=google+calendar" target="_blank" rel="noopener noreferrer">Google Calendar</a>. I added these as Goose extensions, which means Goose can now can pull in my tasks, analyze them, and schedule them, all with one simple prompt:</p>
<blockquote>
<p><em><strong>Goose, pull all uncompleted tasks assigned to me in Asana. Group them by type of work to reduce context switching. Estimate how long each task will take. Then, schedule each task accordingly in my Google Calendar.  Make sure not to double book or overload any single day.</strong></em></p>
</blockquote>
<div class="theme-admonition theme-admonition-info admonition_xJq3 alert alert--info"><div class="admonitionHeading_Gvgb"><span class="admonitionIcon_Rf37"><svg viewBox="0 0 14 16"><path fill-rule="evenodd" d="M7 2.3c3.14 0 5.7 2.56 5.7 5.7s-2.56 5.7-5.7 5.7A5.71 5.71 0 0 1 1.3 8c0-3.14 2.56-5.7 5.7-5.7zM7 1C3.14 1 0 4.14 0 8s3.14 7 7 7 7-3.14 7-7-3.14-7-7-7zm1 3H6v5h2V4zm0 6H6v2h2v-2z"></path></svg></span>info</div><div class="admonitionContent_BuS1"><p>I used GPT-4o for this task</p></div></div>
<p>With this prompt, Goose reviews my uncompleted tasks in Asana (note that I have my workspace, project, and user IDs stored in <a href="https://block.github.io/goose/docs/tutorials/memory-mcp">memory</a>).</p>
<p>Rather than bouncing between different types of work, which is a productivity killer, Goose sorts my tasks into categories based on context. For example:</p>
<ul>
<li>Writing-related tasks (blog posts, documentation, emails)</li>
<li>Async collaboration (PR reviews, providing feedback)</li>
<li>Technical work (coding, etc)</li>
</ul>
<p>By grouping similar tasks, I can stay in the right headspace without constantly switching gears.</p>
<p>Goose then estimates how long each task will take, the complexity of the task, and any deadlines. If I need to manually adjust something, I can, but it’s usually pretty spot on.</p>
<p>With my tasks organized and estimated, Goose finds open time slots in my Google Calendar and automatically schedules them. It avoids my meetings and ensures I’m not overloading any single day.</p>
<p>Within the first few minutes of the start of my week, my schedule is already mapped out, optimized for focus.</p>
<p>This has been so extremely helpful in increasing my productivity. Thanks, Goose! 🚀</p>
]]></content>
        <author>
            <name>Angie Jones</name>
            <uri>https://angiejones.tech</uri>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[AI Prompting 101: How to Get the Best Responses from Your AI Agent]]></title>
        <id>https://block.github.io/goose/blog/2025/03/19/better-ai-prompting</id>
        <link href="https://block.github.io/goose/blog/2025/03/19/better-ai-prompting"/>
        <updated>2025-03-19T00:00:00.000Z</updated>
        <summary type="html"><![CDATA[How to prompt your AI agent the right way.]]></summary>
        <content type="html"><![CDATA[<p><img decoding="async" loading="lazy" alt="blog cover" src="https://block.github.io/goose/assets/images/prompt-078b12695f95c4f0eac3861a8a2611ef.png" width="2240" height="1260" class="img_ev3q"></p>
<p>Remember that saying, "it’s not what you ask, but <strong>how you ask</strong>"?</p>
<p>When I first started working with Goose as an AI agent, I was convinced there had to be one ‘best' prompting style. I spent so much time trying to figure out which one was superior, but the more I used Goose, the more I realized that couldn't be further from the truth. There isn’t one <em>right</em>  way to prompt AI, but there are better approaches depending on what your end goal is.</p>
<p>So, let’s go through <strong>which prompt style works best for your specific needs</strong>, and how you can use them to vibe code a little better with Goose.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="instruction-based-prompting">Instruction-Based Prompting<a href="https://block.github.io/goose/blog/2025/03/19/better-ai-prompting#instruction-based-prompting" class="hash-link" aria-label="Direct link to Instruction-Based Prompting" title="Direct link to Instruction-Based Prompting">​</a></h2>
<p>If you’re not a developer or you're just new to Goose, this is a great place to start. The best way to get good responses is to be as clear and direct as possible. Goose works best when given specific instructions, so tell it exactly what you need and include all of the important details. If you’re too vague, you might end up with an overly technical or even a possibly incomplete answer that doesn’t actually help you.</p>
<p>For example, instead of saying:</p>
<p>❌ Okay Prompt:</p>
<blockquote>
<p><em><strong>Goose, what’s a pull request?</strong></em></p>
</blockquote>
<p>This might give you a super technical definition that assumes you already know the basics.</p>
<p>So, you could say:</p>
<p>✅ Better Prompt:</p>
<blockquote>
<p><em><strong>Goose, explain how GitHub pull requests work like I’m new to coding</strong></em></p>
</blockquote>
<p>This tells Goose exactly what you need and at what level.</p>
<div class="theme-admonition theme-admonition-tip admonition_xJq3 alert alert--success"><div class="admonitionHeading_Gvgb"><span class="admonitionIcon_Rf37"><svg viewBox="0 0 12 16"><path fill-rule="evenodd" d="M6.5 0C3.48 0 1 2.19 1 5c0 .92.55 2.25 1 3 1.34 2.25 1.78 2.78 2 4v1h5v-1c.22-1.22.66-1.75 2-4 .45-.75 1-2.08 1-3 0-2.81-2.48-5-5.5-5zm3.64 7.48c-.25.44-.47.8-.67 1.11-.86 1.41-1.25 2.06-1.45 3.23-.02.05-.02.11-.02.17H5c0-.06 0-.13-.02-.17-.2-1.17-.59-1.83-1.45-3.23-.2-.31-.42-.67-.67-1.11C2.44 6.78 2 5.65 2 5c0-2.2 2.02-4 4.5-4 1.22 0 2.36.42 3.22 1.19C10.55 2.94 11 3.94 11 5c0 .66-.44 1.78-.86 2.48zM4 14h5c-.23 1.14-1.3 2-2.5 2s-2.27-.86-2.5-2z"></path></svg></span>pro tip</div><div class="admonitionContent_BuS1"><p>If you want Goose to remember your preferences, you can say,</p><blockquote>
<p><em><strong>Goose, remember I’m not a developer. Explain things at a high level unless I ask for technical details</strong></em></p>
</blockquote><p>If you have the <a href="https://block.github.io/goose/docs/tutorials/memory-mcp">Memory Extension</a> enabled, Goose will save this preference so you won’t have to remind it every time.</p></div></div>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="chain-of-thought-prompting">Chain-of-Thought Prompting<a href="https://block.github.io/goose/blog/2025/03/19/better-ai-prompting#chain-of-thought-prompting" class="hash-link" aria-label="Direct link to Chain-of-Thought Prompting" title="Direct link to Chain-of-Thought Prompting">​</a></h2>
<p>Sometimes a topic or task can just be too much to tackle all at once, and that’s where Chain-of-Thought Prompting comes in. Instead of getting this enormous and complicated response back, you can guide Goose to break things down step by step so it’s easier to follow.</p>
<p>For example, instead of saying:</p>
<p>❌ Okay Prompt:</p>
<blockquote>
<p><em><strong>Goose, what are Model Context Protocol Servers, and how are they used in goose?</strong></em></p>
</blockquote>
<p>which might get you a response that's hard to follow, you could say:</p>
<p>✅ Better Prompt:</p>
<blockquote>
<p><em><strong>Goose, walk me through what MCPs are and how they're used in gosoe, step by step</strong></em></p>
</blockquote>
<p>This forces Goose to slow down and explain each part clearly, making it easier to understand.</p>
<p>Now, if you want to take it a step further and make sure Goose understands the exact style of responses you're expecting, that’s when Few-Shot Prompting is the way to go.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="few-shot-prompting">Few-Shot Prompting<a href="https://block.github.io/goose/blog/2025/03/19/better-ai-prompting#few-shot-prompting" class="hash-link" aria-label="Direct link to Few-Shot Prompting" title="Direct link to Few-Shot Prompting">​</a></h2>
<p>If you need Goose to match a specific style or format, the best way to get there is by showing it what you want. I use this all the time! Since AI models learn patterns from examples, giving Goose a reference helps it skip the guesswork and just get straight to the point.</p>
<p>For example, instead of saying:</p>
<p>❌ Okay Prompt:</p>
<blockquote>
<p><em><strong>Goose, summarize this report</strong></em></p>
</blockquote>
<p>you could say:</p>
<p>✅ Better Prompt:</p>
<blockquote>
<p><em><strong>Goose, here’s how I usually summarize reports: (example summary). Can you summarize this new report the same way?</strong></em></p>
</blockquote>
<p>By providing an example, you’re guiding Goose to the answer that you actually want.</p>
<p>Now, what if you've given Goose an example and it’s first response isn’t quite right? There's no need to end the session and start over, that’s when Iterative Refinement Prompting is useful.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="iterative-refinement-prompting">Iterative Refinement Prompting<a href="https://block.github.io/goose/blog/2025/03/19/better-ai-prompting#iterative-refinement-prompting" class="hash-link" aria-label="Direct link to Iterative Refinement Prompting" title="Direct link to Iterative Refinement Prompting">​</a></h2>
<p>Let’s be real, Goose just like any AI agent isn’t always going to get it 'right' on the first try. Sometimes, it gives you a response that's way too technical, other times, it might completely miss the mark or even worse, hallucinate its way into a weird, made-up answer, that kind of sounds true. But instead of giving up and starting over, you can steer the conversation by giving feedback on what needs to change.</p>
<p>Since Goose allows you to bring your own LLM, the way it responds depends a lot on which model you’re using. Some LLMs need a little extra guidance, while others might require a few rounds of refinement before they get things right. The good news? You can shape the response without completely starting over.</p>
<p>For example, if Goose spits out something overly complicated, don’t just accept it, you can push back! Try saying:</p>
<blockquote>
<p><em><strong>Goose, this response is too technical. Can you simplify it?</strong></em></p>
</blockquote>
<p>Or if something sounds off and you want to do a fact check:</p>
<blockquote>
<p><em><strong>Goose, where did you get that information? How do you know it's accurate?</strong></em></p>
</blockquote>
<p>Think of working with Goose like pair programming or collaborating with a coworker. Sometimes, you need to clarify what you want or redirect the conversation to get make sure you're both on the same page.</p>
<p>But what if you don’t have a clear example or specific instructions to guide Goose? That’s when I would use Zero-Shot Prompting.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="zero-shot-prompting">Zero-Shot Prompting<a href="https://block.github.io/goose/blog/2025/03/19/better-ai-prompting#zero-shot-prompting" class="hash-link" aria-label="Direct link to Zero-Shot Prompting" title="Direct link to Zero-Shot Prompting">​</a></h2>
<p>Sometimes, you just want Goose to take a wild guess, get a little creative, and run with it. That’s exactly what Zero-Shot Prompting is for, it lets Goose figure things out on its own, without any examples or extra guidance from you.</p>
<p>For example, you might say:</p>
<blockquote>
<p><em><strong>Goose, write me a project update for my team</strong></em></p>
</blockquote>
<p>or:</p>
<blockquote>
<p><em><strong>Goose, I want to build a cool prompt directory</strong></em></p>
</blockquote>
<p>I love using this approach when I have a rough idea but no real clear direction. It’s like brainstorming but with AI, Goose will throw out ideas, suggest next steps, and sometimes even point out things I would’ve never even thought of. More often than not, my original idea ends up 10x better just by letting Goose take the lead.</p>
<p>Now, if you want Goose to not just come up with amazing ideas but also be funny, helpful, and maybe even a little nicer to you, that’s when you need to put those manners you learned in elementary school to use.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="politeness-based-prompting">Politeness-Based Prompting<a href="https://block.github.io/goose/blog/2025/03/19/better-ai-prompting#politeness-based-prompting" class="hash-link" aria-label="Direct link to Politeness-Based Prompting" title="Direct link to Politeness-Based Prompting">​</a></h2>
<p>Believe it or not, being polite actually makes AI responses better! Even though Goose isn’t self-aware……yet…… 👀, AI models tend to generate more thoughtful, structured, and sometimes even friendlier replies when asked nicely. So yes, saying “please” and “thank you” actually makes a difference.</p>
<p>For example, instead of saying:</p>
<p>❌ Okay Prompt:</p>
<blockquote>
<p><em><strong>Goose, generate a project update</strong></em></p>
</blockquote>
<p>you could say:</p>
<p>✅ Better Prompt:</p>
<blockquote>
<p><em><strong>Goose, could you generate a project update for me, please? Thanks!</strong></em></p>
</blockquote>
<p>Goose will respond either way, but <strong>trust me</strong>, polite prompts tend to get you better answers. One of our users once got the sweetest response from Goose at the end of a project, like it was genuinely grateful for the collaboration and even wished them sweet dreams. It was adorable!!</p>
<p><img decoding="async" loading="lazy" alt="goose response" src="https://block.github.io/goose/assets/images/politenessprompt-8bde8ee9a219af685f98f45be5977226.png" width="2322" height="1470" class="img_ev3q"></p>
<blockquote>
<p><em>Here’s the actual response, Goose is really out here making people’s day.</em></p>
</blockquote>
<p>And the best part? This works with any prompting style. So, if you want Goose to be helpful, clear, and maybe even a little extra nice to you, be good to Goose and Goose will be good to you.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="the-best-prompts-feel-natural">The Best Prompts Feel Natural<a href="https://block.github.io/goose/blog/2025/03/19/better-ai-prompting#the-best-prompts-feel-natural" class="hash-link" aria-label="Direct link to The Best Prompts Feel Natural" title="Direct link to The Best Prompts Feel Natural">​</a></h2>
<p>At the end of the day, all these prompting styles are just tools, at your disposal. The most important thing is to keep your prompts clear and natural. You don’t have to overthink it, but adding a little structure can make a huge difference in getting the responses you actually want.</p>
<p>Goose is here to make your life easier, so the next time you open up a session, just keep your goal in mind, experiment with different prompting styles, and see what works best for you.</p>
]]></content>
        <author>
            <name>Ebony Louis</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[How Goose Catches AI Errors with Langfuse]]></title>
        <id>https://block.github.io/goose/blog/2025/03/18/goose-langfuse</id>
        <link href="https://block.github.io/goose/blog/2025/03/18/goose-langfuse"/>
        <updated>2025-03-18T00:00:00.000Z</updated>
        <summary type="html"><![CDATA[Get detailed insights into Goose's behavior with Langfuse's observability tools.]]></summary>
        <content type="html"><![CDATA[<p><img decoding="async" loading="lazy" alt="blog cover" src="https://block.github.io/goose/assets/images/goose_aierrors-22154af884db86789ce1a12a72897e8e.png" width="1206" height="633" class="img_ev3q"></p>
<p>How do we debug AI agents like Goose? In the <a href="https://youtube.com/playlist?list=PLyMFt_U2IX4uFFhd_2TD9-tlJkgHMMb6F&amp;feature=shared" target="_blank" rel="noopener noreferrer">Goosing Around</a> stream series, host <a href="https://www.linkedin.com/in/rizel-bobb-semple/" target="_blank" rel="noopener noreferrer">Rizel Scarlett</a> invited <a href="https://www.linkedin.com/in/marcklingen/" target="_blank" rel="noopener noreferrer">Marc Klingen</a>, Co-Founder at Langfuse, and <a href="https://www.linkedin.com/in/alice-hau/" target="_blank" rel="noopener noreferrer">Alice Hau</a>, Machine Learning Engineer at Block, to demo how Langfuse enables observability into Goose's actions, letting you trace LLM behavior and catch errors.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="what-is-langfuse">What is Langfuse<a href="https://block.github.io/goose/blog/2025/03/18/goose-langfuse#what-is-langfuse" class="hash-link" aria-label="Direct link to What is Langfuse" title="Direct link to What is Langfuse">​</a></h2>
<p><a href="https://langfuse.com/" target="_blank" rel="noopener noreferrer">Langfuse</a> is an open source observability platform specifically designed for LLM-powered apps. Mark revealed during stream that Langfuse wasn't originally an observability platform, it was born from early attempts to build an AI agent like Goose.</p>
<p>While they were limited by the available models at the time, especially with multi-file edits, the team discovered the tooling they had built for debugging and monitoring their agent was more valuable to them than their agent.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="how-langfuse-works-with-goose">How Langfuse Works With Goose<a href="https://block.github.io/goose/blog/2025/03/18/goose-langfuse#how-langfuse-works-with-goose" class="hash-link" aria-label="Direct link to How Langfuse Works With Goose" title="Direct link to How Langfuse Works With Goose">​</a></h2>
<p>Since traditional observability tools don't quite cut it when it comes to AI agents. Langfuse introduces 3 core concepts to make Goose's behavior more observable, and create logs that are easier to parse:</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="traces">Traces<a href="https://block.github.io/goose/blog/2025/03/18/goose-langfuse#traces" class="hash-link" aria-label="Direct link to Traces" title="Direct link to Traces">​</a></h3>
<p>Each interaction with Goose creates a trace to capture the full story of what happened. These traces include key information, from the initial prompt and user messages to tool calls and their responses. They also store valuable metadata about model outputs and timing information, giving developers a complete picture of each interaction.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="timeline-view">Timeline View<a href="https://block.github.io/goose/blog/2025/03/18/goose-langfuse#timeline-view" class="hash-link" aria-label="Direct link to Timeline View" title="Direct link to Timeline View">​</a></h3>
<p>The timeline view takes these complex interactions and transforms it into a digestible format. Developers can see parallel task execution in real-time, understand the dependencies between different actions, and measure the actual duration of each opersation. This can be super helpful when debugging a complex sequence of actions taken by Goose, or to help optimize performance.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="structured-data">Structured Data<a href="https://block.github.io/goose/blog/2025/03/18/goose-langfuse#structured-data" class="hash-link" aria-label="Direct link to Structured Data" title="Direct link to Structured Data">​</a></h3>
<p>Alice explained, "Goose sessions can be really long... we have log files, but you'll just see a massive log of JSON."</p>
<p>Rather than rangle raw JSON log, Langfuse helps organize this data to help make navigating longer sessions and their data more straightforward. This approach can help developers easily analyze tool usage patterns, monitor token consumption, and quickly identify any performance bottlenecks and where they may happen.</p>
<p>With this integration, you can instead better understand the sequence of actions taken by Goose, and analyze track token usage and model behavior across LLMs.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="practical-benefits">Practical Benefits<a href="https://block.github.io/goose/blog/2025/03/18/goose-langfuse#practical-benefits" class="hash-link" aria-label="Direct link to Practical Benefits" title="Direct link to Practical Benefits">​</a></h2>
<p>The observability the Goose and Langfuse integration brings is great for anyone who wants clear insight into what Goose is doing behind the scenes. Alice and Marc discussed the different ways this integration can help you debug faster.</p>
<p>Developers can dive deeper into detailed session logs and identify the root cause to a reported issue and ensure Goose is operating as efficiently as possible. Like checking why certain commands may not be working as expected, or seeing exactly how Goose is processing information for a given task with a specific LLM.</p>
<p>As developers focus on operational efficiency, researchers can use the analytical capabilities of this integration to better understand which models best suit their needs. Through comprehensive model evaluations, they can analyze how different models handle tool calling, understand decision-making patterns across LLMs, and establish a systematic approach to understanding and improving AI systems.</p>
<h1>The Future of AI Observability</h1>
<p>These powerful debugging and analysis capabilities are only the beginning. This integration between Goose and Langfuse represents a significant step forward in making AI agents as transparent and debuggable as traditional code.</p>
<p>To keep up with the exciting developments as they release, you can check out both of the <a href="https://github.com/block/goose" target="_blank" rel="noopener noreferrer">Goose</a> and <a href="https://github.com/langfuse/langfuse" target="_blank" rel="noopener noreferrer">Langfuse</a> repositories on GitHub.</p>
<p>You can also watch the <a href="https://www.youtube.com/live/W39BQjsTS9E?feature=shared" target="_blank" rel="noopener noreferrer">livestream discussing the Goose and Langfuse integration</a>, and follow the <a href="https://block.github.io/goose/docs/tutorials/langfuse" target="_blank" rel="noopener noreferrer">tutorial showing you how to integrate Langfuse with Goose</a>.</p>
<p>Also, be sure to subscribe to our <a href="https://calget.com/c/t7jszrie" target="_blank" rel="noopener noreferrer">events calendar</a> to catch upcoming events.</p>
]]></content>
        <author>
            <name>Tania Chakraborty</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[AI, But Make It Local With Goose and Ollama]]></title>
        <id>https://block.github.io/goose/blog/2025/03/14/goose-ollama</id>
        <link href="https://block.github.io/goose/blog/2025/03/14/goose-ollama"/>
        <updated>2025-03-14T00:00:00.000Z</updated>
        <summary type="html"><![CDATA[Integrate Goose with Ollama for a fully local experience.]]></summary>
        <content type="html"><![CDATA[<p><img decoding="async" loading="lazy" alt="blog cover" src="https://block.github.io/goose/assets/images/gooseollama-fbb2cb67117c81eaa189a6b6174e6c6c.png" width="1206" height="633" class="img_ev3q"></p>
<p>On the <a href="https://youtube.com/playlist?list=PLyMFt_U2IX4uFFhd_2TD9-tlJkgHMMb6F&amp;feature=shared" target="_blank" rel="noopener noreferrer">Goosing Around</a> stream series, host <a href="https://www.linkedin.com/in/rizel-bobb-semple/" target="_blank" rel="noopener noreferrer">Rizel Scarlett</a> <a href="https://youtube.com/watch?v=WG10r2N0IwM?feature=share" target="_blank" rel="noopener noreferrer">demonstrated how to use Goose locally with Ollama</a> for a fully local experience on your device. Her guest, <a href="https://www.linkedin.com/in/parthsareen/" target="_blank" rel="noopener noreferrer">Parth Sareen</a>, an experienced software engineer with a focus on building frameworks and systems for AI/ML, showed us the magic of structured outputs and how Goose and Ollama work together under the hood.</p>
<p>Goose serves as an on-machine AI agent that can interact with your applications and tools through extensions, providing the framework and interface for AI-powered workflows. Ollama enables running large language models locally with a simple API, handling the optimization of models to run efficiently on consumer hardware.</p>
<p>Together, they create a self-contained AI agent workflow that puts advanced capabilities directly in the hands of developers.</p>
<p>Before diving deep into various capabilities, Rizel walked us through how to set yourself up for success by integrating Goose with Ollama. To follow along, you can download Goose <a href="https://block.github.io/goose/" target="_blank" rel="noopener noreferrer">here</a> and follow a step-by-step walk through in the <a href="https://block.github.io/goose/docs/getting-started/providers" target="_blank" rel="noopener noreferrer">Configure LLM Provider</a> guide.</p>
<p>If you have any questions or get stuck, feel free to chat with us on <a href="https://discord.gg/block-opensource" target="_blank" rel="noopener noreferrer">Discord</a> or post an issue/discussion on <a href="https://github.com/block/goose/" target="_blank" rel="noopener noreferrer">GitHub</a>. Thanks for reading!</p>
<h1>Why Go Local?</h1>
<p>Using cloud-based LLMs and providers make it so you don't need substantial computing resources, so why go local? Here's some benefits you may want to consider:</p>
<ul>
<li><strong>True data privacy</strong> since your conversations never leave your device. You have complete control over sensitive information. As Parth emphasized during the discussion, "Your data stays with you, period."</li>
<li><strong>Offline capability</strong> transforms when and where you can use AI. "I use Ollama all the time on planes—it's a lot of fun!" Parth shared, highlighting how local models free you from the constraints of internet connectivity.</li>
<li><strong>Direct control over model behavior</strong> means you can fine-tune parameters without subscription fees or API limits. Open source models allow you to get a closer look at what's happening behind the scenes.</li>
</ul>
<p>Personal use cases like development assistance, personal knowledge management, education, and content management are but some examples that can benefit from working locally and offline. You can keep research and sensitive data private, and utilize Goose when you have limited connectivity.</p>
<h1>Can My Machine Handle This?</h1>
<p>This question came up repeatedly, and the answer is more encouraging than you think. As Parth pointed out, "You don't need to run the largest models to get excellent results." The requirements you'll want to look out for on your device boils down to this:</p>
<ul>
<li><strong>RAM is key</strong>: 32GB is a solid baseline for larger models and outputs.</li>
<li><strong>For MacBooks, RAM is your primary concern</strong> given the unified memory architecture.</li>
<li><strong>For Windows/Linux, GPU memory is more important</strong> for acceleration</li>
</ul>
<p>Use cases can start with smaller, more efficient models that run on modest hardware. Models optimized for efficiency can deliver impressive performance even on standard laptops! Just start with a smaller model to test your workflow, then scale up as you need. This way you can figure out if you need the beefy hardware or not.</p>
<h1>The Magic of Structured Outputs</h1>
<p>Ollama supports <a href="https://ollama.com/blog/structured-outputs" target="_blank" rel="noopener noreferrer">structured outputs</a>, making it possible to constrain a model’s output to a specific format—essentially teaching models to respond in specific formats like JSON. Parth explained the concept with an elegant analogy: "It's like teaching someone math operations. You show them how to add, subtract, multiply, and then they can solve different problems following those patterns."</p>
<p>Parth showed us how these structured outputs can dramatically improve reliability. By constraining the model to respond within specific parameters, you get more consistent, predictable results. This structured approach ensures the model's response can be reliably parsed and integrated into applications—all while running locally on your device.</p>
<p>Here's an example of how to structure an output from the livestream:</p>
<div class="language-json codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-json codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token comment" style="color:#999988;font-style:italic">// Example of image analysis with structured output</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token punctuation" style="color:#393A34">{</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token property" style="color:#36acaa">"scene"</span><span class="token operator" style="color:#393A34">:</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">"sunset over mountains"</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token property" style="color:#36acaa">"objects"</span><span class="token operator" style="color:#393A34">:</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">[</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token punctuation" style="color:#393A34">{</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      </span><span class="token property" style="color:#36acaa">"type"</span><span class="token operator" style="color:#393A34">:</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">"sun"</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      </span><span class="token property" style="color:#36acaa">"attributes"</span><span class="token operator" style="color:#393A34">:</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">[</span><span class="token string" style="color:#e3116c">"orange"</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">"setting"</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">"partially visible"</span><span class="token punctuation" style="color:#393A34">]</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      </span><span class="token property" style="color:#36acaa">"confidence"</span><span class="token operator" style="color:#393A34">:</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">0.95</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token punctuation" style="color:#393A34">}</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token punctuation" style="color:#393A34">{</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      </span><span class="token property" style="color:#36acaa">"type"</span><span class="token operator" style="color:#393A34">:</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">"mountains"</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      </span><span class="token property" style="color:#36acaa">"attributes"</span><span class="token operator" style="color:#393A34">:</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">[</span><span class="token string" style="color:#e3116c">"silhouetted"</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">"range"</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">"distant"</span><span class="token punctuation" style="color:#393A34">]</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      </span><span class="token property" style="color:#36acaa">"confidence"</span><span class="token operator" style="color:#393A34">:</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">0.92</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token punctuation" style="color:#393A34">}</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token punctuation" style="color:#393A34">{</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      </span><span class="token property" style="color:#36acaa">"type"</span><span class="token operator" style="color:#393A34">:</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">"sky"</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      </span><span class="token property" style="color:#36acaa">"attributes"</span><span class="token operator" style="color:#393A34">:</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">[</span><span class="token string" style="color:#e3116c">"gradient"</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">"orange to purple"</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">"clear"</span><span class="token punctuation" style="color:#393A34">]</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      </span><span class="token property" style="color:#36acaa">"confidence"</span><span class="token operator" style="color:#393A34">:</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">0.98</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token punctuation" style="color:#393A34">}</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token punctuation" style="color:#393A34">]</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token property" style="color:#36acaa">"mood"</span><span class="token operator" style="color:#393A34">:</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">"peaceful"</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token property" style="color:#36acaa">"lighting"</span><span class="token operator" style="color:#393A34">:</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">"golden hour"</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token property" style="color:#36acaa">"composition"</span><span class="token operator" style="color:#393A34">:</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">"rule of thirds"</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token punctuation" style="color:#393A34">}</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>As Parth walked through these examples, he shared key practices to ensure you get the most out of local LLMs:</p>
<ol>
<li><strong>For precision tasks, lower the temperature</strong>. Setting it to 0 makes responses more deterministic and factual.</li>
<li><strong>Use structured outputs whenever possible</strong>, be explicit about the format you want in your prompts.</li>
<li><strong>Be mindful of context windows</strong>, local models have limits on how much information they can process at once.</li>
<li><strong>Experiment with different models</strong>! Each has strengths and weaknesses you'll want to explore for your needs.</li>
<li><strong>For larger documents, chunk them</strong> into manageable pieces, this helps a lot when you're working with larger files.</li>
</ol>
<h1>It's About The Freedom To Choose</h1>
<p>While there are trade-offs in terms of raw processing power when you go local vs cloud, you don't have to choose one over the other. As Parth summarized during the livestream: "Local AI isn't about replacing cloud options—it's about having the freedom to choose the right approach for your specific needs."</p>
<p>The benefits of owning your AI experience can be compelling for a variety of use cases. Whether you're a developer building tools, a writer working with confidential material, or simply someone who values privacy and control, I hope the Goose-Ollama integration offers a glimpse into how a local experience can benefit you, and explore a future where sophisticated AI is as personal and private as the data on your hard drive. Thanks for reading!</p>
]]></content>
        <author>
            <name>Tania Chakraborty</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Turn Figma Designs Into Code With Goose]]></title>
        <id>https://block.github.io/goose/blog/2025/03/12/goose-figma-mcp</id>
        <link href="https://block.github.io/goose/blog/2025/03/12/goose-figma-mcp"/>
        <updated>2025-03-12T00:00:00.000Z</updated>
        <summary type="html"><![CDATA[Give Goose the ability to turn Figma designs into code with the Figma extension.]]></summary>
        <content type="html"><![CDATA[<p><img decoding="async" loading="lazy" alt="blog cover" src="https://block.github.io/goose/assets/images/goosefigma-e6f84a734bd56cb431bb02452331a5d5.png" width="1206" height="633" class="img_ev3q"></p>
<p>In our previous episode of <a href="https://www.youtube.com/playlist?list=PLyMFt_U2IX4s1pMaidir5P4lSfjUK6Nzm" target="_blank" rel="noopener noreferrer">Goose Flight School</a>, our host <a href="https://www.linkedin.com/in/acekyd/" target="_blank" rel="noopener noreferrer">Adewale Abati</a> showed us how to use Goose to take a Figma design and transform it into a functional Nuxt application. In this stream he covered the entire process, from initial setup to final implementation, highlighting how Goose can help developers bridge the gap between design and development.</p>
<p><a href="https://block.github.io/goose/docs/getting-started/using-extensions" target="_blank" rel="noopener noreferrer">Extensions</a> enhance Goose's functionality by connecting with your existing tools and workflows. They add new features, access external data resources, and integrate with other systems. Learn how multiple extensions, including Figma and Developer, worked together seamlessly to dramatically accelerate development.</p>
<h1>Live Tutorial: Goose Builds Live</h1>
<p>During the livestream, Adewale demonstrated step-by-step how Goose handled each development phase, from creating the basic application structure to generating responsive layouts using Tailwind CSS. Adewale also highlighted how Goose addresses potential limitations as you go, showcasing the powerful balance between the Goose's automation and developer control.</p>
<iframe class="aspect-ratio" src="https://www.youtube.com/embed/_9t_N9zKwKM?si=r3e1MkrjS-f2AvkI" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin"></iframe>
<p>Throughout the stream, Adewale shared valuable tips to prepare your design for Goose. His key recommendations include:</p>
<ul>
<li>start with a well-structured Figma design</li>
<li>use Goose to make targeted improvements after the initial generation</li>
<li>fine-tune specific elements as needed</li>
<li>make sure you thoroughly test for functionality and responsiveness</li>
</ul>
<h1>Getting Started with Goose and Figma</h1>
<p>Whether you're a designer wanting to rapidly turn concepts into working code or a developer curious about streamlining design implementation, you can download Goose with its built-in <a href="https://block.github.io/goose/docs/getting-started/installation" target="_blank" rel="noopener noreferrer">Developer extension</a> and add the <a href="https://block.github.io/goose/v1/extensions/" target="_blank" rel="noopener noreferrer">Figma extension</a>.</p>
<p>For step-by-step instructions, check out the <a href="https://block.github.io/goose/docs/tutorials/figma-mcp" target="_blank" rel="noopener noreferrer">Figma tutorial</a>.</p>
]]></content>
        <author>
            <name>Tania Chakraborty</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Automating Phone Calls with Goose]]></title>
        <id>https://block.github.io/goose/blog/2025/03/10/goose-calls-vyop</id>
        <link href="https://block.github.io/goose/blog/2025/03/10/goose-calls-vyop"/>
        <updated>2025-03-10T00:00:00.000Z</updated>
        <summary type="html"><![CDATA[Practical tips to help you use Goose more effectively and efficiently.]]></summary>
        <content type="html"><![CDATA[<div style="display:none"><p><img decoding="async" loading="lazy" alt="blog cover" src="https://block.github.io/goose/assets/images/goose-voyp-215f3391cfbe2132542a2be63db84999.png" width="1920" height="1080" class="img_ev3q"></p></div>
<p>In the latest episode of <a href="https://www.youtube.com/playlist?list=PLyMFt_U2IX4uMW9kpE1FENQUyIgLuUnWD" target="_blank" rel="noopener noreferrer">Wild Goose Case</a>, hosts <a href="https://www.linkedin.com/in/ebonylouis/" target="_blank" rel="noopener noreferrer">Ebony Louis</a> and <a href="https://www.linkedin.com/in/acekyd/" target="_blank" rel="noopener noreferrer">Ace Abati</a> explored a fascinating new way to extend Goose’s automation capabilities by integrating with <a href="https://voyp.app/" target="_blank" rel="noopener noreferrer">VOYP</a>, an AI-powered system that makes phone calls. Their guest, <a href="https://www.linkedin.com/in/paulotaylor/" target="_blank" rel="noopener noreferrer">Paulo Taylor</a>, a technology veteran with over 35 years of experience, walked through how developers can use Goose to trigger and manage phone-based interactions through VOYP.</p>
<p>Goose is already known for automating tasks, but you can extend that automation beyond the screen. With the <a href="goose://extension?cmd=npx&amp;arg=-y&amp;arg=voyp-mcp&amp;id=voyp&amp;name=VOYP&amp;description=Automated%20Phone%20Calling&amp;env=VOYP_API_KEY%3DVOYP%20API%20key" target="_blank" rel="noopener noreferrer">VOYP Goose Extension</a>, you can automate phone calls to retrieve information, handle customer interactions, or even assist with accessibility needs.</p>
<p>VOYP functions as an AI call agent, using LLMs and Text-to-Speech (TTS) technology to conduct conversations over the phone. This means you can trigger phone interactions directly from Goose sessions, enabling real-world automation beyond traditional interfaces.</p>
<h1>How It Works</h1>
<p>Under the hood, VOYP utilizes multiple telecom providers to optimize call costs. It supports various LLMs and TTS providers, giving users flexibility in how they configure their AI caller. The integration with Goose is made possible through the <a href="https://modelcontextprotocol.io/" target="_blank" rel="noopener noreferrer">Model Context Protocol (MCP)</a>, which allows Goose to communicate seamlessly with VOYP and other AI-driven tools.</p>
<h1>Live Demo: AI Calls in Action</h1>
<p>During the livestream, Paulo demonstrated VOYP’s capabilities with a series of engaging examples. One highlight was a playful experiment where the AI made a phone call to tell a goose-themed joke.</p>
<iframe class="aspect-ratio" src="https://www.youtube.com/embed/Cvf6xvz1RUc?si=KQ44y6ypZFrzbest" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin"></iframe>
<p>In <a href="https://www.youtube.com/live/g_F1u6aqohk?t=1515" target="_blank" rel="noopener noreferrer">another demo</a>, Paulo had VOYP engage in a conversation with ChatGPT’s phone service about time travel, showing how fluid and adaptable the AI’s responses can be. He also walked through VOYP's real-time conversation monitoring dashboard, which provides a transparent look at how the AI processes and responds during calls.</p>
<h1>Getting Started with Goose and VOYP</h1>
<p>For those eager to experiment with <a href="https://github.com/paulotaylor/voyp-mcp" target="_blank" rel="noopener noreferrer">VOYP</a>, sign up on the <a href="https://voyp.app/" target="_blank" rel="noopener noreferrer">VOYP website</a> to create an account and obtain an API key. While calls require credits, new users receive 20 free credits for testing. The cost per call varies by region, with U.S.-based calls being the most affordable at approximately five credits per minute. To integrate VOYP with Goose, <a href="goose://extension?cmd=npx&amp;arg=-y&amp;arg=voyp-mcp&amp;id=voyp&amp;name=VOYP&amp;description=Automated%20Phone%20Calling&amp;env=VOYP_API_KEY%3DVOYP%20API%20key" target="_blank" rel="noopener noreferrer">install the VOYP extension</a>.</p>
]]></content>
        <author>
            <name>Angie Jones</name>
            <uri>https://angiejones.tech</uri>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[6 Essential Tips for Working with Goose]]></title>
        <id>https://block.github.io/goose/blog/2025/03/06/goose-tips</id>
        <link href="https://block.github.io/goose/blog/2025/03/06/goose-tips"/>
        <updated>2025-03-06T00:00:00.000Z</updated>
        <summary type="html"><![CDATA[Practical tips to help you use Goose more effectively and efficiently.]]></summary>
        <content type="html"><![CDATA[<p><img decoding="async" loading="lazy" alt="goose tips" src="https://block.github.io/goose/assets/images/goose-tips-4add28cc7201737dfb468ad11980f070.png" width="1200" height="630" class="img_ev3q"></p>
<p>Working with AI agents can sometimes feel unpredictable. After using Goose extensively for the last few months, I've compiled a few key tips that will help you get the most out of this tool. No matter your workflow, these guidelines will help you work more efficiently with Goose.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="1-keep-sessions-focused-and-short">1. Keep Sessions Focused and Short<a href="https://block.github.io/goose/blog/2025/03/06/goose-tips#1-keep-sessions-focused-and-short" class="hash-link" aria-label="Direct link to 1. Keep Sessions Focused and Short" title="Direct link to 1. Keep Sessions Focused and Short">​</a></h2>
<p>One of the most common mistakes users make is trying to accomplish too much in a single session. While it might seem efficient to keep the conversation going, longer sessions can actually hinder Goose's performance.</p>
<p>Every message adds to the context window, which is the amount of conversation history Goose can retain at any given time. This history is made up of tokens, the individual pieces of text (words or even parts of words) that Goose processes to generate responses. More tokens don’t just increase processing time, they also contribute to LLM usage costs. And once the context window fills up, older messages get pushed out, which can lead to loss of important details or unexpected behavior.</p>
<p>Think of it like keeping too many browser tabs open. Eventually, it impacts performance. Instead, start fresh sessions for distinct tasks. Don't worry about losing context; that's exactly what the <a href="https://block.github.io/goose/docs/tutorials/memory-mcp">Memory extension</a> is for. Keeping sessions focused and concise ensures more accurate, relevant responses while also keeping your LLM costs under control.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="2-minimize-active-extensions">2. Minimize Active Extensions<a href="https://block.github.io/goose/blog/2025/03/06/goose-tips#2-minimize-active-extensions" class="hash-link" aria-label="Direct link to 2. Minimize Active Extensions" title="Direct link to 2. Minimize Active Extensions">​</a></h2>
<p>When it comes to Goose extensions, less is often more. It's tempting to enable <a href="https://www.pulsemcp.com/servers" target="_blank" rel="noopener noreferrer">every available extension</a> just in case (I'm guilty of this!), but this approach can be counterproductive. Each active extension adds to the system prompt, increasing complexity and making Goose work harder to decide which tools to use.</p>
<p>Consider this: if you're cooking in a kitchen, having every possible utensil and appliance out on the counter doesn't make you a better chef. It just creates clutter and confusion. The same principle applies here.</p>
<p>Go ahead and install any extensions that interest you, but <a href="https://block.github.io/goose/docs/getting-started/using-extensions#enablingdisabling-extensions">keep them disabled</a> until you need them. Start with the built-in <a href="https://block.github.io/goose/docs/tutorials/developer-mcp">Developer extension</a> enabled, which is surprisingly powerful on its own, and only enable others when you need their specific capabilities. This leads to faster responses, lower token usage, and often more focused solutions.</p>
<div class="theme-admonition theme-admonition-tip admonition_xJq3 alert alert--success"><div class="admonitionHeading_Gvgb"><span class="admonitionIcon_Rf37"><svg viewBox="0 0 12 16"><path fill-rule="evenodd" d="M6.5 0C3.48 0 1 2.19 1 5c0 .92.55 2.25 1 3 1.34 2.25 1.78 2.78 2 4v1h5v-1c.22-1.22.66-1.75 2-4 .45-.75 1-2.08 1-3 0-2.81-2.48-5-5.5-5zm3.64 7.48c-.25.44-.47.8-.67 1.11-.86 1.41-1.25 2.06-1.45 3.23-.02.05-.02.11-.02.17H5c0-.06 0-.13-.02-.17-.2-1.17-.59-1.83-1.45-3.23-.2-.31-.42-.67-.67-1.11C2.44 6.78 2 5.65 2 5c0-2.2 2.02-4 4.5-4 1.22 0 2.36.42 3.22 1.19C10.55 2.94 11 3.94 11 5c0 .66-.44 1.78-.86 2.48zM4 14h5c-.23 1.14-1.3 2-2.5 2s-2.27-.86-2.5-2z"></path></svg></span>Bonus Tip</div><div class="admonitionContent_BuS1"><p>Before starting a complex task, ask Goose about its current capabilities. A simple prompt like "Do you have tools available to work with [specific technology/service]?" can save time and prevent false starts. Goose can tell you whether it has the necessary tools for your task, and if not, suggest which extensions you might need to enable. This quick check ensures you have the right tools ready before diving in too deep.</p></div></div>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="3-teach-goose-with-goosehints-files">3. Teach Goose with .goosehints Files<a href="https://block.github.io/goose/blog/2025/03/06/goose-tips#3-teach-goose-with-goosehints-files" class="hash-link" aria-label="Direct link to 3. Teach Goose with .goosehints Files" title="Direct link to 3. Teach Goose with .goosehints Files">​</a></h2>
<p>One of Goose's most powerful features is its ability to understand context through <a href="https://block.github.io/goose/docs/guides/using-goosehints">.goosehints</a> files, acting like a "README for AI". These hints can be set at both the project and global levels to guide Goose’s responses.</p>
<p>At the project level, placing .goosehints files in your directory helps Goose understand your structure, conventions, and special considerations. You can even use multiple files - one at the root for overall guidance and others in specific directories for more granular instructions (e.g., frontend styling conventions).</p>
<p>Beyond projects, global .goosehints files (<code>~/.config/goose/.goosehints</code>) apply across all sessions, making them perfect for things like:</p>
<ul>
<li>Personal coding style preferences</li>
<li>Favorite tools and workflows</li>
<li>Standard testing practices</li>
<li>Documentation conventions</li>
<li>Git commit message formatting</li>
</ul>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="4-choose-the-right-mode-for-your-workflow">4. Choose the Right Mode for Your Workflow<a href="https://block.github.io/goose/blog/2025/03/06/goose-tips#4-choose-the-right-mode-for-your-workflow" class="hash-link" aria-label="Direct link to 4. Choose the Right Mode for Your Workflow" title="Direct link to 4. Choose the Right Mode for Your Workflow">​</a></h2>
<p>Goose offers <a href="https://block.github.io/goose/docs/guides/goose-permissions">different modes</a> that determine how much autonomy it has when modifying files, using extensions, and performing automated actions.</p>
<ul>
<li>
<p>⚡️ <strong>Auto Mode (Default):</strong> Goose can modify, create, and delete files, as well as use extensions, without requiring approval. Best for users who want seamless automation.</p>
</li>
<li>
<p>✅ <strong>Approve Mode:</strong> Goose asks for confirmation before making changes. With <a href="https://block.github.io/goose/docs/guides/goose-permissions#smart-approve">Smart Approve</a> enabled, it evaluates risk levels and prompts for high-risk actions while executing safe ones automatically.</p>
</li>
<li>
<p>💬 <strong>Chat Mode:</strong> Goose operates in chat-only mode, without modifying files or using extensions. Ideal for users who want AI assistance without automation.</p>
</li>
</ul>
<p>If you’re new to Goose or working on a critical project, Approve Mode offers a great balance of automation and oversight. For hands-free workflows, Auto Mode keeps things moving, while Chat Mode is perfect for brainstorming and general AI assistance.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="5-guide-goose-with-step-by-step-execution">5. Guide Goose with Step-by-Step Execution<a href="https://block.github.io/goose/blog/2025/03/06/goose-tips#5-guide-goose-with-step-by-step-execution" class="hash-link" aria-label="Direct link to 5. Guide Goose with Step-by-Step Execution" title="Direct link to 5. Guide Goose with Step-by-Step Execution">​</a></h2>
<p>Complex tasks are best handled in stages, and Goose excels when you allow it to break problems into manageable steps. Instead of expecting an instant solution, ask Goose to generate a step-by-step plan first. Review the plan to ensure it aligns with your goals, then let Goose execute each step in sequence.</p>
<p>This structured approach not only improves accuracy but also gives you more control over the process. You can pause, adjust, or refine each step as needed, giving you more control while ensuring better results.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="6-refine-and-iterate-for-better-responses">6. Refine and Iterate for Better Responses<a href="https://block.github.io/goose/blog/2025/03/06/goose-tips#6-refine-and-iterate-for-better-responses" class="hash-link" aria-label="Direct link to 6. Refine and Iterate for Better Responses" title="Direct link to 6. Refine and Iterate for Better Responses">​</a></h2>
<p>Goose is powerful, but like any AI, it sometimes needs a second pass to get things right. If you don’t get the response you need, try refining your prompt or asking Goose to adjust its answer.</p>
<p>Good iteration techniques include:</p>
<ul>
<li>Asking Goose to explain its reasoning before taking action</li>
<li>Requesting alternative solutions to compare different approaches</li>
<li>Asking for a step-by-step breakdown of its thought process</li>
<li>Rewording prompts to add more detail or constraints</li>
</ul>
<p>For example, instead of asking, "Help me debug this error," try, "I’m getting a NullPointerException in my Java method. Here’s the stack trace. What could be causing it?" A small tweak in how you ask can dramatically improve the quality of the response.</p>
<hr>
<p>By following these tips, you'll be able to work more effectively with Goose, getting better results while using fewer resources. Remember, the goal is to solve problems efficiently and effectively. Whether you're writing code, automating tasks, or managing complex projects, these guidelines will help you make the most of what Goose has to offer.</p>
]]></content>
        <author>
            <name>Angie Jones</name>
            <uri>https://angiejones.tech</uri>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Let A Team of AI Agents Do It For You]]></title>
        <id>https://block.github.io/goose/blog/2025/02/21/gooseteam-mcp</id>
        <link href="https://block.github.io/goose/blog/2025/02/21/gooseteam-mcp"/>
        <updated>2025-02-21T00:00:00.000Z</updated>
        <summary type="html"><![CDATA[Community Spotlight on Cliff Hall's GooseTeam MCP server.]]></summary>
        <content type="html"><![CDATA[<p><img decoding="async" loading="lazy" alt="blog banner" src="https://block.github.io/goose/assets/images/gooseteam-mcp-082fa2890c313519c2a1637ca979c219.png" width="1206" height="633" class="img_ev3q"></p>
<p>During our <a href="https://youtu.be/9tq-QUnE29U" target="_blank" rel="noopener noreferrer">previous livestream</a>, Aaron Goldsmith, Infrastructure Operations Engineer at Cash App, showed a team of Goose AI agents collaborating in real time to create a website. Our community loved it so much, Cliff Hall was inspired to iterate on that idea and create a GooseTeam MCP server.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="the-original-protocol">The Original Protocol<a href="https://block.github.io/goose/blog/2025/02/21/gooseteam-mcp#the-original-protocol" class="hash-link" aria-label="Direct link to The Original Protocol" title="Direct link to The Original Protocol">​</a></h2>
<p>Aaron Goldsmith made an AI agent team consisting of multiple Goose instances a reality with his lightweight <a href="https://gist.github.com/AaronGoldsmith/114c439ae67e4f4c47cc33e829c82fac" target="_blank" rel="noopener noreferrer">Agent Communication Protocol</a>. With it, each Goose agent enters the chat, gets assigned a role (e.g. Project Coordinator, Researcher, Web Developer), and works on its part of a given task. The protocol specifies instructions guiding how the agents should talk and behave, allowing multiple Goose agents to collaborate. It also specifies that communication between the agents should be done via a Python-based websocket server with text/markdown .</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="gooseteam-mcp-server">GooseTeam MCP Server<a href="https://block.github.io/goose/blog/2025/02/21/gooseteam-mcp#gooseteam-mcp-server" class="hash-link" aria-label="Direct link to GooseTeam MCP Server" title="Direct link to GooseTeam MCP Server">​</a></h2>
<p>Introducing <a href="https://github.com/cliffhall/GooseTeam" target="_blank" rel="noopener noreferrer">GooseTeam</a>, created by Software Architect and community member, Cliff Hall. GooseTeam takes Aaron's protocol and iterates on it into an MCP server and collaboration protocol for Goose Agents. With features like task management, message storage, and agent waiting, you can have an entire team of Goose agents work together on a task or project for you.</p>
<p>A Goose agent with the Project Coordinator role will assign roles to other agents, your connected agents will send messages that can retrieved at any time, and your team of agents will connect to the same MCP server to collaborate together.</p>
<p><img decoding="async" loading="lazy" alt="Goose Agents" src="https://block.github.io/goose/assets/images/gooseteam-agents-61bd50464e81d67f3f51ce2e3a2be223.png" width="3768" height="758" class="img_ev3q"></p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="a-new-way-to-goose">A New Way to Goose<a href="https://block.github.io/goose/blog/2025/02/21/gooseteam-mcp#a-new-way-to-goose" class="hash-link" aria-label="Direct link to A New Way to Goose" title="Direct link to A New Way to Goose">​</a></h2>
<p>Working with a team of AI agents on a task is a game changer. Instead of getting confused as to how to improve your prompt engineering on your own or work across sessions manually, tools like Cliff's GooseTeam or Aaron's Agent Communication Protocol help us make sure AI agents like Goose are doing the work for us as efficiently as possible. The possibilities feel endless!</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="get-your-contribution-featured">Get Your Contribution Featured<a href="https://block.github.io/goose/blog/2025/02/21/gooseteam-mcp#get-your-contribution-featured" class="hash-link" aria-label="Direct link to Get Your Contribution Featured" title="Direct link to Get Your Contribution Featured">​</a></h2>
<p>Hopefully this contribution inspired you as much as it inspired our community. If you have a Goose contribution or project you'd like to share with our community, join our <a href="https://discord.gg/block-opensource" target="_blank" rel="noopener noreferrer">Discord</a> and share your work in the <strong>#share-your-work</strong> channel. You may just be featured on our livestream or get a cool prize. 👀 You can also star Goose on GitHub or follow us on social media so you never miss an update from us. Until next time!</p>
]]></content>
        <author>
            <name>Tania Chakraborty</name>
        </author>
    </entry>
</feed>