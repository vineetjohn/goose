"use strict";(self.webpackChunkgoose=self.webpackChunkgoose||[]).push([[9375],{438:e=>{e.exports=JSON.parse('{"archive":{"blogPosts":[{"id":"/2025/03/18/goose-langfuse","metadata":{"permalink":"/goose/blog/2025/03/18/goose-langfuse","source":"@site/blog/2025-03-18-goose-langfuse/index.md","title":"How Goose Catches AI Errors with Langfuse","description":"Get detailed insights into Goose\'s behavior with Langfuse\'s observability tools.","date":"2025-03-18T00:00:00.000Z","tags":[],"readingTime":3.4,"hasTruncateMarker":true,"authors":[{"name":"Tania Chakraborty","title":"Senior Technical Community Manager","page":{"permalink":"/goose/blog/authors/tania"},"socials":{"linkedin":"https://www.linkedin.com/in/taniachakraborty/","x":"https://x.com/taniashiba","github":"https://github.com/taniashiba"},"imageURL":"https://avatars.githubusercontent.com/u/126204004?v=4","key":"tania"}],"frontMatter":{"title":"How Goose Catches AI Errors with Langfuse","description":"Get detailed insights into Goose\'s behavior with Langfuse\'s observability tools.","authors":["tania"]},"unlisted":false,"nextItem":{"title":"AI, But Make It Local With Goose and Ollama","permalink":"/goose/blog/2025/03/14/goose-ollama"}},"content":"![blog cover](goose_aierrors.png)\\n\\nHow do we debug AI agents like Goose? In the [Goosing Around](https://youtube.com/playlist?list=PLyMFt_U2IX4uFFhd_2TD9-tlJkgHMMb6F&feature=shared) stream series, host [Rizel Scarlett](https://www.linkedin.com/in/rizel-bobb-semple/) invited [Marc Klingen](https://www.linkedin.com/in/marcklingen/), Co-Founder at Langfuse, and [Alice Hau](https://www.linkedin.com/in/alice-hau/), Machine Learning Engineer at Block, to demo how Langfuse enables observability into Goose\'s actions, letting you trace LLM behavior and catch errors.\\n\\n\x3c!--truncate--\x3e\\n\\n## What is Langfuse\\n\\n[Langfuse](https://langfuse.com/) is an open source observability platform specifically designed for LLM-powered apps. Mark revealed during stream that Langfuse wasn\'t originally an observability platform, it was born from early attempts to build an AI agent like Goose. \\n\\nWhile they were limited by the available models at the time, especially with multi-file edits, the team discovered the tooling they had built for debugging and monitoring their agent was more valuable to them than their agent.\\n\\n## How Langfuse Works With Goose\\nSince traditional observability tools don\'t quite cut it when it comes to AI agents. Langfuse introduces 3 core concepts to make Goose\'s behavior more observable, and create logs that are easier to parse:\\n\\n### Traces\\n\\nEach interaction with Goose creates a trace to capture the full story of what happened. These traces include key information, from the initial prompt and user messages to tool calls and their responses. They also store valuable metadata about model outputs and timing information, giving developers a complete picture of each interaction.\\n\\n### Timeline View\\nThe timeline view takes these complex interactions and transforms it into a digestible format. Developers can see parallel task execution in real-time, understand the dependencies between different actions, and measure the actual duration of each opersation. This can be super helpful when debugging a complex sequence of actions taken by Goose, or to help optimize performance.\\n\\n### Structured Data\\nAlice explained, \\"Goose sessions can be really long... we have log files, but you\'ll just see a massive log of JSON.\\"\\n\\nRather than rangle raw JSON log, Langfuse helps organize this data to help make navigating longer sessions and their data more straightforward. This approach can help developers easily analyze tool usage patterns, monitor token consumption, and quickly identify any performance bottlenecks and where they may happen.\\n\\nWith this integration, you can instead better understand the sequence of actions taken by Goose, and analyze track token usage and model behavior across LLMs.\\n\\n## Practical Benefits\\nThe observability the Goose and Langfuse integration brings is great for anyone who wants clear insight into what Goose is doing behind the scenes. Alice and Marc discussed the different ways this integration can help you debug faster.\\n\\nDevelopers can dive deeper into detailed session logs and identify the root cause to a reported issue and ensure Goose is operating as efficiently as possible. Like checking why certain commands may not be working as expected, or seeing exactly how Goose is processing information for a given task with a specific LLM. \\n\\nAs developers focus on operational efficiency, researchers can use the analytical capabilities of this integration to better understand which models best suit their needs. Through comprehensive model evaluations, they can analyze how different models handle tool calling, understand decision-making patterns across LLMs, and establish a systematic approach to understanding and improving AI systems.\\n\\n# The Future of AI Observability\\nThese powerful debugging and analysis capabilities are only the beginning. This integration between Goose and Langfuse represents a significant step forward in making AI agents as transparent and debuggable as traditional code.\\n\\nTo keep up with the exciting developments as they release, you can check out both of the [Goose](https://github.com/block/goose) and [Langfuse](https://github.com/langfuse/langfuse) repositories on GitHub. \\n\\nYou can also watch the [livestream discussing the Goose and Langfuse integration](https://www.youtube.com/live/W39BQjsTS9E?feature=shared).\\n\\nAlso, be sure to subscribe to our [events calendar](https://calget.com/c/t7jszrie) to catch upcoming events.\\n\\n<head>\\n  <meta property=\\"og:title\\" content=\\"How Goose Catches AI Errors with Langfuse\\" />\\n  <meta property=\\"og:type\\" content=\\"article\\" />\\n  <meta property=\\"og:url\\" content=\\"https://block.github.io/goose/blog/2025/03/18/goose-langfuse\\" />\\n  <meta property=\\"og:description\\" content=\\"Get detailed insights into Goose\'s behavior with Langfuse\'s observability tools.\\" />\\n  <meta property=\\"og:image\\" content=\\"http://block.github.io/goose/assets/images/goose_aierrors-22154af884db86789ce1a12a72897e8e.png\\" />\\n  <meta name=\\"twitter:card\\" content=\\"summary_large_image\\" />\\n  <meta property=\\"twitter:domain\\" content=\\"block.github.io/goose\\" />\\n  <meta name=\\"twitter:title\\" content=\\"How Goose Catches AI Errors with Langfuse\\" />\\n  <meta name=\\"twitter:description\\" content=\\"Get detailed insights into Goose\'s behavior with Langfuse\'s observability tools.\\" />\\n  <meta name=\\"twitter:image\\" content=\\"http://block.github.io/goose/assets/images/goose_aierrors-22154af884db86789ce1a12a72897e8e.png\\" />\\n</head>"},{"id":"/2025/03/14/goose-ollama","metadata":{"permalink":"/goose/blog/2025/03/14/goose-ollama","source":"@site/blog/2025-03-14-goose-ollama/index.md","title":"AI, But Make It Local With Goose and Ollama","description":"Integrate Goose with Ollama for a fully local experience.","date":"2025-03-14T00:00:00.000Z","tags":[],"readingTime":5.07,"hasTruncateMarker":true,"authors":[{"name":"Tania Chakraborty","title":"Senior Technical Community Manager","page":{"permalink":"/goose/blog/authors/tania"},"socials":{"linkedin":"https://www.linkedin.com/in/taniachakraborty/","x":"https://x.com/taniashiba","github":"https://github.com/taniashiba"},"imageURL":"https://avatars.githubusercontent.com/u/126204004?v=4","key":"tania"}],"frontMatter":{"title":"AI, But Make It Local With Goose and Ollama","description":"Integrate Goose with Ollama for a fully local experience.","authors":["tania"]},"unlisted":false,"prevItem":{"title":"How Goose Catches AI Errors with Langfuse","permalink":"/goose/blog/2025/03/18/goose-langfuse"},"nextItem":{"title":"Turn Figma Designs Into Code With Goose","permalink":"/goose/blog/2025/03/12/goose-figma-mcp"}},"content":"![blog cover](gooseollama.png)\\n\\nOn the [Goosing Around](https://youtube.com/playlist?list=PLyMFt_U2IX4uFFhd_2TD9-tlJkgHMMb6F&feature=shared) stream series, host [Rizel Scarlett](https://www.linkedin.com/in/rizel-bobb-semple/) [demonstrated how to use Goose locally with Ollama](https://youtube.com/watch?v=WG10r2N0IwM?feature=share) for a fully local experience on your device. Her guest, [Parth Sareen](https://www.linkedin.com/in/parthsareen/), an experienced software engineer with a focus on building frameworks and systems for AI/ML, showed us the magic of structured outputs and how Goose and Ollama work together under the hood.\\n\\n\x3c!--truncate--\x3e\\n\\nGoose serves as an on-machine AI agent that can interact with your applications and tools through extensions, providing the framework and interface for AI-powered workflows. Ollama enables running large language models locally with a simple API, handling the optimization of models to run efficiently on consumer hardware.\\n\\nTogether, they create a self-contained AI agent workflow that puts advanced capabilities directly in the hands of developers.\\n\\n# Getting Started\\n\\nBefore diving deep into various capabilities, Rizel walked us through how to set yourself up for success by integrating Goose with Ollama. To follow along, you can download Goose [here](https://block.github.io/goose/) and follow a step-by-step walk through in the [Configure LLM Provider](https://block.github.io/goose/docs/getting-started/providers) guide.\\n\\nIf you have any questions or get stuck, feel free to chat with us on [Discord](https://discord.gg/block-opensource) or post an issue/discussion on [GitHub](https://github.com/block/goose/). Thanks for reading!\\n\\n# Why Go Local?\\nUsing cloud-based LLMs and providers make it so you don\'t need substantial computing resources, so why go local? Here\'s some benefits you may want to consider:\\n\\n- **True data privacy** since your conversations never leave your device. You have complete control over sensitive information. As Parth emphasized during the discussion, \\"Your data stays with you, period.\\"\\n- **Offline capability** transforms when and where you can use AI. \\"I use Ollama all the time on planes\u2014it\'s a lot of fun!\\" Parth shared, highlighting how local models free you from the constraints of internet connectivity.\\n- **Direct control over model behavior** means you can fine-tune parameters without subscription fees or API limits. Open source models allow you to get a closer look at what\'s happening behind the scenes.\\n\\nPersonal use cases like development assistance, personal knowledge management, education, and content management are but some examples that can benefit from working locally and offline. You can keep research and sensitive data private, and utilize Goose when you have limited connectivity.\\n\\n# Can My Machine Handle This?\\nThis question came up repeatedly, and the answer is more encouraging than you think. As Parth pointed out, \\"You don\'t need to run the largest models to get excellent results.\\" The requirements you\'ll want to look out for on your device boils down to this:\\n\\n- **RAM is key**: 32GB is a solid baseline for larger models and outputs.\\n- **For MacBooks, RAM is your primary concern** given the unified memory architecture.\\n- **For Windows/Linux, GPU memory is more important** for acceleration\\n\\nUse cases can start with smaller, more efficient models that run on modest hardware. Models optimized for efficiency can deliver impressive performance even on standard laptops! Just start with a smaller model to test your workflow, then scale up as you need. This way you can figure out if you need the beefy hardware or not.\\n\\n# The Magic of Structured Outputs\\nOllama supports [structured outputs](https://ollama.com/blog/structured-outputs), making it possible to constrain a model\u2019s output to a specific format\u2014essentially teaching models to respond in specific formats like JSON. Parth explained the concept with an elegant analogy: \\"It\'s like teaching someone math operations. You show them how to add, subtract, multiply, and then they can solve different problems following those patterns.\\"\\n\\nParth showed us how these structured outputs can dramatically improve reliability. By constraining the model to respond within specific parameters, you get more consistent, predictable results. This structured approach ensures the model\'s response can be reliably parsed and integrated into applications\u2014all while running locally on your device.\\n\\nHere\'s an example of how to structure an output from the livestream:\\n\\n```json\\n// Example of image analysis with structured output\\n{\\n  \\"scene\\": \\"sunset over mountains\\",\\n  \\"objects\\": [\\n    {\\n      \\"type\\": \\"sun\\",\\n      \\"attributes\\": [\\"orange\\", \\"setting\\", \\"partially visible\\"],\\n      \\"confidence\\": 0.95\\n    },\\n    {\\n      \\"type\\": \\"mountains\\",\\n      \\"attributes\\": [\\"silhouetted\\", \\"range\\", \\"distant\\"],\\n      \\"confidence\\": 0.92\\n    },\\n    {\\n      \\"type\\": \\"sky\\",\\n      \\"attributes\\": [\\"gradient\\", \\"orange to purple\\", \\"clear\\"],\\n      \\"confidence\\": 0.98\\n    }\\n  ],\\n  \\"mood\\": \\"peaceful\\",\\n  \\"lighting\\": \\"golden hour\\",\\n  \\"composition\\": \\"rule of thirds\\"\\n}\\n```\\nAs Parth walked through these examples, he shared key practices to ensure you get the most out of local LLMs:\\n\\n1. **For precision tasks, lower the temperature**. Setting it to 0 makes responses more deterministic and factual.\\n2. **Use structured outputs whenever possible**, be explicit about the format you want in your prompts.\\n3. **Be mindful of context windows**, local models have limits on how much information they can process at once.\\n4. **Experiment with different models**! Each has strengths and weaknesses you\'ll want to explore for your needs.\\n5. **For larger documents, chunk them** into manageable pieces, this helps a lot when you\'re working with larger files.\\n\\n# It\'s About The Freedom To Choose\\nWhile there are trade-offs in terms of raw processing power when you go local vs cloud, you don\'t have to choose one over the other. As Parth summarized during the livestream: \\"Local AI isn\'t about replacing cloud options\u2014it\'s about having the freedom to choose the right approach for your specific needs.\\"\\n\\nThe benefits of owning your AI experience can be compelling for a variety of use cases. Whether you\'re a developer building tools, a writer working with confidential material, or simply someone who values privacy and control, I hope the Goose-Ollama integration offers a glimpse into how a local experience can benefit you, and explore a future where sophisticated AI is as personal and private as the data on your hard drive. Thanks for reading!\\n\\n<head>\\n  <meta property=\\"og:title\\" content=\\"Goosing Around: AI, But Make It Local With Goose and Ollama\\" />\\n  <meta property=\\"og:type\\" content=\\"article\\" />\\n  <meta property=\\"og:url\\" content=\\"https://block.github.io/goose/blog/2025/03/13/goose-ollama-local\\" />\\n  <meta property=\\"og:description\\" content=\\"Integrate Goose with Ollama for a fully local experience.\\" />\\n  <meta property=\\"og:image\\" content=\\"http://block.github.io/goose/assets/images/gooseollama-fbb2cb67117c81eaa189a6b6174e6c6c.png\\" />\\n  <meta name=\\"twitter:card\\" content=\\"summary_large_image\\" />\\n  <meta property=\\"twitter:domain\\" content=\\"block.github.io/goose\\" />\\n  <meta name=\\"twitter:title\\" content=\\"Goosing Around: AI, But Make It Local With Goose and Ollama\\" />\\n  <meta name=\\"twitter:description\\" content=\\"Integrate Goose with Ollama for a fully local experience.\\" />\\n  <meta name=\\"twitter:image\\" content=\\"http://block.github.io/goose/assets/images/gooseollama-fbb2cb67117c81eaa189a6b6174e6c6c.png\\" />\\n</head>"},{"id":"/2025/03/12/goose-figma-mcp","metadata":{"permalink":"/goose/blog/2025/03/12/goose-figma-mcp","source":"@site/blog/2025-03-12-goose-figma-mcp/index.md","title":"Turn Figma Designs Into Code With Goose","description":"Give Goose the ability to turn Figma designs into code with the Figma extension.","date":"2025-03-12T00:00:00.000Z","tags":[],"readingTime":1.8,"hasTruncateMarker":true,"authors":[{"name":"Tania Chakraborty","title":"Senior Technical Community Manager","page":{"permalink":"/goose/blog/authors/tania"},"socials":{"linkedin":"https://www.linkedin.com/in/taniachakraborty/","x":"https://x.com/taniashiba","github":"https://github.com/taniashiba"},"imageURL":"https://avatars.githubusercontent.com/u/126204004?v=4","key":"tania"}],"frontMatter":{"title":"Turn Figma Designs Into Code With Goose","description":"Give Goose the ability to turn Figma designs into code with the Figma extension.","authors":["tania"]},"unlisted":false,"prevItem":{"title":"AI, But Make It Local With Goose and Ollama","permalink":"/goose/blog/2025/03/14/goose-ollama"},"nextItem":{"title":"Automating Phone Calls with Goose","permalink":"/goose/blog/2025/03/10/goose-calls-vyop"}},"content":"![blog cover](goosefigma.png)\\n\\nIn our previous episode of [Goose Flight School](https://www.youtube.com/playlist?list=PLyMFt_U2IX4s1pMaidir5P4lSfjUK6Nzm), our host [Adewale Abati](https://www.linkedin.com/in/acekyd/) showed us how to use Goose to take a Figma design and transform it into a functional Nuxt application. In this stream he covered the entire process, from initial setup to final implementation, highlighting how Goose can help developers bridge the gap between design and development.\\n\\n\x3c!--truncate--\x3e\\n\\n# How It Works\\n[Extensions](https://block.github.io/goose/docs/getting-started/using-extensions) enhance Goose\'s functionality by connecting with your existing tools and workflows. They add new features, access external data resources, and integrate with other systems. Learn how multiple extensions, including Figma and Developer, worked together seamlessly to dramatically accelerate development.\\n\\n# Live Tutorial: Goose Builds Live\\nDuring the livestream, Adewale demonstrated step-by-step how Goose handled each development phase, from creating the basic application structure to generating responsive layouts using Tailwind CSS. Adewale also highlighted how Goose addresses potential limitations as you go, showcasing the powerful balance between the Goose\'s automation and developer control.\\n\\n<iframe class=\\"aspect-ratio\\" src=\\"https://www.youtube.com/embed/_9t_N9zKwKM?si=r3e1MkrjS-f2AvkI\\" title=\\"YouTube video player\\" frameborder=\\"0\\" allow=\\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\\" referrerpolicy=\\"strict-origin-when-cross-origin\\" allowfullscreen></iframe>\\n\\nThroughout the stream, Adewale shared valuable tips to prepare your design for Goose. His key recommendations include: \\n\\n* start with a well-structured Figma design\\n* use Goose to make targeted improvements after the initial generation\\n* fine-tune specific elements as needed\\n* make sure you thoroughly test for functionality and responsiveness\\n\\n# Getting Started with Goose and Figma\\nWhether you\'re a designer wanting to rapidly turn concepts into working code or a developer curious about streamlining design implementation, you can download Goose with its built-in [Developer extension](https://block.github.io/goose/docs/getting-started/installation) and add the [Figma extension](https://block.github.io/goose/v1/extensions/). \\n\\nFor step-by-step instructions, check out the [Figma tutorial](https://block.github.io/goose/docs/tutorials/figma-mcp).\\n\\n<head>\\n  <meta property=\\"og:title\\" content=\\"Goose Flight School: Turn Figma Designs Into Code With Goose\\" />\\n  <meta property=\\"og:type\\" content=\\"article\\" />\\n  <meta property=\\"og:url\\" content=\\"https://block.github.io/goose/blog/2025/03/12/goose-figma-mcp\\" />\\n  <meta property=\\"og:description\\" content=\\"Give Goose the ability to turn Figma designs into code with the Figma extension.\\" />\\n  <meta property=\\"og:image\\" content=\\"http://block.github.io/goose/assets/images/goosefigma-e6f84a734bd56cb431bb02452331a5d5.png\\" />\\n  <meta name=\\"twitter:card\\" content=\\"summary_large_image\\" />\\n  <meta property=\\"twitter:domain\\" content=\\"block.github.io/goose\\" />\\n  <meta name=\\"twitter:title\\" content=\\"Goose Flight School: Turn Figma Designs Into Code With Goose\\" />\\n  <meta name=\\"twitter:description\\" content=\\"Give Goose the ability to turn Figma designs into code with the Figma extension.\\" />\\n  <meta name=\\"twitter:image\\" content=\\"http://block.github.io/goose/assets/images/goosefigma-e6f84a734bd56cb431bb02452331a5d5.png\\" />\\n</head>"},{"id":"/2025/03/10/goose-calls-vyop","metadata":{"permalink":"/goose/blog/2025/03/10/goose-calls-vyop","source":"@site/blog/2025-03-10-goose-calls-vyop/index.md","title":"Automating Phone Calls with Goose","description":"Practical tips to help you use Goose more effectively and efficiently.","date":"2025-03-10T00:00:00.000Z","tags":[],"readingTime":2.325,"hasTruncateMarker":true,"authors":[{"name":"Angie Jones","title":"Head of Developer Relations","url":"https://angiejones.tech","page":{"permalink":"/goose/blog/authors/angie"},"socials":{"linkedin":"https://www.linkedin.com/in/angiejones/","github":"https://github.com/angiejones","x":"https://x.com/techgirl1908"},"imageURL":"https://avatars.githubusercontent.com/u/15972783?v=4","key":"angie"}],"frontMatter":{"title":"Automating Phone Calls with Goose","description":"Practical tips to help you use Goose more effectively and efficiently.","authors":["angie"]},"unlisted":false,"prevItem":{"title":"Turn Figma Designs Into Code With Goose","permalink":"/goose/blog/2025/03/12/goose-figma-mcp"},"nextItem":{"title":"6 Essential Tips for Working with Goose","permalink":"/goose/blog/2025/03/06/goose-tips"}},"content":"<div style={{display: \'none\'}}>\\n\\n![blog cover](goose-voyp.png)\\n\\n</div>\\n\\nIn the latest episode of [Wild Goose Case](https://www.youtube.com/playlist?list=PLyMFt_U2IX4uMW9kpE1FENQUyIgLuUnWD), hosts [Ebony Louis](https://www.linkedin.com/in/ebonylouis/) and [Ace Abati](https://www.linkedin.com/in/acekyd/) explored a fascinating new way to extend Goose\u2019s automation capabilities by integrating with [VOYP](https://voyp.app/), an AI-powered system that makes phone calls. Their guest, [Paulo Taylor](https://www.linkedin.com/in/paulotaylor/), a technology veteran with over 35 years of experience, walked through how developers can use Goose to trigger and manage phone-based interactions through VOYP.\\n\\n\x3c!--truncate--\x3e\\n\\n# Expanding Goose\u2019s Reach with AI-Powered Calls\\n\\nGoose is already known for automating tasks, but you can extend that automation beyond the screen. With the [VOYP Goose Extension](goose://extension?cmd=npx&arg=-y&arg=voyp-mcp&id=voyp&name=VOYP&description=Automated%20Phone%20Calling&env=VOYP_API_KEY%3DVOYP%20API%20key), you can automate phone calls to retrieve information, handle customer interactions, or even assist with accessibility needs.\\n\\nVOYP functions as an AI call agent, using LLMs and Text-to-Speech (TTS) technology to conduct conversations over the phone. This means you can trigger phone interactions directly from Goose sessions, enabling real-world automation beyond traditional interfaces.\\n\\n# How It Works\\n\\nUnder the hood, VOYP utilizes multiple telecom providers to optimize call costs. It supports various LLMs and TTS providers, giving users flexibility in how they configure their AI caller. The integration with Goose is made possible through the [Model Context Protocol (MCP)](https://modelcontextprotocol.io/), which allows Goose to communicate seamlessly with VOYP and other AI-driven tools.\\n\\n# Live Demo: AI Calls in Action\\nDuring the livestream, Paulo demonstrated VOYP\u2019s capabilities with a series of engaging examples. One highlight was a playful experiment where the AI made a phone call to tell a goose-themed joke. \\n\\n<iframe class=\\"aspect-ratio\\" src=\\"https://www.youtube.com/embed/Cvf6xvz1RUc?si=KQ44y6ypZFrzbest\\" title=\\"YouTube video player\\" frameborder=\\"0\\" allow=\\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\\" referrerpolicy=\\"strict-origin-when-cross-origin\\" allowfullscreen></iframe>\\n\\nIn [another demo](https://www.youtube.com/live/g_F1u6aqohk?t=1515), Paulo had VOYP engage in a conversation with ChatGPT\u2019s phone service about time travel, showing how fluid and adaptable the AI\u2019s responses can be. He also walked through VOYP\'s real-time conversation monitoring dashboard, which provides a transparent look at how the AI processes and responds during calls.\\n\\n# Getting Started with Goose and VOYP\\nFor those eager to experiment with [VOYP](https://github.com/paulotaylor/voyp-mcp), sign up on the [VOYP website](https://voyp.app/) to create an account and obtain an API key. While calls require credits, new users receive 20 free credits for testing. The cost per call varies by region, with U.S.-based calls being the most affordable at approximately five credits per minute. To integrate VOYP with Goose, [install the VOYP extension](goose://extension?cmd=npx&arg=-y&arg=voyp-mcp&id=voyp&name=VOYP&description=Automated%20Phone%20Calling&env=VOYP_API_KEY%3DVOYP%20API%20key).\\n\\n<head>\\n  <meta property=\\"og:title\\" content=\\"Wild Goose Case: Automating Phone Calls with Goose and VOYP\\" />\\n  <meta property=\\"og:type\\" content=\\"article\\" />\\n  <meta property=\\"og:url\\" content=\\"https://block.github.io/goose/blog/2025/03/06/goose-tips\\" />\\n  <meta property=\\"og:description\\" content=\\"Give Goose the ability to make phone calls with the VOYP extension.\\" />\\n  <meta property=\\"og:image\\" content=\\"https://block.github.io/goose/assets/images/goose-voyp-215f3391cfbe2132542a2be63db84999.png\\" />\\n  <meta name=\\"twitter:card\\" content=\\"summary_large_image\\" />\\n  <meta property=\\"twitter:domain\\" content=\\"block.github.io/goose\\" />\\n  <meta name=\\"twitter:title\\" content=\\"Wild Goose Case: Automating Phone Calls with Goose and VOYP\\" />\\n  <meta name=\\"twitter:description\\" content=\\"Give Goose the ability to make phone calls with the VOYP extension.\\" />\\n  <meta name=\\"twitter:image\\" content=\\"https://block.github.io/goose/assets/images/goose-voyp-215f3391cfbe2132542a2be63db84999.png\\" />\\n</head>"},{"id":"/2025/03/06/goose-tips","metadata":{"permalink":"/goose/blog/2025/03/06/goose-tips","source":"@site/blog/2025-03-06-goose-tips/index.md","title":"6 Essential Tips for Working with Goose","description":"Practical tips to help you use Goose more effectively and efficiently.","date":"2025-03-06T00:00:00.000Z","tags":[],"readingTime":5.37,"hasTruncateMarker":true,"authors":[{"name":"Angie Jones","title":"Head of Developer Relations","url":"https://angiejones.tech","page":{"permalink":"/goose/blog/authors/angie"},"socials":{"linkedin":"https://www.linkedin.com/in/angiejones/","github":"https://github.com/angiejones","x":"https://x.com/techgirl1908"},"imageURL":"https://avatars.githubusercontent.com/u/15972783?v=4","key":"angie"}],"frontMatter":{"title":"6 Essential Tips for Working with Goose","description":"Practical tips to help you use Goose more effectively and efficiently.","authors":["angie"]},"unlisted":false,"prevItem":{"title":"Automating Phone Calls with Goose","permalink":"/goose/blog/2025/03/10/goose-calls-vyop"},"nextItem":{"title":"Let A Team of AI Agents Do It For You","permalink":"/goose/blog/2025/02/21/gooseteam-mcp"}},"content":"![goose tips](goose-tips.png)\\n\\nWorking with AI agents can sometimes feel unpredictable. After using Goose extensively for the last few months, I\'ve compiled a few key tips that will help you get the most out of this tool. No matter your workflow, these guidelines will help you work more efficiently with Goose.\\n\\n\\n\x3c!--truncate--\x3e\\n\\n## 1. Keep Sessions Focused and Short\\n\\nOne of the most common mistakes users make is trying to accomplish too much in a single session. While it might seem efficient to keep the conversation going, longer sessions can actually hinder Goose\'s performance. \\n\\nEvery message adds to the context window, which is the amount of conversation history Goose can retain at any given time. This history is made up of tokens, the individual pieces of text (words or even parts of words) that Goose processes to generate responses. More tokens don\u2019t just increase processing time, they also contribute to LLM usage costs. And once the context window fills up, older messages get pushed out, which can lead to loss of important details or unexpected behavior.\\n\\nThink of it like keeping too many browser tabs open. Eventually, it impacts performance. Instead, start fresh sessions for distinct tasks. Don\'t worry about losing context; that\'s exactly what the [Memory extension](/docs/tutorials/memory-mcp) is for. Keeping sessions focused and concise ensures more accurate, relevant responses while also keeping your LLM costs under control.\\n\\n\\n## 2. Minimize Active Extensions\\n\\nWhen it comes to Goose extensions, less is often more. It\'s tempting to enable [every available extension](https://www.pulsemcp.com/servers) just in case (I\'m guilty of this!), but this approach can be counterproductive. Each active extension adds to the system prompt, increasing complexity and making Goose work harder to decide which tools to use.\\n\\nConsider this: if you\'re cooking in a kitchen, having every possible utensil and appliance out on the counter doesn\'t make you a better chef. It just creates clutter and confusion. The same principle applies here. \\n\\nGo ahead and install any extensions that interest you, but [keep them disabled](/docs/getting-started/using-extensions#enablingdisabling-extensions) until you need them. Start with the built-in [Developer extension](/docs/tutorials/developer-mcp) enabled, which is surprisingly powerful on its own, and only enable others when you need their specific capabilities. This leads to faster responses, lower token usage, and often more focused solutions.\\n\\n:::tip Bonus Tip\\nBefore starting a complex task, ask Goose about its current capabilities. A simple prompt like \\"Do you have tools available to work with [specific technology/service]?\\" can save time and prevent false starts. Goose can tell you whether it has the necessary tools for your task, and if not, suggest which extensions you might need to enable. This quick check ensures you have the right tools ready before diving in too deep.\\n:::\\n\\n## 3. Teach Goose with .goosehints Files\\n\\n\\nOne of Goose\'s most powerful features is its ability to understand context through [.goosehints](/docs/guides/using-goosehints) files, acting like a \\"README for AI\\". These hints can be set at both the project and global levels to guide Goose\u2019s responses.\\n\\nAt the project level, placing .goosehints files in your directory helps Goose understand your structure, conventions, and special considerations. You can even use multiple files - one at the root for overall guidance and others in specific directories for more granular instructions (e.g., frontend styling conventions).\\n\\nBeyond projects, global .goosehints files (`~/.config/goose/.goosehints`) apply across all sessions, making them perfect for things like:\\n\\n* Personal coding style preferences\\n* Favorite tools and workflows\\n* Standard testing practices\\n* Documentation conventions\\n* Git commit message formatting\\n\\n## 4. Choose the Right Mode for Your Workflow\\n\\nGoose offers [different modes](/docs/guides/goose-permissions) that determine how much autonomy it has when modifying files, using extensions, and performing automated actions. \\n\\n* \u26a1\ufe0f **Auto Mode (Default):** Goose can modify, create, and delete files, as well as use extensions, without requiring approval. Best for users who want seamless automation.\\n\\n* \u2705 **Approve Mode:** Goose asks for confirmation before making changes. With [Smart Approve](/docs/guides/goose-permissions#smart-approve) enabled, it evaluates risk levels and prompts for high-risk actions while executing safe ones automatically.\\n\\n* \ud83d\udcac **Chat Mode:** Goose operates in chat-only mode, without modifying files or using extensions. Ideal for users who want AI assistance without automation.\\n\\nIf you\u2019re new to Goose or working on a critical project, Approve Mode offers a great balance of automation and oversight. For hands-free workflows, Auto Mode keeps things moving, while Chat Mode is perfect for brainstorming and general AI assistance.\\n\\n## 5. Guide Goose with Step-by-Step Execution\\n\\nComplex tasks are best handled in stages, and Goose excels when you allow it to break problems into manageable steps. Instead of expecting an instant solution, ask Goose to generate a step-by-step plan first. Review the plan to ensure it aligns with your goals, then let Goose execute each step in sequence.\\n\\nThis structured approach not only improves accuracy but also gives you more control over the process. You can pause, adjust, or refine each step as needed, giving you more control while ensuring better results.\\n\\n## 6. Refine and Iterate for Better Responses\\n\\nGoose is powerful, but like any AI, it sometimes needs a second pass to get things right. If you don\u2019t get the response you need, try refining your prompt or asking Goose to adjust its answer.\\n\\nGood iteration techniques include:\\n\\n* Asking Goose to explain its reasoning before taking action\\n* Requesting alternative solutions to compare different approaches\\n* Asking for a step-by-step breakdown of its thought process\\n* Rewording prompts to add more detail or constraints\\n\\nFor example, instead of asking, \\"Help me debug this error,\\" try, \\"I\u2019m getting a NullPointerException in my Java method. Here\u2019s the stack trace. What could be causing it?\\" A small tweak in how you ask can dramatically improve the quality of the response.\\n\\n---\\n\\nBy following these tips, you\'ll be able to work more effectively with Goose, getting better results while using fewer resources. Remember, the goal is to solve problems efficiently and effectively. Whether you\'re writing code, automating tasks, or managing complex projects, these guidelines will help you make the most of what Goose has to offer.\\n\\n<head>\\n  <meta property=\\"og:title\\" content=\\"6 Essential Tips for Working with Goose\\" />\\n  <meta property=\\"og:type\\" content=\\"article\\" />\\n  <meta property=\\"og:url\\" content=\\"https://block.github.io/goose/blog/2025/03/06/goose-tips\\" />\\n  <meta property=\\"og:description\\" content=\\"Practical tips to help you use Goose more effectively and efficiently.\\" />\\n  <meta property=\\"og:image\\" content=\\"https://block.github.io/goose/assets/images/goose-tips-4add28cc7201737dfb468ad11980f070.png\\" />\\n  <meta name=\\"twitter:card\\" content=\\"summary_large_image\\" />\\n  <meta property=\\"twitter:domain\\" content=\\"block.github.io/goose\\" />\\n  <meta name=\\"twitter:title\\" content=\\"6 Essential Tips for Working with Goose\\" />\\n  <meta name=\\"twitter:description\\" content=\\"Practical tips to help you use Goose more effectively and efficiently.\\" />\\n  <meta name=\\"twitter:image\\" content=\\"https://block.github.io/goose/assets/images/goose-tips-4add28cc7201737dfb468ad11980f070.png\\" />\\n</head>"},{"id":"/2025/02/21/gooseteam-mcp","metadata":{"permalink":"/goose/blog/2025/02/21/gooseteam-mcp","source":"@site/blog/2025-02-21-gooseteam-mcp/index.md","title":"Let A Team of AI Agents Do It For You","description":"Community Spotlight on Cliff Hall\'s GooseTeam MCP server.","date":"2025-02-21T00:00:00.000Z","tags":[],"readingTime":2.345,"hasTruncateMarker":true,"authors":[{"name":"Tania Chakraborty","title":"Senior Technical Community Manager","page":{"permalink":"/goose/blog/authors/tania"},"socials":{"linkedin":"https://www.linkedin.com/in/taniachakraborty/","x":"https://x.com/taniashiba","github":"https://github.com/taniashiba"},"imageURL":"https://avatars.githubusercontent.com/u/126204004?v=4","key":"tania"}],"frontMatter":{"title":"Let A Team of AI Agents Do It For You","description":"Community Spotlight on Cliff Hall\'s GooseTeam MCP server.","authors":["tania"]},"unlisted":false,"prevItem":{"title":"6 Essential Tips for Working with Goose","permalink":"/goose/blog/2025/03/06/goose-tips"},"nextItem":{"title":"Agentic AI and the MCP Ecosystem","permalink":"/goose/blog/2025/02/17/agentic-ai-mcp"}},"content":"![blog banner](gooseteam-mcp.png)\\n\\nDuring our [previous livestream](https://youtu.be/9tq-QUnE29U), Aaron Goldsmith, Infrastructure Operations Engineer at Cash App, showed a team of Goose AI agents collaborating in real time to create a website. Our community loved it so much, Cliff Hall was inspired to iterate on that idea and create a GooseTeam MCP server.\\n\\n\x3c!--truncate--\x3e\\n\\n## The Original Protocol\\n\\nAaron Goldsmith made an AI agent team consisting of multiple Goose instances a reality with his lightweight [Agent Communication Protocol](https://gist.github.com/AaronGoldsmith/114c439ae67e4f4c47cc33e829c82fac). With it, each Goose agent enters the chat, gets assigned a role (e.g. Project Coordinator, Researcher, Web Developer), and works on its part of a given task. The protocol specifies instructions guiding how the agents should talk and behave, allowing multiple Goose agents to collaborate. It also specifies that communication between the agents should be done via a Python-based websocket server with text/markdown . \\n\\n## GooseTeam MCP Server\\n\\nIntroducing [GooseTeam](https://github.com/cliffhall/GooseTeam), created by Software Architect and community member, Cliff Hall. GooseTeam takes Aaron\'s protocol and iterates on it into an MCP server and collaboration protocol for Goose Agents. With features like task management, message storage, and agent waiting, you can have an entire team of Goose agents work together on a task or project for you.\\n\\nA Goose agent with the Project Coordinator role will assign roles to other agents, your connected agents will send messages that can retrieved at any time, and your team of agents will connect to the same MCP server to collaborate together.\\n\\n![Goose Agents](gooseteam-agents.png)\\n\\n## A New Way to Goose\\n\\nWorking with a team of AI agents on a task is a game changer. Instead of getting confused as to how to improve your prompt engineering on your own or work across sessions manually, tools like Cliff\'s GooseTeam or Aaron\'s Agent Communication Protocol help us make sure AI agents like Goose are doing the work for us as efficiently as possible. The possibilities feel endless!\\n\\n## Get Your Contribution Featured\\nHopefully this contribution inspired you as much as it inspired our community. If you have a Goose contribution or project you\'d like to share with our community, join our [Discord](https://discord.gg/block-opensource) and share your work in the **#share-your-work** channel. You may just be featured on our livestream or get a cool prize. \ud83d\udc40 You can also star Goose on GitHub or follow us on social media so you never miss an update from us. Until next time!\\n\\n\\n<head>\\n  <meta property=\\"og:title\\" content=\\"Let A Team of AI Agents Do It For You\\" />\\n  <meta property=\\"og:type\\" content=\\"article\\" />\\n  <meta property=\\"og:url\\" content=\\"https://block.github.io/goose/blog/2025/02/17/gooseteam-mcp\\" />\\n  <meta property=\\"og:description\\" content=\\"Community Spotlight on Cliff Hall\'s GooseTeam MCP server.\\" />\\n  <meta property=\\"og:image\\" content=\\"https://block.github.io/goose/assets/images/gooseteam-mcp-082fa2890c313519c2a1637ca979c219.png\\" />\\n  <meta name=\\"twitter:card\\" content=\\"summary_large_image\\" />\\n  <meta property=\\"twitter:domain\\" content=\\"block.github.io/goose\\" />\\n  <meta name=\\"twitter:title\\" content=\\"Let A Team of AI Agents Do It For You\\" />\\n  <meta name=\\"twitter:description\\" content=\\"Community Spotlight on Cliff Hall\'s GooseTeam MCP server.\\" />\\n  <meta name=\\"twitter:image\\" content=\\"https://block.github.io/goose/assets/images/gooseteam-mcp-082fa2890c313519c2a1637ca979c219.png\\" />\\n</head>"},{"id":"/2025/02/17/agentic-ai-mcp","metadata":{"permalink":"/goose/blog/2025/02/17/agentic-ai-mcp","source":"@site/blog/2025-02-17-agentic-ai-mcp/index.md","title":"Agentic AI and the MCP Ecosystem","description":"A 101 introduction to AI Agents","date":"2025-02-17T00:00:00.000Z","tags":[],"readingTime":6.065,"hasTruncateMarker":true,"authors":[{"name":"Angie Jones","title":"Head of Developer Relations","url":"https://angiejones.tech","page":{"permalink":"/goose/blog/authors/angie"},"socials":{"linkedin":"https://www.linkedin.com/in/angiejones/","github":"https://github.com/angiejones","x":"https://x.com/techgirl1908"},"imageURL":"https://avatars.githubusercontent.com/u/15972783?v=4","key":"angie"}],"frontMatter":{"title":"Agentic AI and the MCP Ecosystem","description":"A 101 introduction to AI Agents","authors":["angie"]},"unlisted":false,"prevItem":{"title":"Let A Team of AI Agents Do It For You","permalink":"/goose/blog/2025/02/21/gooseteam-mcp"},"nextItem":{"title":"Introducing codename goose","permalink":"/goose/blog/2025/01/28/introducing-codename-goose"}},"content":"![blog banner](agentic-ai-with-mcp.png)\\n\\nIt seems like yesterday when we all were wowed by generative AI and specifically the chat interfaces that made interacting with large language models (LLMs) accessible to everyday people.\\n\\nAs amazing as this was, it was only the beginning. The next wave of AI is agentic, meaning AI systems that don\'t just respond to prompts but take actions, make decisions, and interact with external systems. This is accomplished via **AI agents**.\\n\\n\x3c!--truncate--\x3e\\n\\n## What are AI Agents?\\n\\nWhen you interact with chatbots that use AI, like ChatGPT, you can ask it how to do something, and it\'ll provide step-by-step instructions.\\n\\nFor example, if I ran into an error while coding, I could paste the error message into ChatGPT and ask it to help me debug. Because ChatGPT doesn\'t have access to my codebase, it would speculate on the cause of my error and give me a couple of possible solutions to try. I\'d then manually try these proposed solutions and return to inform ChatGPT of the results. We\'d continue this back and forth until the error is resolved or I give up.\\n\\nAI Agents greatly simplify this flow by talking with the LLM on my behalf and taking direct action to fix the problem.\\n\\n> _**An AI agent is a system that operates autonomously to accomplish a goal.**_\\n\\nBecause AI agents are connected to systems, they can analyze a situation, determine the next action, and execute it without much, if any, human intervention. This capability turns them from passive chatbots into automation assistants.\\n\\nBy using an AI agent, I can simply say \\"fix the error\\" and it\'ll have context about what\'s wrong and automatically fix the error for me.\\n\\n## How AI Agents Work with LLMs\\n\\nLLMs (e.g. GPT-4o, Claude 3.5 Sonnet, Gemini 2.0, etc) provide cognitive abilities to AI agents. Most AI agents will have a chat interface themselves where you type your prompt, and the agent will send this prompt to an LLM. At the same time, the agent will also inform the LLM of what **tools** it has access to.\\n\\n### Tool Calling\\n\\nTools are one of the most important aspects of agentic AI. AI agents are able to execute API calls via **tool calling**.\\n\\nLet\'s look at an example:\\n\\n1. A user sends a prompt to their AI agent: _\\"Fix the NullPointerException in my UserService.java file.\\"_\\n\\n2. The agent sends the user request and the list of its available tools to the LLM in a structured format.\\n```\\nUser Request: \\"Fix the NullPointerException in my UserService.java file.\\"\\n\\nAvailable Tools:\\n1. read_file(file_path: str) \u2192 Returns the contents of the specified file.\\n2. analyze_code(file_content: str) \u2192 Identifies potential errors and suggests fixes.\\n3. edit_file(file_path: str, modifications: dict) \u2192 Applies code changes.\\n4. run_tests() \u2192 Executes the test suite and returns results.\\n```\\n\\n3. The LLM analyzes the request and selects the appropriate tools. It determines that it needs to read the file in order to help.\\n```json\\n[\\n  {\\n    \\"tool\\": \\"read_file\\",\\n    \\"parameters\\": { \\"file_path\\": \\"UserService.java\\" }\\n  }\\n]\\n```\\n\\n4. The agent executes `read_file()` and sends the code to the LLM.\\n```java\\npublic class UserService {\\n    private Database db;\\n\\n    public void getUser(String userId) {\\n        System.out.println(db.findUserById(userId).getName());\\n    }\\n}\\n```\\n\\n5. The LLM recognizes the issue (`db` variable is not initialized) and now selects another tool to fix the issue.\\n```json\\n[\\n  {\\n    \\"tool\\": \\"edit_file\\",\\n    \\"parameters\\": {\\n      \\"file_path\\": \\"UserService.java\\",\\n      \\"modifications\\": {\\n        \\"line_number\\": 3,\\n        \\"replacement\\": \\"private Database db = new Database();\\"\\n      }\\n    }\\n  }\\n]\\n```\\n\\n6. The agent executes `edit_file()` to fix `UserService.java` and informs the LLM.\\n\\n7. The LLM determines that it\'s a good idea to run tests to confirm the change.\\n```json\\n[\\n  {\\n    \\"tool\\": \\"run_tests\\",\\n    \\"parameters\\": {}\\n  }\\n]\\n```\\n\\n8. The agent executes `run_tests()` and provides the results to the LLM.\\n```json\\n{\\n  \\"tests_passed\\": true,\\n  \\"failed_tests\\": []\\n}\\n```\\n\\n9. The LLM generates a final message that the agent then presents to the user.\\n```\\nI\u2019ve fixed the NullPointerException in UserService.java by initializing the db variable. All tests have passed. Let me know if you need further modifications!\\n```\\n\\nWithout tool calling, LLMs would only guess answers based on their training data. But by using tools, agents can directly access the data they need to make accurate decisions and take actions.\\n\\nIt\'s worth noting that not all agents are the same when it comes to tool access. Most proprietary agents are tightly scoped to a specific LLM and a predefined set of tools, as companies build agents tailored for their own applications.\\n\\nOther agents, like Goose, are more extensible, allowing users to configure it with the LLM of their choice, as well as add tools for various APIs, databases, and even [local environments like IDEs](/docs/tutorials/jetbrains-mcp). However, for agents to scale across different tools and systems without requiring custom integrations for each one, they need a standardized way to discover, call, and manage tools. This is exactly what the [Model Context Protocol (MCP)](https://modelcontextprotocol.io/introduction) provides.\\n\\n## MCP Ecosystem\\n\\nTraditional AI integrations require custom API calls for every system, making scaling difficult. MCP solves this by providing an open, universal protocol for agents to communicate with external systems dynamically.\\n\\nWith MCP, an agent like Goose can:\\n\\n* connect to any API without a developer writing manual integration code\\n* integrate with cloud services, dev tools, databases, and enterprise systems\\n* retrieve and store context to enhance reasoning\\n\\nAt the time of this writing, there are more than [1000 MCP servers](https://www.pulsemcp.com/servers) (systems that expose tools) that any MCP-enabled AI agent like Goose can connect to! These MCP servers act as bridges between agents and external systems, enabling access to APIs, databases, and development environments. Some were developed by the official API providers, while the vast majority were developed by community members. Because MCP is an open standard, anyone can build an MCP server for any resource. This greatly increases the possibilities of AI agents!\\n\\nFor example, let\'s say I want Goose to develop a new web app for me in my WebStorm IDE based on a Figma design and then commit the code to a new repo in GitHub. I can add the following MCP Servers as Goose extensions to give it all of these capabilities:\\n\\n* [Figma](/docs/tutorials/figma-mcp)\\n* [JetBrains](/docs/tutorials/jetbrains-mcp)\\n* [GitHub](/docs/tutorials/github-mcp)\\n\\nWith this, I can prompt my AI agent in natural language and it\'ll take care of the work:\\n\\n> _\\"Based on the figma design with file ID XYZ, build a web app in WebStorm and commit the code to a new GitHub repo named angiejones/myapp\\"_\\n\\nPretty powerful, right?! \\n\\n## Get Started with AI Agents\\nHopefully this has provided clear insight into what are AI agents, how they work, and what they can enable for you. [Goose](/docs/getting-started/installation) is free and open source and you can add as many [extensions](/docs/getting-started/using-extensions#adding-extensions) as you desire. This is a great way to get started with AI agents and see how they can automate tasks in your workflow to make you more efficient.\\n\\n\\n<head>\\n  <meta property=\\"og:title\\" content=\\"Agentic AI and the MCP Ecosystem\\" />\\n  <meta property=\\"og:type\\" content=\\"article\\" />\\n  <meta property=\\"og:url\\" content=\\"https://block.github.io/goose/blog/2025/02/17/agentic-ai-mcp\\" />\\n  <meta property=\\"og:description\\" content=\\"A 101 introduction to AI Agents\\" />\\n  <meta property=\\"og:image\\" content=\\"https://block.github.io/goose/assets/images/agentic-ai-with-mcp-1e3050cc8d8ae7a620440e871ad9f0d2.png\\" />\\n  <meta name=\\"twitter:card\\" content=\\"summary_large_image\\" />\\n  <meta property=\\"twitter:domain\\" content=\\"block.github.io/goose\\" />\\n  <meta name=\\"twitter:title\\" content=\\"Agentic AI and the MCP Ecosystem\\" />\\n  <meta name=\\"twitter:description\\" content=\\"A 101 introduction to AI Agents\\" />\\n  <meta name=\\"twitter:image\\" content=\\"https://block.github.io/goose/assets/images/agentic-ai-with-mcp-1e3050cc8d8ae7a620440e871ad9f0d2.png\\" />\\n</head>"},{"id":"/2025/01/28/introducing-codename-goose","metadata":{"permalink":"/goose/blog/2025/01/28/introducing-codename-goose","source":"@site/blog/2025-01-28-introducing-codename-goose/index.md","title":"Introducing codename goose","description":"codename goose is your open source AI agent, automating engineering tasks and improving productivity.","date":"2025-01-28T00:00:00.000Z","tags":[],"readingTime":2.465,"hasTruncateMarker":true,"authors":[{"name":"Adewale Abati","title":"Staff Developer Advocate","url":"https://adewaleabati.com","page":{"permalink":"/goose/blog/authors/adewale"},"socials":{"x":"https://x.com/ace_kyd","github":"https://github.com/acekyd"},"imageURL":"https://avatars.githubusercontent.com/u/4003538?v=4","key":"adewale"}],"frontMatter":{"title":"Introducing codename goose","description":"codename goose is your open source AI agent, automating engineering tasks and improving productivity.","authors":["adewale"]},"unlisted":false,"prevItem":{"title":"Agentic AI and the MCP Ecosystem","permalink":"/goose/blog/2025/02/17/agentic-ai-mcp"},"nextItem":{"title":"Resolving CI Issues with Goose: A Practical Walkthrough","permalink":"/goose/blog/2024/12/11/resolving-ci-issues-with-goose-a-practical-walkthrough"}},"content":"![Introducing codename goose](introducing-codename-goose.png)\\n\\nWe are thrilled to announce **codename goose**, your on-machine, open source AI agent built to automate your tasks. \\n\\nPowered by your choice of [large language models (LLMs)](/docs/getting-started/providers), a user-friendly desktop interface and CLI, and [extensions](/docs/getting-started/using-extensions) that integrate with your existing tools and applications, Goose is designed to enhance your productivity and workflow.\\n\\n\x3c!--truncate--\x3e\\n\\n\\nYou can think of Goose as an assistant that is ready to take your instructions, and do the work for you.\\n\\nWhile Goose\'s first use cases are engineering focused, the community has been exploring other non-engineering use cases for Goose as well. And it goes without saying, Goose is [open source](https://github.com/block/goose) \ud83c\udf89.\\n\\n\\n## How Goose Works\\n\\nGoose operates as an intelligent, autonomous agent capable of handling complex tasks through a well-orchestrated coordination of its core features:\\n  \\n- **Using Extensions**: [Extensions](/docs/getting-started/using-extensions) are key to Goose\u2019s adaptability, providing you the ability to connect with applications and tools that you already use. Whether it\u2019s connecting to GitHub, accessing Google Drive or integrating with JetBrains IDEs, the possibilities are extensive. Some of these extensions have been curated in the [extensions][extensions-directory] directory. Goose extensions are built on the [Model Context Protocol (MCP)](https://www.anthropic.com/news/model-context-protocol) - enabling you to build or bring your own custom integrations to Goose. \\n\\n- **LLM Providers**: Goose is compatible with a wide range of [LLM providers](/docs/getting-started/providers), allowing you to choose and integrate your preferred model. \\n\\n- **CLI and Desktop Support**: You can run Goose as a desktop app or through the command-line interface (CLI) using the same configurations across both.\\n\\n## Goose in Action\\n\\nGoose is able to handle a wide range of tasks, from simple to complex, across various engineering domains. Here are some examples of tasks that Goose has helped people with:\\n\\n- Conduct code migrations such as Ember to React, Ruby to Kotlin, Prefect-1 to Prefect-2 etc. \\n- Dive into a new project in an unfamiliar coding language\\n- Transition a code-base from field-based injection to constructor-based injection in a dependency injection framework.\\n- Conduct performance benchmarks for a build command using a build automation tool\\n- Increasing code coverage above a specific threshold\\n- Scaffolding an API for data retention\\n- Creating Datadog monitors\\n- Removing or adding feature flags etc.\\n- Generating unit tests for a feature\\n\\n## Getting Started\\n\\nYou can get started using Goose right away! Check out our [Quickstart](/docs/quickstart).\\n\\n\\n## Join the Goose Community\\n\\nExcited for upcoming features and events? Be sure to connect with us!\\n\\n- [GitHub](https://github.com/block/goose)\\n- [Discord](https://discord.gg/block-opensource)\\n- [YouTube](https://www.youtube.com/@blockopensource)\\n- [LinkedIn](https://www.linkedin.com/company/block-opensource)\\n- [X](https://x.com/blockopensource)\\n- [BlueSky](https://bsky.app/profile/opensource.block.xyz)\\n\\n\\n[extensions-directory]: https://block.github.io/goose/v1/extensions\\n\\n\\n<head>\\n  <meta property=\\"og:title\\" content=\\"Introducing codename goose\\" />\\n  <meta property=\\"og:type\\" content=\\"article\\" />\\n  <meta property=\\"og:url\\" content=\\"https://block.github.io/goose/blog/2024/12/11/resolving-ci-issues-with-goose-a-practical-walkthrough\\" />\\n  <meta property=\\"og:description\\" content=\\"codename goose is your open source AI agent, automating engineering tasks and improving productivity.\\" />\\n  <meta property=\\"og:image\\" content=\\"https://block.github.io/goose/assets/images/introducing-codename-goose-89cac25816e0ea215dd47d4b9768c8ab.png\\" />\\n  <meta name=\\"twitter:card\\" content=\\"summary_large_image\\" />\\n  <meta property=\\"twitter:domain\\" content=\\"block.github.io/goose\\" />\\n  <meta name=\\"twitter:title\\" content=\\"Introducing codename goose\\" />\\n  <meta name=\\"twitter:description\\" content=\\"codename goose is your open source AI agent, automating engineering tasks and improving productivity.\\" />\\n  <meta name=\\"twitter:image\\" content=\\"https://block.github.io/goose/assets/images/introducing-codename-goose-89cac25816e0ea215dd47d4b9768c8ab.png\\" />\\n</head>"},{"id":"/2024/12/11/resolving-ci-issues-with-goose-a-practical-walkthrough","metadata":{"permalink":"/goose/blog/2024/12/11/resolving-ci-issues-with-goose-a-practical-walkthrough","source":"@site/blog/2024-12-11-resolving-ci-issues-with-goose-a-practical-walkthrough/index.md","title":"Resolving CI Issues with Goose: A Practical Walkthrough","description":"Leverage Goose to simplify your CI debugging process, fetch detailed information about failed CI runs & annotations directly from GitHub, and even apply fixes directly.","date":"2024-12-11T00:00:00.000Z","tags":[],"readingTime":3.985,"hasTruncateMarker":true,"authors":[{"name":"Dalton Turner","title":"Software Engineer","page":{"permalink":"/goose/blog/authors/dalton"},"socials":{"github":"https://github.com/dalton-turner"},"imageURL":"https://avatars.githubusercontent.com/u/78099245?v=4","key":"dalton"}],"frontMatter":{"draft":false,"title":"Resolving CI Issues with Goose: A Practical Walkthrough","description":"Leverage Goose to simplify your CI debugging process, fetch detailed information about failed CI runs & annotations directly from GitHub, and even apply fixes directly.","date":"2024-12-11T00:00:00.000Z","authors":["dalton"]},"unlisted":false,"prevItem":{"title":"Introducing codename goose","permalink":"/goose/blog/2025/01/28/introducing-codename-goose"},"nextItem":{"title":"Connecting AI Agents to Your Systems with MCP","permalink":"/goose/blog/2024/12/10/connecting-ai-agents-to-your-systems-with-mcp"}},"content":"![CI](goose-github-ci.png)\\n\\nRunning into Continuous Integration (CI) failures in pull requests can be quite frustrating but they happen very often. In this post, we leverage the GitHub CLI (`gh`) using Goose to simplify your CI debugging process, fetch detailed information about failed CI runs and annotations directly from GitHub, and even apply fixes directly.\\n\\n\x3c!-- truncate --\x3e\\n\\n:::warning Goose Beta Version\\nThis post was written about a beta version of Goose and the commands and flow may have changed.\\n:::\\n\\n\\n## Getting Started\\n\\nBefore diving in, ensure you have the necessary tools set up.\\n\\n### 1. Install and Authenticate GitHub CLI (`gh`)\\n\\nYou\'ll need the [GitHub CLI](https://cli.github.com/) `gh` to enable Goose\'s access to CI check run details.  \\n\\n```bash\\nbrew install gh\\ngh auth login\\n```\\n\\nFollow the prompts to authenticate your account.\\n\\n\\n### 2. Configure Goose\\nEnsure Goose is configured and ready to interact with your repository and local tools. Specifically, you will need to configure a goose profile with the GitHub toolkit.\\n\\nUpdate your `profiles.yaml` file in `~/.config/goose` with the necessary toolkits:\\n\\n```yaml\\nmy-profile:\\n  provider: anthropic\\n  processor: claude-3-5-sonnet\\n  accelerator: claude-3-5-sonnet\\n  moderator: truncate\\n  toolkits:\\n    - name: developer\\n      requires: {}\\n    - name: github\\n      requires: {}\\n```\\nStart a session with the profile:\\n\\n```bash\\ngoose session start --profile my-profile\\n```\\nIf the profile\u2019s toolkits are not correctly configured, Goose might fail to access `gh` commands.\\n\\n## Resolving CI Failures with Goose\\nOnce everything is set up, we can now use Goose to tackle CI issues with the following steps:\\n\\n### Step 1: Fetch CI Failure Details\\nAsk Goose to retrieve information about the CI failures for a specific PR.\\n\\n**Example Request:**\\n\\n```\\n\\nCan you tell me about the CI failures on PR #11111 in the organization/repo repository? The check run ID is 123456.\\n```\\n\\nYou can access a check run ID by clicking on a PR\u2019s checks tab and selecting a failure. The ID will be available in the URL.\\n\\n**Goose\'s Workflow:**\\n\\nGoose will use the `gh` CLI to check run information and provide a detailed summary of the issues. Goose uses the GitHub CLI to:\\n\\n- Fetch details about failed CI runs, including logs and annotations.\\n- Provide a clear and actionable summary of issues.\\n\\n**Example Command Goose Runs:**\\n\\n```curl\\ngh api -H \\"Accept: application/vnd.github+json\\" /repos/<owner>/<repo>/check-runs/<check-run-id>/annotations\\n```\\n\\n**Example Goose Output:**\\n```mathematica\\nHere are the details for Check Run ID 123456:\\n\\n**Name**: CI-Build-All  \\n**Status**: completed  \\n**Conclusion**: failure  \\n\\n**Annotations Summary:**  \\n1. **ModuleA Test Failure**  \\n   File: `ModuleATests`  \\n   Line: 35  \\n   Error: Mismatched parameter order in function call.  \\n\\n2. **ModuleB Test Failure**  \\n   File: `ModuleBTests`  \\n   Line: 64  \\n   Error: Unexpected nil value encountered during initialization.  \\n\\n3. **ModuleC Test Failure**  \\n   File: `ModuleCTests`  \\n   Line: 98  \\n   Error: Type mismatch in returned value. Expected \'String\', found \'Int\'.  \\n```\\n### Step 2: Request Fixes from Goose\\nOnce Goose provides the failure details, ask it to resolve the issues directly.\\n\\nExample Request:\\n\\n```\\nCan you fix these issues and stage the changes so I can review them? Do not add unnecessary code comments.\\n```\\n\\n**What Goose Does:**\\n\\n- Applies fixes based on error messages.\\n- Stages changes for review.\\n\\n\\n**Example Goose Response:**\\n```markdown\\nI have fixed the following files and staged them:\\n\\n- `ModuleATests`: Corrected the order of parameters in the function call.  \\n- `ModuleBTests`: Resolved the unexpected nil value encountered during initialization.  \\n- `ModuleCTests`: Adjusted the type mismatch in the returned value.  \\n\\nYou can now review the staged changes.\\n```\\n\\n\\n### Step 3: Review the Changes\\nCarefully review the staged changes to ensure they address the issues correctly and avoid unintended modifications.\\n\\n**Things to Check:**\\n\\n- No unnecessary comments (e.g., // Fix xyz).\\n- No alterations to unrelated parts of the code.\\n\\n\\nIf needed, clean up or re-stage the changes before committing.\\n\\n## Benefits of Using Goose\\nUsing Goose to resolve CI issues streamlines your workflow by:\\n\\n- identifying issues and applying fixes with minimal manual effort.\\n- integrating with tools like the GitHub CLI to validate changes.\\n- handling repetitive CI debugging tasks while you focus on code quality.\\n\\nGoose allows you to resolve CI failures efficiently, ensuring confidence in your workflow while reducing the effort required for debugging and testing.\\n\\nTry it out, and let Goose handle the heavy lifting of CI debugging for you!\\n\\n<head>\\n  <meta property=\\"og:title\\" content=\\"Resolving CI Issues with Goose: A Practical Walkthrough\\" />\\n  <meta property=\\"og:type\\" content=\\"article\\" />\\n  <meta property=\\"og:url\\" content=\\"https://block.github.io/goose/blog/2024/12/11/resolving-ci-issues-with-goose-a-practical-walkthrough\\" />\\n  <meta property=\\"og:description\\" content=\\"Leverage Goose to simplify your CI debugging process, fetch detailed information about failed CI runs & annotations directly from GitHub, and even apply fixes directly.\\" />\\n  <meta property=\\"og:image\\" content=\\"https://block.github.io/goose/assets/images/goose-github-ci-30930008ab57b0aebae15a03c73a12b5.png\\" />\\n  <meta name=\\"twitter:card\\" content=\\"summary_large_image\\" />\\n  <meta property=\\"twitter:domain\\" content=\\"block.github.io/goose\\" />\\n  <meta name=\\"twitter:title\\" content=\\"Resolving CI Issues with Goose: A Practical Walkthrough\\" />\\n  <meta name=\\"twitter:description\\" content=\\"Leverage Goose to simplify your CI debugging process, fetch detailed information about failed CI runs & annotations directly from GitHub, and even apply fixes directly.\\" />\\n  <meta name=\\"twitter:image\\" content=\\"https://block.github.io/goose/assets/images/goose-github-ci-30930008ab57b0aebae15a03c73a12b5.png\\" />\\n</head>"},{"id":"/2024/12/10/connecting-ai-agents-to-your-systems-with-mcp","metadata":{"permalink":"/goose/blog/2024/12/10/connecting-ai-agents-to-your-systems-with-mcp","source":"@site/blog/2024-12-10-connecting-ai-agents-to-your-systems-with-mcp/index.md","title":"Connecting AI Agents to Your Systems with MCP","description":"mcp","date":"2024-12-10T00:00:00.000Z","tags":[],"readingTime":3.315,"hasTruncateMarker":true,"authors":[{"name":"Angie Jones","title":"Head of Developer Relations","url":"https://angiejones.tech","page":{"permalink":"/goose/blog/authors/angie"},"socials":{"linkedin":"https://www.linkedin.com/in/angiejones/","github":"https://github.com/angiejones","x":"https://x.com/techgirl1908"},"imageURL":"https://avatars.githubusercontent.com/u/15972783?v=4","key":"angie"}],"frontMatter":{"draft":false,"title":"Connecting AI Agents to Your Systems with MCP","date":"2024-12-10T00:00:00.000Z","authors":["angie"]},"unlisted":false,"prevItem":{"title":"Resolving CI Issues with Goose: A Practical Walkthrough","permalink":"/goose/blog/2024/12/11/resolving-ci-issues-with-goose-a-practical-walkthrough"},"nextItem":{"title":"Previewing Goose v1.0 Beta","permalink":"/goose/blog/2024/12/06/previewing-goose-v10-beta"}},"content":"![mcp](goose-mcp.png)\\n\\nOpen standards are a critical ingredient for interoperable systems. They have enabled most of the technologies that we all rely on. The ability to connect to the internet no matter where we are relies on open standards such as Wi-Fi, TCP/IP and DNS. When you receive an email in your Gmail account from an Outlook sender, it\'s the use of open standards like SMTP, IMAP, and POP3 that makes this seamless. One of the most transformative technologies of our lifetime - the internet - enables anyone to have their web page accessible to the entire world thanks to the HTTP and HTML standards.\\n\\nWe\'re in the early days of a new era in tech, one where companies are innovating and building practical AI solutions for the masses. To ensure the longevity of this technology, open standards will be essential in guiding the development of AI tools so that the diverse systems built by various companies can work together seamlessly.\\n\\n\x3c!-- truncate --\x3e\\n\\n\\n### The MCP Open Standard\\n\\nAnthropic is leading the charge with the [Model Context Protocol (MCP)](https://modelcontextprotocol.io), an open standard that enables large language model (LLM) applications to connect with external systems, providing the necessary context for more informed and relevant AI interactions. \\n\\nThis is a game changer for AI agents such as [Goose](https://block.github.io/goose/), which can perform tasks autonomously - a significant leap beyond chatbots that only provide step-by-step instructions. However, to unlock the full potential of these AI agents, we need a standard method for connecting them to external data sources. MCP provides this foundation.\\n\\nWith MCP\'s standardized APIs and endpoints, Goose can integrate seamlessly into your systems, enhancing its ability to perform complex tasks like debugging, writing code, and running commands directly in your environment. \\n\\n![Goose Framework](goose-framework-1.0.png)\\n\\n### What\'s Possible\\n\\nWithout MCP, every [Goose toolkit](https://block.github.io/goose/plugins/using-toolkits.html) developer would need to implement bespoke integrations with every system they need to connect to. Not only is this tedious and repetitive, but it delays the fun stuff.\\n\\nLet\'s take a simple GitHub workflow, for example. Goose interacts directly with the GitHub API using custom scripts or configurations. Developers must configure Goose to authenticate with GitHub and specify endpoints for actions like fetching open pull requests or adding comments. Each integration requires manual setup and custom coding to handle authentication tokens, error handling, and API updates.\\n\\nMCP simplifies the process by providing a standardized interface for accessing GitHub as a resource. Goose, acting as an [MCP client](https://modelcontextprotocol.io/clients), requests the necessary information (e.g., list of open pull requests) from an [MCP server](https://modelcontextprotocol.io/quickstart#general-architecture) configured to expose GitHub\'s capabilities. The MCP server handles authentication and communication with GitHub, abstracting away the complexity of API interactions. Goose can then focus on tasks like providing a detailed review comment or suggesting code changes.\\n\\n### Join the Ecosystem\\n\\nAs MCP adoption expands, so does Goose\u2019s potential to deliver even more powerful solutions for your organization. By [integrating Goose](https://block.github.io/goose/) into your workflows and [embracing MCP](https://modelcontextprotocol.io/introduction), you\u2019re not just enhancing your own systems, you\u2019re contributing to the growth of an ecosystem that makes AI tools more interoperable, efficient, and impactful.\\n\\n\\n\\n<head>\\n  <meta charset=\\"UTF-8\\" />\\n  <title>Connecting AI Agents to Your Systems with MCP</title>\\n  <meta name=\\"description\\" content=\\"Goose\\" />\\n  <meta name=\\"keywords\\" content=\\"MCP, Anthropic, AI Open Standards\\" />\\n\\n\\n  \x3c!-- HTML Meta Tags --\x3e\\n  <title>Connecting AI Agents to Your Systems with MCP</title>\\n  <meta name=\\"description\\" content=\\"Learn how MCP standardizes integrations and fosters an ecosystem for the future of AI-enabled tools.\\" />\\n\\n  \x3c!-- Facebook Meta Tags --\x3e\\n  <meta property=\\"og:url\\" content=\\"https://block.github.io/goose/blog/2024/12/10/connecting-ai-agents-to-your-systems-with-mcp\\" />\\n  <meta property=\\"og:type\\" content=\\"website\\" />\\n  <meta property=\\"og:title\\" content=\\"Connecting AI Agents to Your Systems with MCP\\" />\\n  <meta property=\\"og:description\\" content=\\"Learn how MCP standardizes integrations and fosters an ecosystem for the future of AI-enabled tools.\\" />\\n  <meta property=\\"og:image\\" content=\\"https://block.github.io/goose/assets/images/goose-mcp-34a5252d18d18dff26157d673f7af779.png\\" />\\n\\n  \x3c!-- Twitter Meta Tags --\x3e\\n  <meta name=\\"twitter:card\\" content=\\"summary_large_image\\" />\\n  <meta property=\\"twitter:domain\\" content=\\"block.github.io\\" />\\n  <meta property=\\"twitter:url\\" content=\\"https://block.github.io/goose/blog/2024/12/10/connecting-ai-agents-to-your-systems-with-mcp\\" />\\n  <meta name=\\"twitter:title\\" content=\\"Connecting AI Agents to Your Systems with MCP\\" />\\n  <meta name=\\"twitter:description\\" content=\\"Learn how MCP standardizes integrations and fosters an ecosystem for the future of AI-enabled tools.\\" />\\n  <meta name=\\"twitter:image\\" content=\\"https://block.github.io/goose/assets/images/goose-mcp-34a5252d18d18dff26157d673f7af779.png\\" />\\n</head>"},{"id":"/2024/12/06/previewing-goose-v10-beta","metadata":{"permalink":"/goose/blog/2024/12/06/previewing-goose-v10-beta","source":"@site/blog/2024-12-06-previewing-goose-v10-beta/index.md","title":"Previewing Goose v1.0 Beta","description":"Goose v1.0 Beta is here! Learn about the latest features and improvements.","date":"2024-12-06T00:00:00.000Z","tags":[],"readingTime":2.075,"hasTruncateMarker":true,"authors":[{"name":"Adewale Abati","title":"Staff Developer Advocate","url":"https://adewaleabati.com","page":{"permalink":"/goose/blog/authors/adewale"},"socials":{"x":"https://x.com/ace_kyd","github":"https://github.com/acekyd"},"imageURL":"https://avatars.githubusercontent.com/u/4003538?v=4","key":"adewale"}],"frontMatter":{"draft":false,"title":"Previewing Goose v1.0 Beta","description":"Goose v1.0 Beta is here! Learn about the latest features and improvements.","date":"2024-12-06T00:00:00.000Z","authors":["adewale"]},"unlisted":false,"prevItem":{"title":"Connecting AI Agents to Your Systems with MCP","permalink":"/goose/blog/2024/12/10/connecting-ai-agents-to-your-systems-with-mcp"},"nextItem":{"title":"Screenshot-Driven Development","permalink":"/goose/blog/2024/11/22/screenshot-driven-development"}},"content":"![Goose v1.0 Beta](goose-v1.0-beta.png)\\nWe are excited to share a preview of the new updates coming to Goose with Goose v1.0 Beta!\\n\\nThis major update comes with a bunch of new features and improvements that make Goose more powerful and user-friendly. Here are some of the key highlights.\\n\\n\x3c!-- truncate --\x3e\\n\\n\\n## Exciting Features of Goose 1.0 Beta\\n\\n### 1. Transition to Rust\\n\\nThe core of Goose has been rewritten in Rust. Why does this matter? Rust allows for a more portable and stable experience. This change means that Goose can run smoothly on different systems without the need for Python to be installed, making it easier for anyone to start using it.\\n\\n### 2. Contextual Memory\\n\\nGoose will remember previous interactions to better understand ongoing projects. This means you won\u2019t have to keep repeating yourself. Imagine having a conversation with someone who remembers every detail\u2014this is the kind of support Goose aims to offer.\\n\\n### 3. Improved Plugin System\\n\\nIn Goose v1.0, the Goose toolkit system is being replaced with Extensions. Extensions are modular daemons that Goose can interact with dynamically. As a result, Goose will be able to support more complex plugins and integrations. This will make it easier to extend Goose with new features and functionality.\\n\\n### 4. Headless mode\\n\\nYou can now run Goose in headless mode - this is useful for running Goose on servers or in environments where a graphical interface is not available.\\n\\n```sh\\ncargo run --bin goose -- run -i instructions.md\\n```\\n\\n### 5. Goose now has a GUI\\n\\nGoose now has an electron-based GUI macOS application that provides and alternative to the CLI to interact with Goose and manage your projects.\\n\\n![Goose GUI](goose-gui.png)\\n\\n### 6. Goose alignment with open protocols\\n\\nGoose v1.0 Beta now uses a custom protocol, that is designed in parallel with [Anthropic\u2019s Model Context Protocol](https://www.anthropic.com/news/model-context-protocol) (MCP) to communicate with Systems. This makes it possible for developers to create their own systems (e.g Jira, ) that Goose can integrate with. \\n\\nExcited for many more feature updates and improvements? Stay tuned for more updates on Goose! Check out the [Goose repo](https://github.com/block/goose) and join our [Discord community](https://discord.gg/block-opensource).\\n\\n\\n<head>\\n  <meta property=\\"og:title\\" content=\\"Previewing Goose v1.0 Beta\\" />\\n  <meta property=\\"og:type\\" content=\\"article\\" />\\n  <meta property=\\"og:url\\" content=\\"https://block.github.io/goose/blog/2024/12/06/previewing-goose-v10-beta\\" />\\n  <meta property=\\"og:description\\" content=\\"AI Agent uses screenshots to assist in styling.\\" />\\n  <meta property=\\"og:image\\" content=\\"https://block.github.io/goose/assets/images/goose-v1.0-beta-5d469fa73edea37cfccfe8a8ca0b47e2.png\\" />\\n  <meta name=\\"twitter:card\\" content=\\"summary_large_image\\" />\\n  <meta property=\\"twitter:domain\\" content=\\"block.github.io/goose\\" />\\n  <meta name=\\"twitter:title\\" content=\\"Screenshot-Driven Development\\" />\\n  <meta name=\\"twitter:description\\" content=\\"AI Agent uses screenshots to assist in styling.\\" />\\n  <meta name=\\"twitter:image\\" content=\\"https://block.github.io/goose/assets/images/goose-v1.0-beta-5d469fa73edea37cfccfe8a8ca0b47e2.png\\" />\\n</head>"},{"id":"/2024/11/22/screenshot-driven-development","metadata":{"permalink":"/goose/blog/2024/11/22/screenshot-driven-development","source":"@site/blog/2024-11-22-screenshot-driven-development/index.md","title":"Screenshot-Driven Development","description":"AI Agent uses screenshots to assist in styling.","date":"2024-11-22T00:00:00.000Z","tags":[],"readingTime":4.485,"hasTruncateMarker":true,"authors":[{"name":"Rizel Scarlett","title":"Staff Developer Advocate","page":{"permalink":"/goose/blog/authors/rizel"},"socials":{"x":"https://x.com/blackgirlbytes","github":"https://github.com/blackgirlbytes"},"imageURL":"https://avatars.githubusercontent.com/u/22990146?v=4","key":"rizel"}],"frontMatter":{"draft":false,"title":"Screenshot-Driven Development","description":"AI Agent uses screenshots to assist in styling.","date":"2024-11-22T00:00:00.000Z","authors":["rizel"]},"unlisted":false,"prevItem":{"title":"Previewing Goose v1.0 Beta","permalink":"/goose/blog/2024/12/06/previewing-goose-v10-beta"}},"content":"![calendar](screenshot-driven-development.png)\\n\\nI\'m a developer at heart, so when I\'m working on a personal project, the hardest part isn\'t writing code\u2014it\'s making design decisions. I recently built a calendar user interface. I wanted to enhance its visual appeal, so I researched UI design trends like \\"glassmorphism\\" and \\"claymorphism.\\"\\n\\nHowever, I didn\'t want to spend hours implementing the CSS for each design trend, so I developed a faster approach: screenshot-driven development. I used an open source developer agent called [Goose](https://github.com/block/goose) to transform my user interfaces quickly.\\n\\n\x3c!-- truncate --\x3e\\n\\n:::warning Goose Beta Version\\nThis post was written about a beta version of Goose and the commands and flow may have changed.\\n:::\\n\\n### My original calendar:\\n![calendar](screenshot-calendar-og.png)\\n\\n### Goose prototyped the designs below: \\n![Goose prototypes](goose-prototypes-calendar.png)\\n\\nIn this blog post, I\'ll show you how to quickly prototype design styles by letting Goose handle the CSS for you.\\n>\ud83d\udca1 Note: Your results might look different from my examples - that\'s part of the fun of generative AI! Each run can produce unique variations of these design trends.\\n\\n## Get Started with Screenshot-Driven Development\\n\\n### Step 1: Create your UI\\nLet\'s create a basic UI to experiment with. Create an index.html file with the code below:\\n\\n<details>\\n<summary>Create an index.html file with the code below</summary>\\n\\n```html\\n<!DOCTYPE html>\\n<html>\\n<head>\\n    <style>\\n        body {\\n            display: flex;\\n            justify-content: center;\\n            align-items: center;\\n            min-height: 100vh;\\n            margin: 0;\\n            background: linear-gradient(45deg, #6e48aa, #9c27b0);\\n            font-family: -apple-system, BlinkMacSystemFont, \\"Segoe UI\\", Roboto, sans-serif;\\n        }\\n\\n        .calendar {\\n            background: white;\\n            border-radius: 12px;\\n            box-shadow: 0 5px 20px rgba(0,0,0,0.1);\\n            width: 400px;\\n            padding: 20px;\\n        }\\n\\n        .header {\\n            display: flex;\\n            justify-content: space-between;\\n            align-items: center;\\n            padding-bottom: 20px;\\n            border-bottom: 2px solid #f0f0f0;\\n        }\\n\\n        .month {\\n            font-size: 24px;\\n            font-weight: 600;\\n            color: #1a1a1a;\\n        }\\n\\n        .days {\\n            display: grid;\\n            grid-template-columns: repeat(7, 1fr);\\n            gap: 10px;\\n            margin-top: 20px;\\n            text-align: center;\\n        }\\n\\n        .days-header {\\n            display: grid;\\n            grid-template-columns: repeat(7, 1fr);\\n            gap: 10px;\\n            margin-top: 20px;\\n            text-align: center;\\n        }\\n\\n        .days-header span {\\n            color: #666;\\n            font-weight: 500;\\n            font-size: 14px;\\n        }\\n\\n        .day {\\n            aspect-ratio: 1;\\n            display: flex;\\n            align-items: center;\\n            justify-content: center;\\n            border-radius: 50%;\\n            font-size: 14px;\\n            color: #333;\\n            cursor: pointer;\\n            transition: all 0.2s;\\n        }\\n\\n        .day:hover {\\n            background: #f0f0f0;\\n        }\\n\\n        .day.today {\\n            background: #9c27b0;\\n            color: white;\\n        }\\n\\n        .day.inactive {\\n            color: #ccc;\\n        }\\n    </style>\\n</head>\\n<body>\\n    <div class=\\"calendar\\">\\n        <div class=\\"header\\">\\n            <div class=\\"month\\">November 2024</div>\\n        </div>\\n        <div class=\\"days-header\\">\\n            <span>Sun</span>\\n            <span>Mon</span>\\n            <span>Tue</span>\\n            <span>Wed</span>\\n            <span>Thu</span>\\n            <span>Fri</span>\\n            <span>Sat</span>\\n        </div>\\n        <div class=\\"days\\">\\n            <div class=\\"day inactive\\">27</div>\\n            <div class=\\"day inactive\\">28</div>\\n            <div class=\\"day inactive\\">29</div>\\n            <div class=\\"day inactive\\">30</div>\\n            <div class=\\"day inactive\\">31</div>\\n            <div class=\\"day\\">1</div>\\n            <div class=\\"day\\">2</div>\\n            <div class=\\"day\\">3</div>\\n            <div class=\\"day\\">4</div>\\n            <div class=\\"day\\">5</div>\\n            <div class=\\"day\\">6</div>\\n            <div class=\\"day\\">7</div>\\n            <div class=\\"day\\">8</div>\\n            <div class=\\"day\\">9</div>\\n            <div class=\\"day\\">10</div>\\n            <div class=\\"day\\">11</div>\\n            <div class=\\"day\\">12</div>\\n            <div class=\\"day\\">13</div>\\n            <div class=\\"day today\\">14</div>\\n            <div class=\\"day\\">15</div>\\n            <div class=\\"day\\">16</div>\\n            <div class=\\"day\\">17</div>\\n            <div class=\\"day\\">18</div>\\n            <div class=\\"day\\">19</div>\\n            <div class=\\"day\\">20</div>\\n            <div class=\\"day\\">21</div>\\n            <div class=\\"day\\">22</div>\\n            <div class=\\"day\\">23</div>\\n            <div class=\\"day\\">24</div>\\n            <div class=\\"day\\">25</div>\\n            <div class=\\"day\\">26</div>\\n            <div class=\\"day\\">27</div>\\n            <div class=\\"day\\">28</div>\\n            <div class=\\"day\\">29</div>\\n            <div class=\\"day\\">30</div>\\n        </div>\\n    </div>\\n</body>\\n</html>\\n```\\n</details>\\n\\nOnce saved, open the file in your browser. You should see a calendar!\\n\\n### Step 2: Install Goose\\n\\n```bash\\nbrew install pipx\\npipx ensurepath\\npipx install goose-ai\\n```\\n\\n### Step 3: Start a session\\n\\n```bash\\ngoose session start\\n```\\n\\n#### Bring your own LLM\\n\\n>Goose will prompt you to set up your API key when you first run this command. You can use various LLM providers like OpenAI or Anthropic\\n\\n```bash\\nexport OPENAI_API_KEY=your_api_key\\n# Or for other providers:\\nexport ANTHROPIC_API_KEY=your_api_key\\n```\\n\\n### Step 4: Enable the Screen toolkit\\nGoose uses [toolkits](https://block.github.io/goose/plugins/plugins.html) to extend its capabilities. The [screen](https://block.github.io/goose/plugins/available-toolkits.html#6-screen-toolkit) toolkit lets Goose take and analyze screenshots.\\n\\nTo enable the Screen toolkit, add it to your Goose profile at ~/.config/goose/profiles.yaml.\\n\\n> Your configuration might look slightly different depending on your LLM provider preferences.\\n\\n\\n```yaml\\ndefault:\\n  provider: openai\\n  processor: gpt-4o\\n  accelerator: gpt-4o-mini\\n  moderator: truncate\\n  toolkits:\\n  - name: developer\\n    requires: {}\\n  - name: screen\\n    requires: {}\\n```\\n\\n### Step 5: Prompt Goose to screenshot your UI\\nGoose analyzes your UI through screenshots to understand its structure and elements. In your Gooses session, prompt Goose to take a screenshot by specifying which display your UI is on:\\n\\n```bash\\nTake a screenshot of display(1)  \\n```\\n\\n> The display number is required - use display(1) for your main monitor or display(2) for a secondary monitor.\\n\\nUpon success, Goose will run a `screencapture` command and save it as a temporary file.\\n\\n### Step 6: Prompt Goose to transform your UI\\n\\nNow, you can ask Goose to apply different design styles. Here are some of the prompts I gave Goose and the results it produced:\\n\\n#### Glassmorphism\\n\\n```bash\\nApply a glassmorphic effect to my UI\\n```\\n\\n![glassmorphism](glassmorphism-calendar.png)\\n\\n\\n#### Neumorphism\\n\\n```bash\\nApply neumorphic effects to my calendar and the dates\\n```\\n\\n![neumorphism](neumorphism-calendar.png)\\n\\n\\n#### Claymorphism\\n\\n```bash\\nPlease replace with a claymorphic effect\\n```\\n\\n![claymorphism](claymorphism-calendar.png)\\n\\n\\n#### Brutalism\\n\\n```bash\\nApply a brutalist effect please\\n```\\n\\n![brutalism](brutalism-calendar.png)\\n\\n## Learn More\\n\\nDeveloping user interfaces is a blend of creativity and problem-solving. And I love that using Goose gives me more time to focus on creativity rather than wrestling with CSS for hours. \\n\\nBeyond prototyping, Goose\'s ability to analyze screenshots can help developers identify and resolve UI bugs.\\n\\nIf you\'re interested in learning more, check out the [Goose repo](https://github.com/block/goose) and join our [Discord community](https://discord.gg/block-opensource).\\n\\n<head>\\n    <meta property=\\"og:title\\" content=\\"Screenshot-Driven Development\\" />\\n    <meta property=\\"og:type\\" content=\\"article\\" />\\n    <meta property=\\"og:url\\" content=\\"https://block.github.io/goose/blog/2024/11/22/screenshot-driven-development\\" />\\n    <meta property=\\"og:description\\" content=\\"AI Agent uses screenshots to assist in styling.\\" />\\n    <meta property=\\"og:image\\" content=\\"https://block.github.io/goose/assets/images/screenshot-driven-development-4ed1beaa10c6062c0bf87e2d27590ad6.png\\" />\\n    <meta name=\\"twitter:card\\" content=\\"summary_large_image\\" />\\n    <meta property=\\"twitter:domain\\" content=\\"block.github.io/goose\\" />\\n    <meta name=\\"twitter:title\\" content=\\"Screenshot-Driven Development\\" />\\n    <meta name=\\"twitter:description\\" content=\\"AI Agent uses screenshots to assist in styling.\\" />\\n    <meta name=\\"twitter:image\\" content=\\"https://block.github.io/goose/assets/images/screenshot-driven-development-4ed1beaa10c6062c0bf87e2d27590ad6.png\\" />\\n</head>"}]}}')}}]);